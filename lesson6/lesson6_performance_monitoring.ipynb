{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "lesson6-title",
   "metadata": {},
   "source": [
    "# 6차시: 성능 최적화 & 모니터링\n",
    "\n",
    "## 학습 목표\n",
    "- 응답 캐싱 시스템 구현\n",
    "- 비동기 처리를 통한 성능 향상\n",
    "- 토큰 사용량 최적화 전략\n",
    "- 실시간 모니터링 및 메트릭 수집\n",
    "- 성능 분석 및 대시보드 구축\n",
    "\n",
    "## 목차\n",
    "1. [캐싱 시스템](#캐싱-시스템)\n",
    "2. [비동기 처리](#비동기-처리)\n",
    "3. [토큰 최적화](#토큰-최적화)\n",
    "4. [모니터링 시스템](#모니터링-시스템)\n",
    "5. [성능 분석](#성능-분석)\n",
    "6. [실습 과제](#실습-과제)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup",
   "metadata": {},
   "source": [
    "## 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "6차시: 성능 최적화 & 모니터링\n",
    "Author: AI Chatbot Workshop\n",
    "Date: 2024-08-30\n",
    "Description: 응답 캐싱, 비동기 처리, 토큰 최적화, 모니터링 시스템 구현\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import uuid\n",
    "import logging\n",
    "import asyncio\n",
    "import hashlib\n",
    "import threading\n",
    "from typing import Dict, List, Any, Optional, Union, Callable\n",
    "from dataclasses import dataclass, asdict, field\n",
    "from datetime import datetime, timedelta\n",
    "from collections import defaultdict, deque\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from functools import wraps, lru_cache\n",
    "import pickle\n",
    "import sqlite3\n",
    "\n",
    "# 외부 라이브러리\n",
    "import streamlit as st\n",
    "from openai import OpenAI\n",
    "import redis\n",
    "import psutil\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from prometheus_client import Counter, Histogram, Gauge, start_http_server\n",
    "import asyncio\n",
    "import aiohttp\n",
    "\n",
    "# 로컬 모듈\n",
    "sys.path.append('..')\n",
    "from config import get_config\n",
    "\n",
    "# 설정 및 로깅\n",
    "config = get_config()\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Prometheus 메트릭 정의\n",
    "REQUESTS_TOTAL = Counter('chatbot_requests_total', 'Total requests', ['method', 'endpoint'])\n",
    "REQUEST_DURATION = Histogram('chatbot_request_duration_seconds', 'Request duration')\n",
    "CACHE_HITS = Counter('chatbot_cache_hits_total', 'Cache hits')\n",
    "CACHE_MISSES = Counter('chatbot_cache_misses_total', 'Cache misses')\n",
    "TOKEN_USAGE = Counter('chatbot_tokens_total', 'Token usage', ['type'])\n",
    "ACTIVE_CONNECTIONS = Gauge('chatbot_active_connections', 'Active connections')\n",
    "ERROR_RATE = Counter('chatbot_errors_total', 'Total errors', ['error_type'])\n",
    "\n",
    "print(\"환경 설정 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caching-system",
   "metadata": {},
   "source": [
    "## 1. 캐싱 시스템\n",
    "\n",
    "### 1.1 캐시 매니저 구현\n",
    "Redis와 로컬 메모리를 활용한 다층 캐싱 시스템을 구현합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cache-manager",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class CacheMetrics:\n",
    "    hits: int = 0\n",
    "    misses: int = 0\n",
    "    evictions: int = 0\n",
    "    total_size: int = 0\n",
    "    hit_rate: float = 0.0\n",
    "\n",
    "class CacheManager:\n",
    "    def __init__(self, redis_host='localhost', redis_port=6379, \n",
    "                 redis_db=0, local_cache_size=1000):\n",
    "        \"\"\"\n",
    "        다층 캐싱 시스템 초기화\n",
    "        - L1: 로컬 메모리 캐시 (빠름)\n",
    "        - L2: Redis 캐시 (영속적)\n",
    "        \"\"\"\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        \n",
    "        # Redis 연결\n",
    "        try:\n",
    "            self.redis_client = redis.Redis(\n",
    "                host=redis_host, \n",
    "                port=redis_port, \n",
    "                db=redis_db,\n",
    "                decode_responses=True\n",
    "            )\n",
    "            self.redis_client.ping()\n",
    "            self.redis_available = True\n",
    "            self.logger.info(\"Redis 연결 성공\")\n",
    "        except Exception as e:\n",
    "            self.redis_client = None\n",
    "            self.redis_available = False\n",
    "            self.logger.warning(f\"Redis 연결 실패: {e}\")\n",
    "        \n",
    "        # 로컬 캐시 (LRU)\n",
    "        self.local_cache = {}\n",
    "        self.local_cache_order = deque()\n",
    "        self.local_cache_size = local_cache_size\n",
    "        \n",
    "        # 메트릭\n",
    "        self.metrics = CacheMetrics()\n",
    "        self.lock = threading.Lock()\n",
    "    \n",
    "    def _generate_cache_key(self, key_data: Dict[str, Any]) -> str:\n",
    "        \"\"\"\n",
    "        캐시 키 생성 (해시 기반)\n",
    "        \"\"\"\n",
    "        key_string = json.dumps(key_data, sort_keys=True)\n",
    "        return hashlib.sha256(key_string.encode()).hexdigest()[:16]\n",
    "    \n",
    "    def get(self, key: str) -> Optional[Any]:\n",
    "        \"\"\"\n",
    "        캐시에서 값 조회 (L1 -> L2 순서)\n",
    "        \"\"\"\n",
    "        with self.lock:\n",
    "            # L1 캐시 확인\n",
    "            if key in self.local_cache:\n",
    "                # LRU 업데이트\n",
    "                self.local_cache_order.remove(key)\n",
    "                self.local_cache_order.append(key)\n",
    "                \n",
    "                self.metrics.hits += 1\n",
    "                CACHE_HITS.inc()\n",
    "                \n",
    "                self.logger.debug(f\"L1 캐시 히트: {key}\")\n",
    "                return self.local_cache[key]\n",
    "            \n",
    "            # L2 캐시 확인 (Redis)\n",
    "            if self.redis_available:\n",
    "                try:\n",
    "                    cached_value = self.redis_client.get(key)\n",
    "                    if cached_value:\n",
    "                        # JSON 역직렬화\n",
    "                        value = json.loads(cached_value)\n",
    "                        \n",
    "                        # L1 캐시에도 저장\n",
    "                        self._store_local(key, value)\n",
    "                        \n",
    "                        self.metrics.hits += 1\n",
    "                        CACHE_HITS.inc()\n",
    "                        \n",
    "                        self.logger.debug(f\"L2 캐시 히트: {key}\")\n",
    "                        return value\n",
    "                except Exception as e:\n",
    "                    self.logger.error(f\"Redis 조회 오류: {e}\")\n",
    "            \n",
    "            # 캐시 미스\n",
    "            self.metrics.misses += 1\n",
    "            CACHE_MISSES.inc()\n",
    "            return None\n",
    "    \n",
    "    def set(self, key: str, value: Any, ttl: int = 3600):\n",
    "        \"\"\"\n",
    "        캐시에 값 저장\n",
    "        \"\"\"\n",
    "        with self.lock:\n",
    "            # L1 캐시 저장\n",
    "            self._store_local(key, value)\n",
    "            \n",
    "            # L2 캐시 저장 (Redis)\n",
    "            if self.redis_available:\n",
    "                try:\n",
    "                    serialized_value = json.dumps(value)\n",
    "                    self.redis_client.setex(key, ttl, serialized_value)\n",
    "                except Exception as e:\n",
    "                    self.logger.error(f\"Redis 저장 오류: {e}\")\n",
    "    \n",
    "    def _store_local(self, key: str, value: Any):\n",
    "        \"\"\"\n",
    "        로컬 캐시에 저장 (LRU 정책)\n",
    "        \"\"\"\n",
    "        if key in self.local_cache:\n",
    "            self.local_cache_order.remove(key)\n",
    "        \n",
    "        self.local_cache[key] = value\n",
    "        self.local_cache_order.append(key)\n",
    "        \n",
    "        # 캐시 크기 제한\n",
    "        while len(self.local_cache) > self.local_cache_size:\n",
    "            oldest_key = self.local_cache_order.popleft()\n",
    "            del self.local_cache[oldest_key]\n",
    "            self.metrics.evictions += 1\n",
    "    \n",
    "    def get_metrics(self) -> CacheMetrics:\n",
    "        \"\"\"\n",
    "        캐시 메트릭 조회\n",
    "        \"\"\"\n",
    "        total_requests = self.metrics.hits + self.metrics.misses\n",
    "        if total_requests > 0:\n",
    "            self.metrics.hit_rate = self.metrics.hits / total_requests\n",
    "        \n",
    "        self.metrics.total_size = len(self.local_cache)\n",
    "        return self.metrics\n",
    "\n",
    "# 캐시 매니저 테스트\n",
    "cache_manager = CacheManager(local_cache_size=10)\n",
    "\n",
    "# 테스트 데이터\n",
    "test_key = \"test_conversation\"\n",
    "test_data = {\"response\": \"안녕하세요!\", \"tokens\": 100}\n",
    "\n",
    "# 저장 및 조회\n",
    "cache_manager.set(test_key, test_data)\n",
    "cached_result = cache_manager.get(test_key)\n",
    "\n",
    "print(f\"캐시 저장/조회 테스트: {cached_result}\")\n",
    "print(f\"캐시 메트릭: {cache_manager.get_metrics()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "async-processing",
   "metadata": {},
   "source": [
    "## 2. 비동기 처리\n",
    "\n",
    "### 2.1 비동기 챗봇 구현\n",
    "여러 요청을 동시에 처리할 수 있는 비동기 챗봇을 구현합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "async-chatbot",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AsyncChatbot:\n",
    "    def __init__(self, cache_manager: CacheManager):\n",
    "        \"\"\"\n",
    "        비동기 챗봇 초기화\n",
    "        \"\"\"\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        self.client = OpenAI(api_key=config.get('openai_api_key'))\n",
    "        self.cache_manager = cache_manager\n",
    "        \n",
    "        # 동시 처리 제한\n",
    "        self.semaphore = asyncio.Semaphore(10)  # 최대 10개 동시 요청\n",
    "        \n",
    "        # 메트릭\n",
    "        self.active_requests = 0\n",
    "        self.total_requests = 0\n",
    "        \n",
    "    async def chat_completion(self, messages: List[Dict], \n",
    "                             model: str = \"gpt-3.5-turbo\",\n",
    "                             use_cache: bool = True,\n",
    "                             **kwargs) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        비동기 채팅 완성 요청\n",
    "        \"\"\"\n",
    "        async with self.semaphore:\n",
    "            start_time = time.time()\n",
    "            self.active_requests += 1\n",
    "            self.total_requests += 1\n",
    "            \n",
    "            ACTIVE_CONNECTIONS.set(self.active_requests)\n",
    "            REQUESTS_TOTAL.labels(method='chat', endpoint='completion').inc()\n",
    "            \n",
    "            try:\n",
    "                # 캐시 키 생성\n",
    "                cache_key = None\n",
    "                if use_cache:\n",
    "                    cache_data = {\n",
    "                        \"messages\": messages,\n",
    "                        \"model\": model,\n",
    "                        **kwargs\n",
    "                    }\n",
    "                    cache_key = self.cache_manager._generate_cache_key(cache_data)\n",
    "                    \n",
    "                    # 캐시 조회\n",
    "                    cached_result = self.cache_manager.get(cache_key)\n",
    "                    if cached_result:\n",
    "                        self.logger.info(f\"캐시에서 응답 반환: {cache_key}\")\n",
    "                        return cached_result\n",
    "                \n",
    "                # OpenAI API 호출 (비동기 시뮬레이션)\n",
    "                loop = asyncio.get_event_loop()\n",
    "                response = await loop.run_in_executor(\n",
    "                    None, \n",
    "                    self._make_openai_request,\n",
    "                    messages, model, kwargs\n",
    "                )\n",
    "                \n",
    "                # 응답 처리\n",
    "                result = {\n",
    "                    \"response\": response.choices[0].message.content,\n",
    "                    \"model\": response.model,\n",
    "                    \"usage\": {\n",
    "                        \"prompt_tokens\": response.usage.prompt_tokens,\n",
    "                        \"completion_tokens\": response.usage.completion_tokens,\n",
    "                        \"total_tokens\": response.usage.total_tokens\n",
    "                    },\n",
    "                    \"timestamp\": datetime.now().isoformat(),\n",
    "                    \"duration\": time.time() - start_time\n",
    "                }\n",
    "                \n",
    "                # 토큰 사용량 기록\n",
    "                TOKEN_USAGE.labels(type='prompt').inc(response.usage.prompt_tokens)\n",
    "                TOKEN_USAGE.labels(type='completion').inc(response.usage.completion_tokens)\n",
    "                \n",
    "                # 캐시에 저장\n",
    "                if use_cache and cache_key:\n",
    "                    self.cache_manager.set(cache_key, result, ttl=3600)\n",
    "                \n",
    "                return result\n",
    "                \n",
    "            except Exception as e:\n",
    "                ERROR_RATE.labels(error_type=type(e).__name__).inc()\n",
    "                self.logger.error(f\"채팅 완성 오류: {e}\")\n",
    "                raise\n",
    "            finally:\n",
    "                self.active_requests -= 1\n",
    "                ACTIVE_CONNECTIONS.set(self.active_requests)\n",
    "                REQUEST_DURATION.observe(time.time() - start_time)\n",
    "    \n",
    "    def _make_openai_request(self, messages: List[Dict], \n",
    "                           model: str, kwargs: Dict) -> Any:\n",
    "        \"\"\"\n",
    "        동기 OpenAI API 호출 (스레드 풀에서 실행)\n",
    "        \"\"\"\n",
    "        return self.client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            **kwargs\n",
    "        )\n",
    "    \n",
    "    async def batch_chat_completion(self, \n",
    "                                   batch_requests: List[Dict]) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        배치 처리 - 여러 요청을 동시에 처리\n",
    "        \"\"\"\n",
    "        tasks = []\n",
    "        \n",
    "        for request in batch_requests:\n",
    "            task = asyncio.create_task(\n",
    "                self.chat_completion(**request)\n",
    "            )\n",
    "            tasks.append(task)\n",
    "        \n",
    "        # 모든 작업 완료 대기\n",
    "        results = await asyncio.gather(*tasks, return_exceptions=True)\n",
    "        \n",
    "        # 예외 처리\n",
    "        processed_results = []\n",
    "        for i, result in enumerate(results):\n",
    "            if isinstance(result, Exception):\n",
    "                self.logger.error(f\"배치 요청 {i} 실패: {result}\")\n",
    "                processed_results.append({\n",
    "                    \"error\": str(result),\n",
    "                    \"request_index\": i\n",
    "                })\n",
    "            else:\n",
    "                processed_results.append(result)\n",
    "        \n",
    "        return processed_results\n",
    "\n",
    "# 비동기 챗봇 테스트\n",
    "async def test_async_chatbot():\n",
    "    chatbot = AsyncChatbot(cache_manager)\n",
    "    \n",
    "    # 단일 요청 테스트\n",
    "    messages = [{\"role\": \"user\", \"content\": \"안녕하세요!\"}]\n",
    "    \n",
    "    start_time = time.time()\n",
    "    result = await chatbot.chat_completion(messages)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    print(f\"단일 요청 결과: {result['response'][:50]}...\")\n",
    "    print(f\"처리 시간: {end_time - start_time:.2f}초\")\n",
    "    \n",
    "    # 배치 요청 테스트\n",
    "    batch_requests = [\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": \"1+1은?\"}]},\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": \"파이썬이란?\"}]},\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": \"AI의 미래는?\"}]}\n",
    "    ]\n",
    "    \n",
    "    start_time = time.time()\n",
    "    batch_results = await chatbot.batch_chat_completion(batch_requests)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    print(f\"\\n배치 처리 결과 ({len(batch_results)}개):\")\n",
    "    for i, result in enumerate(batch_results):\n",
    "        if 'error' not in result:\n",
    "            print(f\"  {i+1}: {result['response'][:30]}...\")\n",
    "    \n",
    "    print(f\"배치 처리 시간: {end_time - start_time:.2f}초\")\n",
    "\n",
    "# 테스트 실행 (주석 해제하여 실행)\n",
    "# await test_async_chatbot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "token-optimization",
   "metadata": {},
   "source": [
    "## 3. 토큰 최적화\n",
    "\n",
    "### 3.1 토큰 최적화 관리자\n",
    "토큰 사용량을 모니터링하고 최적화하는 시스템을 구현합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "token-optimizer",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TokenUsage:\n",
    "    prompt_tokens: int = 0\n",
    "    completion_tokens: int = 0\n",
    "    total_tokens: int = 0\n",
    "    cost: float = 0.0\n",
    "    timestamp: datetime = field(default_factory=datetime.now)\n",
    "\n",
    "class TokenOptimizer:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        토큰 최적화 관리자 초기화\n",
    "        \"\"\"\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        \n",
    "        # 모델별 토큰 가격 (USD per 1K tokens)\n",
    "        self.token_prices = {\n",
    "            \"gpt-3.5-turbo\": {\"prompt\": 0.0005, \"completion\": 0.0015},\n",
    "            \"gpt-4\": {\"prompt\": 0.01, \"completion\": 0.03},\n",
    "            \"gpt-4-turbo\": {\"prompt\": 0.01, \"completion\": 0.03}\n",
    "        }\n",
    "        \n",
    "        # 사용량 추적\n",
    "        self.usage_history = deque(maxlen=10000)\n",
    "        self.daily_usage = defaultdict(TokenUsage)\n",
    "        \n",
    "        # 최적화 설정\n",
    "        self.max_context_length = {\n",
    "            \"gpt-3.5-turbo\": 4096,\n",
    "            \"gpt-4\": 8192,\n",
    "            \"gpt-4-turbo\": 128000\n",
    "        }\n",
    "    \n",
    "    def calculate_cost(self, usage: Dict[str, int], model: str) -> float:\n",
    "        \"\"\"\n",
    "        토큰 사용량 기반 비용 계산\n",
    "        \"\"\"\n",
    "        if model not in self.token_prices:\n",
    "            self.logger.warning(f\"알 수 없는 모델: {model}\")\n",
    "            return 0.0\n",
    "        \n",
    "        prices = self.token_prices[model]\n",
    "        \n",
    "        prompt_cost = (usage.get('prompt_tokens', 0) / 1000) * prices['prompt']\n",
    "        completion_cost = (usage.get('completion_tokens', 0) / 1000) * prices['completion']\n",
    "        \n",
    "        return prompt_cost + completion_cost\n",
    "    \n",
    "    def track_usage(self, usage: Dict[str, int], model: str):\n",
    "        \"\"\"\n",
    "        토큰 사용량 추적\n",
    "        \"\"\"\n",
    "        cost = self.calculate_cost(usage, model)\n",
    "        \n",
    "        token_usage = TokenUsage(\n",
    "            prompt_tokens=usage.get('prompt_tokens', 0),\n",
    "            completion_tokens=usage.get('completion_tokens', 0),\n",
    "            total_tokens=usage.get('total_tokens', 0),\n",
    "            cost=cost\n",
    "        )\n",
    "        \n",
    "        self.usage_history.append(token_usage)\n",
    "        \n",
    "        # 일별 사용량 누적\n",
    "        today = datetime.now().date().isoformat()\n",
    "        daily = self.daily_usage[today]\n",
    "        daily.prompt_tokens += token_usage.prompt_tokens\n",
    "        daily.completion_tokens += token_usage.completion_tokens\n",
    "        daily.total_tokens += token_usage.total_tokens\n",
    "        daily.cost += token_usage.cost\n",
    "    \n",
    "    def optimize_messages(self, messages: List[Dict], \n",
    "                         model: str = \"gpt-3.5-turbo\") -> List[Dict]:\n",
    "        \"\"\"\n",
    "        메시지 최적화 (컨텍스트 길이 제한)\n",
    "        \"\"\"\n",
    "        max_length = self.max_context_length.get(model, 4096)\n",
    "        \n",
    "        # 토큰 수 추정 (대략적)\n",
    "        estimated_tokens = sum(len(msg.get('content', '').split()) * 1.3 \n",
    "                              for msg in messages)\n",
    "        \n",
    "        if estimated_tokens <= max_length * 0.8:  # 80% 임계값\n",
    "            return messages\n",
    "        \n",
    "        # 시스템 메시지와 최근 메시지 유지\n",
    "        optimized_messages = []\n",
    "        \n",
    "        # 시스템 메시지 보존\n",
    "        for msg in messages:\n",
    "            if msg.get('role') == 'system':\n",
    "                optimized_messages.append(msg)\n",
    "        \n",
    "        # 최근 대화 유지 (역순으로 추가)\n",
    "        remaining_tokens = max_length * 0.7\n",
    "        current_tokens = 0\n",
    "        \n",
    "        for msg in reversed(messages):\n",
    "            if msg.get('role') != 'system':\n",
    "                msg_tokens = len(msg.get('content', '').split()) * 1.3\n",
    "                if current_tokens + msg_tokens <= remaining_tokens:\n",
    "                    optimized_messages.insert(-len([m for m in optimized_messages \n",
    "                                                   if m.get('role') != 'system']), msg)\n",
    "                    current_tokens += msg_tokens\n",
    "                else:\n",
    "                    break\n",
    "        \n",
    "        self.logger.info(f\"메시지 최적화: {len(messages)} -> {len(optimized_messages)}\")\n",
    "        return optimized_messages\n",
    "    \n",
    "    def get_usage_summary(self, days: int = 7) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        사용량 요약 정보 조회\n",
    "        \"\"\"\n",
    "        # 최근 N일 데이터\n",
    "        end_date = datetime.now().date()\n",
    "        start_date = end_date - timedelta(days=days-1)\n",
    "        \n",
    "        period_usage = TokenUsage()\n",
    "        daily_breakdown = {}\n",
    "        \n",
    "        current_date = start_date\n",
    "        while current_date <= end_date:\n",
    "            date_str = current_date.isoformat()\n",
    "            daily_data = self.daily_usage.get(date_str, TokenUsage())\n",
    "            \n",
    "            daily_breakdown[date_str] = asdict(daily_data)\n",
    "            \n",
    "            period_usage.prompt_tokens += daily_data.prompt_tokens\n",
    "            period_usage.completion_tokens += daily_data.completion_tokens\n",
    "            period_usage.total_tokens += daily_data.total_tokens\n",
    "            period_usage.cost += daily_data.cost\n",
    "            \n",
    "            current_date += timedelta(days=1)\n",
    "        \n",
    "        return {\n",
    "            \"period\": f\"{start_date} ~ {end_date}\",\n",
    "            \"total_usage\": asdict(period_usage),\n",
    "            \"daily_breakdown\": daily_breakdown,\n",
    "            \"average_daily_cost\": period_usage.cost / days if days > 0 else 0,\n",
    "            \"total_requests\": len(self.usage_history)\n",
    "        }\n",
    "\n",
    "# 토큰 최적화 테스트\n",
    "token_optimizer = TokenOptimizer()\n",
    "\n",
    "# 사용량 추적 테스트\n",
    "test_usage = {\n",
    "    \"prompt_tokens\": 100,\n",
    "    \"completion_tokens\": 50,\n",
    "    \"total_tokens\": 150\n",
    "}\n",
    "\n",
    "token_optimizer.track_usage(test_usage, \"gpt-3.5-turbo\")\n",
    "cost = token_optimizer.calculate_cost(test_usage, \"gpt-3.5-turbo\")\n",
    "\n",
    "print(f\"토큰 비용 계산: ${cost:.6f}\")\n",
    "\n",
    "# 메시지 최적화 테스트\n",
    "long_messages = [\n",
    "    {\"role\": \"system\", \"content\": \"당신은 도움이 되는 AI 어시스턴트입니다.\"},\n",
    "    {\"role\": \"user\", \"content\": \"안녕하세요!\" * 100},\n",
    "    {\"role\": \"assistant\", \"content\": \"안녕하세요! 무엇을 도와드릴까요?\" * 100},\n",
    "    {\"role\": \"user\", \"content\": \"파이썬에 대해 알려주세요.\" * 100}\n",
    "]\n",
    "\n",
    "optimized = token_optimizer.optimize_messages(long_messages)\n",
    "print(f\"메시지 최적화: {len(long_messages)} -> {len(optimized)}\")\n",
    "\n",
    "# 사용량 요약\n",
    "summary = token_optimizer.get_usage_summary(days=1)\n",
    "print(f\"사용량 요약: {summary['total_usage']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monitoring-system",
   "metadata": {},
   "source": [
    "## 4. 모니터링 시스템\n",
    "\n",
    "### 4.1 성능 모니터 구현\n",
    "시스템 성능과 메트릭을 실시간으로 모니터링하는 시스템을 구현합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "performance-monitor",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SystemMetrics:\n",
    "    cpu_percent: float = 0.0\n",
    "    memory_percent: float = 0.0\n",
    "    disk_usage: float = 0.0\n",
    "    network_io: Dict[str, int] = field(default_factory=dict)\n",
    "    timestamp: datetime = field(default_factory=datetime.now)\n",
    "\n",
    "class PerformanceMonitor:\n",
    "    def __init__(self, db_path: str = \"performance_metrics.db\"):\n",
    "        \"\"\"\n",
    "        성능 모니터 초기화\n",
    "        \"\"\"\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        self.db_path = db_path\n",
    "        \n",
    "        # 메트릭 저장소\n",
    "        self.metrics_buffer = deque(maxlen=1000)\n",
    "        \n",
    "        # 알림 임계값\n",
    "        self.alert_thresholds = {\n",
    "            \"cpu_percent\": 80.0,\n",
    "            \"memory_percent\": 85.0,\n",
    "            \"response_time\": 5.0,  # 초\n",
    "            \"error_rate\": 0.05     # 5%\n",
    "        }\n",
    "        \n",
    "        # 데이터베이스 초기화\n",
    "        self._init_database()\n",
    "        \n",
    "        # 모니터링 스레드\n",
    "        self.monitoring_active = False\n",
    "        self.monitor_thread = None\n",
    "    \n",
    "    def _init_database(self):\n",
    "        \"\"\"\n",
    "        SQLite 데이터베이스 초기화\n",
    "        \"\"\"\n",
    "        try:\n",
    "            conn = sqlite3.connect(self.db_path)\n",
    "            cursor = conn.cursor()\n",
    "            \n",
    "            # 시스템 메트릭 테이블\n",
    "            cursor.execute(\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS system_metrics (\n",
    "                    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                    timestamp DATETIME,\n",
    "                    cpu_percent REAL,\n",
    "                    memory_percent REAL,\n",
    "                    disk_usage REAL,\n",
    "                    network_sent INTEGER,\n",
    "                    network_recv INTEGER\n",
    "                )\n",
    "            \"\"\")\n",
    "            \n",
    "            # 응답 시간 메트릭 테이블\n",
    "            cursor.execute(\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS response_metrics (\n",
    "                    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                    timestamp DATETIME,\n",
    "                    response_time REAL,\n",
    "                    tokens_used INTEGER,\n",
    "                    model TEXT,\n",
    "                    cached BOOLEAN,\n",
    "                    error TEXT\n",
    "                )\n",
    "            \"\"\")\n",
    "            \n",
    "            conn.commit()\n",
    "            conn.close()\n",
    "            \n",
    "            self.logger.info(\"데이터베이스 초기화 완료\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"데이터베이스 초기화 오류: {e}\")\n",
    "    \n",
    "    def collect_system_metrics(self) -> SystemMetrics:\n",
    "        \"\"\"\n",
    "        시스템 메트릭 수집\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # CPU 사용률\n",
    "            cpu_percent = psutil.cpu_percent(interval=1)\n",
    "            \n",
    "            # 메모리 사용률\n",
    "            memory = psutil.virtual_memory()\n",
    "            memory_percent = memory.percent\n",
    "            \n",
    "            # 디스크 사용률\n",
    "            disk = psutil.disk_usage('/')\n",
    "            disk_usage = (disk.used / disk.total) * 100\n",
    "            \n",
    "            # 네트워크 I/O\n",
    "            network = psutil.net_io_counters()\n",
    "            network_io = {\n",
    "                \"bytes_sent\": network.bytes_sent,\n",
    "                \"bytes_recv\": network.bytes_recv\n",
    "            }\n",
    "            \n",
    "            metrics = SystemMetrics(\n",
    "                cpu_percent=cpu_percent,\n",
    "                memory_percent=memory_percent,\n",
    "                disk_usage=disk_usage,\n",
    "                network_io=network_io\n",
    "            )\n",
    "            \n",
    "            return metrics\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"시스템 메트릭 수집 오류: {e}\")\n",
    "            return SystemMetrics()\n",
    "    \n",
    "    def store_metrics(self, metrics: SystemMetrics):\n",
    "        \"\"\"\n",
    "        메트릭을 데이터베이스에 저장\n",
    "        \"\"\"\n",
    "        try:\n",
    "            conn = sqlite3.connect(self.db_path)\n",
    "            cursor = conn.cursor()\n",
    "            \n",
    "            cursor.execute(\"\"\"\n",
    "                INSERT INTO system_metrics \n",
    "                (timestamp, cpu_percent, memory_percent, disk_usage, \n",
    "                 network_sent, network_recv)\n",
    "                VALUES (?, ?, ?, ?, ?, ?)\n",
    "            \"\"\", (\n",
    "                metrics.timestamp.isoformat(),\n",
    "                metrics.cpu_percent,\n",
    "                metrics.memory_percent,\n",
    "                metrics.disk_usage,\n",
    "                metrics.network_io.get('bytes_sent', 0),\n",
    "                metrics.network_io.get('bytes_recv', 0)\n",
    "            ))\n",
    "            \n",
    "            conn.commit()\n",
    "            conn.close()\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"메트릭 저장 오류: {e}\")\n",
    "    \n",
    "    def record_response_time(self, response_time: float, \n",
    "                           tokens_used: int = 0,\n",
    "                           model: str = \"\",\n",
    "                           cached: bool = False,\n",
    "                           error: str = None):\n",
    "        \"\"\"\n",
    "        응답 시간 메트릭 기록\n",
    "        \"\"\"\n",
    "        try:\n",
    "            conn = sqlite3.connect(self.db_path)\n",
    "            cursor = conn.cursor()\n",
    "            \n",
    "            cursor.execute(\"\"\"\n",
    "                INSERT INTO response_metrics \n",
    "                (timestamp, response_time, tokens_used, model, cached, error)\n",
    "                VALUES (?, ?, ?, ?, ?, ?)\n",
    "            \"\"\", (\n",
    "                datetime.now().isoformat(),\n",
    "                response_time,\n",
    "                tokens_used,\n",
    "                model,\n",
    "                cached,\n",
    "                error\n",
    "            ))\n",
    "            \n",
    "            conn.commit()\n",
    "            conn.close()\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"응답 시간 기록 오류: {e}\")\n",
    "    \n",
    "    def check_alerts(self, metrics: SystemMetrics) -> List[str]:\n",
    "        \"\"\"\n",
    "        알림 조건 확인\n",
    "        \"\"\"\n",
    "        alerts = []\n",
    "        \n",
    "        if metrics.cpu_percent > self.alert_thresholds[\"cpu_percent\"]:\n",
    "            alerts.append(f\"높은 CPU 사용률: {metrics.cpu_percent:.1f}%\")\n",
    "        \n",
    "        if metrics.memory_percent > self.alert_thresholds[\"memory_percent\"]:\n",
    "            alerts.append(f\"높은 메모리 사용률: {metrics.memory_percent:.1f}%\")\n",
    "        \n",
    "        return alerts\n",
    "    \n",
    "    def start_monitoring(self, interval: int = 30):\n",
    "        \"\"\"\n",
    "        모니터링 시작\n",
    "        \"\"\"\n",
    "        if self.monitoring_active:\n",
    "            self.logger.warning(\"모니터링이 이미 실행 중입니다\")\n",
    "            return\n",
    "        \n",
    "        self.monitoring_active = True\n",
    "        \n",
    "        def monitor_loop():\n",
    "            while self.monitoring_active:\n",
    "                try:\n",
    "                    # 메트릭 수집\n",
    "                    metrics = self.collect_system_metrics()\n",
    "                    \n",
    "                    # 저장\n",
    "                    self.store_metrics(metrics)\n",
    "                    self.metrics_buffer.append(metrics)\n",
    "                    \n",
    "                    # 알림 확인\n",
    "                    alerts = self.check_alerts(metrics)\n",
    "                    for alert in alerts:\n",
    "                        self.logger.warning(f\"알림: {alert}\")\n",
    "                    \n",
    "                    time.sleep(interval)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    self.logger.error(f\"모니터링 루프 오류: {e}\")\n",
    "                    time.sleep(interval)\n",
    "        \n",
    "        self.monitor_thread = threading.Thread(target=monitor_loop)\n",
    "        self.monitor_thread.daemon = True\n",
    "        self.monitor_thread.start()\n",
    "        \n",
    "        self.logger.info(f\"모니터링 시작 (간격: {interval}초)\")\n",
    "    \n",
    "    def stop_monitoring(self):\n",
    "        \"\"\"\n",
    "        모니터링 중지\n",
    "        \"\"\"\n",
    "        self.monitoring_active = False\n",
    "        if self.monitor_thread:\n",
    "            self.monitor_thread.join(timeout=5)\n",
    "        self.logger.info(\"모니터링 중지\")\n",
    "    \n",
    "    def get_recent_metrics(self, hours: int = 1) -> List[SystemMetrics]:\n",
    "        \"\"\"\n",
    "        최근 메트릭 조회\n",
    "        \"\"\"\n",
    "        cutoff_time = datetime.now() - timedelta(hours=hours)\n",
    "        return [m for m in self.metrics_buffer \n",
    "                if m.timestamp > cutoff_time]\n",
    "\n",
    "# 성능 모니터 테스트\n",
    "performance_monitor = PerformanceMonitor()\n",
    "\n",
    "# 현재 시스템 메트릭 수집\n",
    "current_metrics = performance_monitor.collect_system_metrics()\n",
    "print(f\"현재 시스템 상태:\")\n",
    "print(f\"  CPU: {current_metrics.cpu_percent:.1f}%\")\n",
    "print(f\"  메모리: {current_metrics.memory_percent:.1f}%\")\n",
    "print(f\"  디스크: {current_metrics.disk_usage:.1f}%\")\n",
    "\n",
    "# 알림 확인\n",
    "alerts = performance_monitor.check_alerts(current_metrics)\n",
    "if alerts:\n",
    "    print(f\"알림: {alerts}\")\n",
    "else:\n",
    "    print(\"시스템 정상\")\n",
    "\n",
    "# 응답 시간 기록\n",
    "performance_monitor.record_response_time(1.25, tokens_used=150, \n",
    "                                       model=\"gpt-3.5-turbo\", cached=True)\n",
    "print(\"응답 시간 메트릭 기록 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "performance-analysis",
   "metadata": {},
   "source": [
    "## 5. 성능 분석\n",
    "\n",
    "### 5.1 성능 분석 도구\n",
    "수집된 메트릭을 분석하고 시각화하는 도구를 구현합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "performance-analyzer",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerformanceAnalyzer:\n",
    "    def __init__(self, monitor: PerformanceMonitor):\n",
    "        \"\"\"\n",
    "        성능 분석기 초기화\n",
    "        \"\"\"\n",
    "        self.monitor = monitor\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "    \n",
    "    def analyze_response_times(self, hours: int = 24) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        응답 시간 분석\n",
    "        \"\"\"\n",
    "        try:\n",
    "            conn = sqlite3.connect(self.monitor.db_path)\n",
    "            \n",
    "            # 최근 N시간 데이터 조회\n",
    "            query = \"\"\"\n",
    "                SELECT response_time, tokens_used, model, cached, error\n",
    "                FROM response_metrics\n",
    "                WHERE timestamp >= datetime('now', '-{} hours')\n",
    "                ORDER BY timestamp DESC\n",
    "            \"\"\".format(hours)\n",
    "            \n",
    "            df = pd.read_sql_query(query, conn)\n",
    "            conn.close()\n",
    "            \n",
    "            if df.empty:\n",
    "                return {\"message\": \"분석할 데이터가 없습니다\"}\n",
    "            \n",
    "            # 기본 통계\n",
    "            response_times = df['response_time']\n",
    "            analysis = {\n",
    "                \"total_requests\": len(df),\n",
    "                \"avg_response_time\": response_times.mean(),\n",
    "                \"median_response_time\": response_times.median(),\n",
    "                \"p95_response_time\": response_times.quantile(0.95),\n",
    "                \"p99_response_time\": response_times.quantile(0.99),\n",
    "                \"min_response_time\": response_times.min(),\n",
    "                \"max_response_time\": response_times.max()\n",
    "            }\n",
    "            \n",
    "            # 캐시 히트율\n",
    "            cache_hits = df['cached'].sum()\n",
    "            analysis['cache_hit_rate'] = cache_hits / len(df)\n",
    "            \n",
    "            # 에러율\n",
    "            errors = df['error'].notna().sum()\n",
    "            analysis['error_rate'] = errors / len(df)\n",
    "            \n",
    "            # 모델별 분석\n",
    "            model_analysis = {}\n",
    "            for model in df['model'].unique():\n",
    "                model_data = df[df['model'] == model]\n",
    "                model_analysis[model] = {\n",
    "                    \"count\": len(model_data),\n",
    "                    \"avg_response_time\": model_data['response_time'].mean(),\n",
    "                    \"avg_tokens\": model_data['tokens_used'].mean()\n",
    "                }\n",
    "            \n",
    "            analysis['by_model'] = model_analysis\n",
    "            \n",
    "            return analysis\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"응답 시간 분석 오류: {e}\")\n",
    "            return {\"error\": str(e)}\n",
    "    \n",
    "    def analyze_system_performance(self, hours: int = 24) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        시스템 성능 분석\n",
    "        \"\"\"\n",
    "        try:\n",
    "            conn = sqlite3.connect(self.monitor.db_path)\n",
    "            \n",
    "            query = \"\"\"\n",
    "                SELECT timestamp, cpu_percent, memory_percent, disk_usage\n",
    "                FROM system_metrics\n",
    "                WHERE timestamp >= datetime('now', '-{} hours')\n",
    "                ORDER BY timestamp\n",
    "            \"\"\".format(hours)\n",
    "            \n",
    "            df = pd.read_sql_query(query, conn)\n",
    "            conn.close()\n",
    "            \n",
    "            if df.empty:\n",
    "                return {\"message\": \"분석할 데이터가 없습니다\"}\n",
    "            \n",
    "            analysis = {\n",
    "                \"cpu\": {\n",
    "                    \"avg\": df['cpu_percent'].mean(),\n",
    "                    \"max\": df['cpu_percent'].max(),\n",
    "                    \"min\": df['cpu_percent'].min(),\n",
    "                    \"std\": df['cpu_percent'].std()\n",
    "                },\n",
    "                \"memory\": {\n",
    "                    \"avg\": df['memory_percent'].mean(),\n",
    "                    \"max\": df['memory_percent'].max(),\n",
    "                    \"min\": df['memory_percent'].min(),\n",
    "                    \"std\": df['memory_percent'].std()\n",
    "                },\n",
    "                \"disk\": {\n",
    "                    \"current\": df['disk_usage'].iloc[-1],\n",
    "                    \"trend\": \"increasing\" if df['disk_usage'].iloc[-1] > df['disk_usage'].iloc[0] else \"stable\"\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            return analysis\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"시스템 성능 분석 오류: {e}\")\n",
    "            return {\"error\": str(e)}\n",
    "    \n",
    "    def generate_performance_report(self) -> str:\n",
    "        \"\"\"\n",
    "        성능 리포트 생성\n",
    "        \"\"\"\n",
    "        response_analysis = self.analyze_response_times()\n",
    "        system_analysis = self.analyze_system_performance()\n",
    "        \n",
    "        report = []\n",
    "        report.append(\"# 성능 분석 리포트\")\n",
    "        report.append(f\"생성 시간: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        report.append(\"\")\n",
    "        \n",
    "        # 응답 시간 분석\n",
    "        if \"error\" not in response_analysis:\n",
    "            report.append(\"## 응답 시간 분석\")\n",
    "            report.append(f\"- 총 요청 수: {response_analysis.get('total_requests', 0):,}\")\n",
    "            report.append(f\"- 평균 응답시간: {response_analysis.get('avg_response_time', 0):.3f}초\")\n",
    "            report.append(f\"- 95% 응답시간: {response_analysis.get('p95_response_time', 0):.3f}초\")\n",
    "            report.append(f\"- 캐시 히트율: {response_analysis.get('cache_hit_rate', 0):.1%}\")\n",
    "            report.append(f\"- 에러율: {response_analysis.get('error_rate', 0):.1%}\")\n",
    "            report.append(\"\")\n",
    "        \n",
    "        # 시스템 성능 분석\n",
    "        if \"error\" not in system_analysis:\n",
    "            report.append(\"## 시스템 리소스 분석\")\n",
    "            cpu = system_analysis.get('cpu', {})\n",
    "            memory = system_analysis.get('memory', {})\n",
    "            \n",
    "            report.append(f\"- CPU 평균 사용률: {cpu.get('avg', 0):.1f}%\")\n",
    "            report.append(f\"- CPU 최대 사용률: {cpu.get('max', 0):.1f}%\")\n",
    "            report.append(f\"- 메모리 평균 사용률: {memory.get('avg', 0):.1f}%\")\n",
    "            report.append(f\"- 메모리 최대 사용률: {memory.get('max', 0):.1f}%\")\n",
    "            report.append(\"\")\n",
    "        \n",
    "        # 권장사항\n",
    "        report.append(\"## 권장사항\")\n",
    "        \n",
    "        if response_analysis.get('cache_hit_rate', 0) < 0.5:\n",
    "            report.append(\"- 캐시 히트율이 낮습니다. 캐싱 전략을 검토하세요.\")\n",
    "        \n",
    "        if response_analysis.get('avg_response_time', 0) > 3.0:\n",
    "            report.append(\"- 평균 응답시간이 높습니다. 최적화를 고려하세요.\")\n",
    "        \n",
    "        if system_analysis.get('cpu', {}).get('avg', 0) > 70:\n",
    "            report.append(\"- CPU 사용률이 높습니다. 스케일링을 검토하세요.\")\n",
    "        \n",
    "        if system_analysis.get('memory', {}).get('avg', 0) > 80:\n",
    "            report.append(\"- 메모리 사용률이 높습니다. 메모리 최적화가 필요합니다.\")\n",
    "        \n",
    "        return \"\\n\".join(report)\n",
    "    \n",
    "    def plot_performance_charts(self):\n",
    "        \"\"\"\n",
    "        성능 차트 생성\n",
    "        \"\"\"\n",
    "        try:\n",
    "            conn = sqlite3.connect(self.monitor.db_path)\n",
    "            \n",
    "            # 응답 시간 데이터\n",
    "            response_df = pd.read_sql_query(\"\"\"\n",
    "                SELECT timestamp, response_time, cached\n",
    "                FROM response_metrics\n",
    "                WHERE timestamp >= datetime('now', '-24 hours')\n",
    "                ORDER BY timestamp\n",
    "            \"\"\", conn)\n",
    "            \n",
    "            # 시스템 메트릭 데이터\n",
    "            system_df = pd.read_sql_query(\"\"\"\n",
    "                SELECT timestamp, cpu_percent, memory_percent\n",
    "                FROM system_metrics\n",
    "                WHERE timestamp >= datetime('now', '-24 hours')\n",
    "                ORDER BY timestamp\n",
    "            \"\"\", conn)\n",
    "            \n",
    "            conn.close()\n",
    "            \n",
    "            # 차트 생성\n",
    "            fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "            \n",
    "            # 응답 시간 분포\n",
    "            if not response_df.empty:\n",
    "                axes[0, 0].hist(response_df['response_time'], bins=30, alpha=0.7)\n",
    "                axes[0, 0].set_title('응답 시간 분포')\n",
    "                axes[0, 0].set_xlabel('응답 시간 (초)')\n",
    "                axes[0, 0].set_ylabel('빈도')\n",
    "            \n",
    "            # 캐시 히트 비율\n",
    "            if not response_df.empty:\n",
    "                cache_counts = response_df['cached'].value_counts()\n",
    "                axes[0, 1].pie(cache_counts.values, labels=['캐시 미스', '캐시 히트'], \n",
    "                             autopct='%1.1f%%')\n",
    "                axes[0, 1].set_title('캐시 히트율')\n",
    "            \n",
    "            # CPU 사용률 시계열\n",
    "            if not system_df.empty:\n",
    "                system_df['timestamp'] = pd.to_datetime(system_df['timestamp'])\n",
    "                axes[1, 0].plot(system_df['timestamp'], system_df['cpu_percent'])\n",
    "                axes[1, 0].set_title('CPU 사용률 추이')\n",
    "                axes[1, 0].set_ylabel('CPU %')\n",
    "                axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "            \n",
    "            # 메모리 사용률 시계열\n",
    "            if not system_df.empty:\n",
    "                axes[1, 1].plot(system_df['timestamp'], system_df['memory_percent'], \n",
    "                              color='orange')\n",
    "                axes[1, 1].set_title('메모리 사용률 추이')\n",
    "                axes[1, 1].set_ylabel('메모리 %')\n",
    "                axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            return fig\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"차트 생성 오류: {e}\")\n",
    "            return None\n",
    "\n",
    "# 성능 분석기 테스트\n",
    "analyzer = PerformanceAnalyzer(performance_monitor)\n",
    "\n",
    "# 몇 개의 샘플 데이터 추가\n",
    "for i in range(5):\n",
    "    performance_monitor.record_response_time(\n",
    "        response_time=np.random.normal(2.0, 0.5),\n",
    "        tokens_used=np.random.randint(50, 200),\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        cached=np.random.choice([True, False])\n",
    "    )\n",
    "\n",
    "# 분석 실행\n",
    "response_analysis = analyzer.analyze_response_times(hours=1)\n",
    "print(\"응답 시간 분석 결과:\")\n",
    "for key, value in response_analysis.items():\n",
    "    if isinstance(value, dict):\n",
    "        print(f\"  {key}: {value}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "# 성능 리포트 생성\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "report = analyzer.generate_performance_report()\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "streamlit-dashboard",
   "metadata": {},
   "source": [
    "## 6. Streamlit 대시보드\n",
    "\n",
    "### 6.1 실시간 모니터링 대시보드\n",
    "성능 메트릭을 실시간으로 시각화하는 웹 대시보드를 구현합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "streamlit-dashboard",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_monitoring_dashboard():\n",
    "    \"\"\"\n",
    "    Streamlit 모니터링 대시보드 생성\n",
    "    \"\"\"\n",
    "    st.set_page_config(\n",
    "        page_title=\"AI 챗봇 성능 모니터링\",\n",
    "        page_icon=\"📊\",\n",
    "        layout=\"wide\"\n",
    "    )\n",
    "    \n",
    "    st.title(\"🚀 AI 챗봇 성능 모니터링 대시보드\")\n",
    "    \n",
    "    # 사이드바 설정\n",
    "    st.sidebar.header(\"설정\")\n",
    "    \n",
    "    # 모니터링 컴포넌트 초기화\n",
    "    if 'cache_manager' not in st.session_state:\n",
    "        st.session_state.cache_manager = CacheManager()\n",
    "    \n",
    "    if 'performance_monitor' not in st.session_state:\n",
    "        st.session_state.performance_monitor = PerformanceMonitor()\n",
    "    \n",
    "    if 'analyzer' not in st.session_state:\n",
    "        st.session_state.analyzer = PerformanceAnalyzer(\n",
    "            st.session_state.performance_monitor\n",
    "        )\n",
    "    \n",
    "    if 'chatbot' not in st.session_state:\n",
    "        st.session_state.chatbot = AsyncChatbot(\n",
    "            st.session_state.cache_manager\n",
    "        )\n",
    "    \n",
    "    # 실시간 메트릭 표시\n",
    "    col1, col2, col3, col4 = st.columns(4)\n",
    "    \n",
    "    # 현재 시스템 상태\n",
    "    current_metrics = st.session_state.performance_monitor.collect_system_metrics()\n",
    "    \n",
    "    with col1:\n",
    "        st.metric(\n",
    "            label=\"CPU 사용률\",\n",
    "            value=f\"{current_metrics.cpu_percent:.1f}%\",\n",
    "            delta=None\n",
    "        )\n",
    "    \n",
    "    with col2:\n",
    "        st.metric(\n",
    "            label=\"메모리 사용률\",\n",
    "            value=f\"{current_metrics.memory_percent:.1f}%\",\n",
    "            delta=None\n",
    "        )\n",
    "    \n",
    "    with col3:\n",
    "        cache_metrics = st.session_state.cache_manager.get_metrics()\n",
    "        st.metric(\n",
    "            label=\"캐시 히트율\",\n",
    "            value=f\"{cache_metrics.hit_rate:.1%}\",\n",
    "            delta=None\n",
    "        )\n",
    "    \n",
    "    with col4:\n",
    "        st.metric(\n",
    "            label=\"활성 연결\",\n",
    "            value=f\"{st.session_state.chatbot.active_requests}\",\n",
    "            delta=None\n",
    "        )\n",
    "    \n",
    "    # 탭 구성\n",
    "    tab1, tab2, tab3, tab4 = st.tabs([\"💬 챗봇 테스트\", \"📈 성능 분석\", \"🔧 캐시 관리\", \"📊 시스템 모니터링\"])\n",
    "    \n",
    "    with tab1:\n",
    "        st.header(\"챗봇 성능 테스트\")\n",
    "        \n",
    "        # 챗봇 설정\n",
    "        col1, col2 = st.columns(2)\n",
    "        \n",
    "        with col1:\n",
    "            model = st.selectbox(\n",
    "                \"모델 선택\",\n",
    "                [\"gpt-3.5-turbo\", \"gpt-4\", \"gpt-4-turbo\"]\n",
    "            )\n",
    "        \n",
    "        with col2:\n",
    "            use_cache = st.checkbox(\"캐시 사용\", value=True)\n",
    "        \n",
    "        # 채팅 인터페이스\n",
    "        user_input = st.text_area(\"메시지 입력\", height=100)\n",
    "        \n",
    "        if st.button(\"전송\", type=\"primary\"):\n",
    "            if user_input.strip():\n",
    "                with st.spinner(\"응답 생성 중...\"):\n",
    "                    start_time = time.time()\n",
    "                    \n",
    "                    try:\n",
    "                        # 비동기 함수를 동기적으로 실행\n",
    "                        import asyncio\n",
    "                        \n",
    "                        # 새로운 이벤트 루프 생성 (Streamlit 환경)\n",
    "                        try:\n",
    "                            loop = asyncio.get_event_loop()\n",
    "                        except RuntimeError:\n",
    "                            loop = asyncio.new_event_loop()\n",
    "                            asyncio.set_event_loop(loop)\n",
    "                        \n",
    "                        messages = [{\"role\": \"user\", \"content\": user_input}]\n",
    "                        result = loop.run_until_complete(\n",
    "                            st.session_state.chatbot.chat_completion(\n",
    "                                messages, model=model, use_cache=use_cache\n",
    "                            )\n",
    "                        )\n",
    "                        \n",
    "                        response_time = time.time() - start_time\n",
    "                        \n",
    "                        # 결과 표시\n",
    "                        st.success(\"응답 완료!\")\n",
    "                        \n",
    "                        col1, col2 = st.columns([3, 1])\n",
    "                        \n",
    "                        with col1:\n",
    "                            st.text_area(\n",
    "                                \"AI 응답\",\n",
    "                                value=result['response'],\n",
    "                                height=200,\n",
    "                                disabled=True\n",
    "                            )\n",
    "                        \n",
    "                        with col2:\n",
    "                            st.write(\"**메트릭**\")\n",
    "                            st.write(f\"응답시간: {result['duration']:.2f}초\")\n",
    "                            st.write(f\"토큰 사용: {result['usage']['total_tokens']}\")\n",
    "                            st.write(f\"모델: {result['model']}\")\n",
    "                        \n",
    "                        # 성능 메트릭 기록\n",
    "                        st.session_state.performance_monitor.record_response_time(\n",
    "                            response_time=result['duration'],\n",
    "                            tokens_used=result['usage']['total_tokens'],\n",
    "                            model=result['model'],\n",
    "                            cached=False  # 실제 구현에서는 캐시 여부 확인\n",
    "                        )\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        st.error(f\"오류 발생: {e}\")\n",
    "                        \n",
    "                        # 에러 메트릭 기록\n",
    "                        st.session_state.performance_monitor.record_response_time(\n",
    "                            response_time=time.time() - start_time,\n",
    "                            error=str(e)\n",
    "                        )\n",
    "    \n",
    "    with tab2:\n",
    "        st.header(\"성능 분석\")\n",
    "        \n",
    "        # 분석 기간 선택\n",
    "        analysis_hours = st.selectbox(\n",
    "            \"분석 기간\",\n",
    "            [1, 6, 12, 24, 48, 72],\n",
    "            index=3\n",
    "        )\n",
    "        \n",
    "        if st.button(\"분석 실행\"):\n",
    "            with st.spinner(\"분석 중...\"):\n",
    "                # 응답 시간 분석\n",
    "                response_analysis = st.session_state.analyzer.analyze_response_times(\n",
    "                    hours=analysis_hours\n",
    "                )\n",
    "                \n",
    "                if \"error\" not in response_analysis:\n",
    "                    col1, col2 = st.columns(2)\n",
    "                    \n",
    "                    with col1:\n",
    "                        st.subheader(\"응답 시간 통계\")\n",
    "                        \n",
    "                        metrics_data = {\n",
    "                            \"메트릭\": [\"평균\", \"중앙값\", \"95%\", \"99%\", \"최소\", \"최대\"],\n",
    "                            \"값 (초)\": [\n",
    "                                f\"{response_analysis.get('avg_response_time', 0):.3f}\",\n",
    "                                f\"{response_analysis.get('median_response_time', 0):.3f}\",\n",
    "                                f\"{response_analysis.get('p95_response_time', 0):.3f}\",\n",
    "                                f\"{response_analysis.get('p99_response_time', 0):.3f}\",\n",
    "                                f\"{response_analysis.get('min_response_time', 0):.3f}\",\n",
    "                                f\"{response_analysis.get('max_response_time', 0):.3f}\"\n",
    "                            ]\n",
    "                        }\n",
    "                        \n",
    "                        st.table(pd.DataFrame(metrics_data))\n",
    "                    \n",
    "                    with col2:\n",
    "                        st.subheader(\"성능 지표\")\n",
    "                        \n",
    "                        st.metric(\n",
    "                            \"총 요청 수\",\n",
    "                            f\"{response_analysis.get('total_requests', 0):,}\"\n",
    "                        )\n",
    "                        \n",
    "                        st.metric(\n",
    "                            \"캐시 히트율\",\n",
    "                            f\"{response_analysis.get('cache_hit_rate', 0):.1%}\"\n",
    "                        )\n",
    "                        \n",
    "                        st.metric(\n",
    "                            \"에러율\",\n",
    "                            f\"{response_analysis.get('error_rate', 0):.1%}\"\n",
    "                        )\n",
    "                    \n",
    "                    # 모델별 분석\n",
    "                    if response_analysis.get('by_model'):\n",
    "                        st.subheader(\"모델별 성능\")\n",
    "                        \n",
    "                        model_data = []\n",
    "                        for model, stats in response_analysis['by_model'].items():\n",
    "                            model_data.append({\n",
    "                                \"모델\": model,\n",
    "                                \"요청 수\": stats['count'],\n",
    "                                \"평균 응답시간\": f\"{stats['avg_response_time']:.3f}초\",\n",
    "                                \"평균 토큰\": f\"{stats['avg_tokens']:.0f}\"\n",
    "                            })\n",
    "                        \n",
    "                        st.table(pd.DataFrame(model_data))\n",
    "                \n",
    "                else:\n",
    "                    st.warning(\"분석할 데이터가 충분하지 않습니다.\")\n",
    "        \n",
    "        # 성능 리포트\n",
    "        if st.button(\"성능 리포트 생성\"):\n",
    "            report = st.session_state.analyzer.generate_performance_report()\n",
    "            st.text_area(\"성능 리포트\", value=report, height=400)\n",
    "    \n",
    "    with tab3:\n",
    "        st.header(\"캐시 관리\")\n",
    "        \n",
    "        # 캐시 메트릭\n",
    "        cache_metrics = st.session_state.cache_manager.get_metrics()\n",
    "        \n",
    "        col1, col2, col3 = st.columns(3)\n",
    "        \n",
    "        with col1:\n",
    "            st.metric(\"히트 수\", cache_metrics.hits)\n",
    "        \n",
    "        with col2:\n",
    "            st.metric(\"미스 수\", cache_metrics.misses)\n",
    "        \n",
    "        with col3:\n",
    "            st.metric(\"캐시 크기\", cache_metrics.total_size)\n",
    "        \n",
    "        # 캐시 히트율 차트\n",
    "        if cache_metrics.hits + cache_metrics.misses > 0:\n",
    "            hit_rate_data = pd.DataFrame({\n",
    "                \"상태\": [\"히트\", \"미스\"],\n",
    "                \"횟수\": [cache_metrics.hits, cache_metrics.misses]\n",
    "            })\n",
    "            \n",
    "            st.subheader(\"캐시 히트율\")\n",
    "            st.bar_chart(hit_rate_data.set_index(\"상태\"))\n",
    "        \n",
    "        # 캐시 관리 기능\n",
    "        st.subheader(\"캐시 관리\")\n",
    "        \n",
    "        col1, col2 = st.columns(2)\n",
    "        \n",
    "        with col1:\n",
    "            if st.button(\"캐시 통계 새로고침\"):\n",
    "                st.experimental_rerun()\n",
    "        \n",
    "        with col2:\n",
    "            if st.button(\"로컬 캐시 클리어\"):\n",
    "                st.session_state.cache_manager.local_cache.clear()\n",
    "                st.session_state.cache_manager.local_cache_order.clear()\n",
    "                st.success(\"로컬 캐시가 클리어되었습니다.\")\n",
    "    \n",
    "    with tab4:\n",
    "        st.header(\"시스템 모니터링\")\n",
    "        \n",
    "        # 실시간 시스템 메트릭\n",
    "        current_metrics = st.session_state.performance_monitor.collect_system_metrics()\n",
    "        \n",
    "        col1, col2 = st.columns(2)\n",
    "        \n",
    "        with col1:\n",
    "            st.subheader(\"CPU 및 메모리\")\n",
    "            \n",
    "            # CPU 사용률 게이지\n",
    "            cpu_color = \"red\" if current_metrics.cpu_percent > 80 else \"orange\" if current_metrics.cpu_percent > 60 else \"green\"\n",
    "            st.metric(\"CPU 사용률\", f\"{current_metrics.cpu_percent:.1f}%\")\n",
    "            st.progress(current_metrics.cpu_percent / 100)\n",
    "            \n",
    "            # 메모리 사용률 게이지\n",
    "            memory_color = \"red\" if current_metrics.memory_percent > 80 else \"orange\" if current_metrics.memory_percent > 60 else \"green\"\n",
    "            st.metric(\"메모리 사용률\", f\"{current_metrics.memory_percent:.1f}%\")\n",
    "            st.progress(current_metrics.memory_percent / 100)\n",
    "        \n",
    "        with col2:\n",
    "            st.subheader(\"디스크 및 네트워크\")\n",
    "            \n",
    "            st.metric(\"디스크 사용률\", f\"{current_metrics.disk_usage:.1f}%\")\n",
    "            \n",
    "            if current_metrics.network_io:\n",
    "                st.metric(\n",
    "                    \"네트워크 송신\",\n",
    "                    f\"{current_metrics.network_io.get('bytes_sent', 0) / 1024 / 1024:.1f} MB\"\n",
    "                )\n",
    "                st.metric(\n",
    "                    \"네트워크 수신\",\n",
    "                    f\"{current_metrics.network_io.get('bytes_recv', 0) / 1024 / 1024:.1f} MB\"\n",
    "                )\n",
    "        \n",
    "        # 알림 확인\n",
    "        alerts = st.session_state.performance_monitor.check_alerts(current_metrics)\n",
    "        if alerts:\n",
    "            st.warning(\"⚠️ 시스템 알림\")\n",
    "            for alert in alerts:\n",
    "                st.write(f\"• {alert}\")\n",
    "        else:\n",
    "            st.success(\"✅ 시스템 정상\")\n",
    "        \n",
    "        # 모니터링 제어\n",
    "        st.subheader(\"모니터링 제어\")\n",
    "        \n",
    "        col1, col2 = st.columns(2)\n",
    "        \n",
    "        with col1:\n",
    "            monitoring_interval = st.slider(\n",
    "                \"모니터링 간격 (초)\",\n",
    "                min_value=5,\n",
    "                max_value=300,\n",
    "                value=30\n",
    "            )\n",
    "        \n",
    "        with col2:\n",
    "            if not st.session_state.performance_monitor.monitoring_active:\n",
    "                if st.button(\"모니터링 시작\", type=\"primary\"):\n",
    "                    st.session_state.performance_monitor.start_monitoring(\n",
    "                        interval=monitoring_interval\n",
    "                    )\n",
    "                    st.success(\"모니터링이 시작되었습니다.\")\n",
    "            else:\n",
    "                if st.button(\"모니터링 중지\", type=\"secondary\"):\n",
    "                    st.session_state.performance_monitor.stop_monitoring()\n",
    "                    st.info(\"모니터링이 중지되었습니다.\")\n",
    "    \n",
    "    # 자동 새로고침\n",
    "    if st.sidebar.checkbox(\"자동 새로고침 (10초)\"):\n",
    "        time.sleep(10)\n",
    "        st.experimental_rerun()\n",
    "\n",
    "# 대시보드 실행 안내\n",
    "st.markdown(\"\"\"\n",
    "### 🚀 Streamlit 대시보드 실행 방법\n",
    "\n",
    "위의 코드를 별도 파일 (`monitoring_dashboard.py`)로 저장한 후, 다음 명령어로 실행하세요:\n",
    "\n",
    "```bash\n",
    "streamlit run monitoring_dashboard.py\n",
    "```\n",
    "\n",
    "대시보드에서 제공하는 기능:\n",
    "- **실시간 시스템 모니터링**: CPU, 메모리, 디스크 사용률\n",
    "- **챗봇 성능 테스트**: 다양한 모델로 응답 성능 테스트\n",
    "- **캐시 관리**: 캐시 히트율 및 관리 기능\n",
    "- **성능 분석**: 상세한 성능 메트릭 분석 및 리포트\n",
    "\"\"\")\n",
    "\n",
    "print(\"Streamlit 대시보드 코드 생성 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assignments",
   "metadata": {},
   "source": [
    "## 7. 실습 과제\n",
    "\n",
    "### 과제 1: 고급 캐싱 전략 구현\n",
    "1. **LFU(Least Frequently Used) 캐시 정책 구현**\n",
    "   - 사용 빈도를 추적하는 캐싱 시스템\n",
    "   - 메모리 효율성 비교 분석\n",
    "\n",
    "2. **분산 캐싱 시스템 구현**\n",
    "   - 여러 Redis 인스턴스를 활용한 샤딩\n",
    "   - 일관성 해싱을 통한 부하 분산\n",
    "\n",
    "### 과제 2: 비동기 성능 최적화\n",
    "1. **커넥션 풀링 구현**\n",
    "   - OpenAI API 연결을 위한 커넥션 풀\n",
    "   - 동시 요청 처리 성능 향상\n",
    "\n",
    "2. **백프레셔(Backpressure) 제어**\n",
    "   - 과부하 상황에서의 요청 제어\n",
    "   - 큐잉 시스템 구현\n",
    "\n",
    "### 과제 3: 모니터링 고도화\n",
    "1. **분산 트레이싱 구현**\n",
    "   - OpenTelemetry를 사용한 요청 추적\n",
    "   - 마이크로서비스 간 호출 추적\n",
    "\n",
    "2. **실시간 알림 시스템**\n",
    "   - Slack/Discord 웹훅 연동\n",
    "   - 임계값 기반 자동 알림\n",
    "\n",
    "### 과제 4: 성능 벤치마킹\n",
    "1. **부하 테스트 도구 개발**\n",
    "   - 동시 사용자 시뮬레이션\n",
    "   - 성능 메트릭 수집 및 분석\n",
    "\n",
    "2. **A/B 테스트 프레임워크**\n",
    "   - 다양한 최적화 기법 비교\n",
    "   - 통계적 유의성 검증\n",
    "\n",
    "### 제출 방법\n",
    "```bash\n",
    "# 과제 디렉토리 생성\n",
    "mkdir lesson6_assignments\n",
    "cd lesson6_assignments\n",
    "\n",
    "# 각 과제별 구현 파일\n",
    "touch advanced_caching.py\n",
    "touch async_optimization.py\n",
    "touch monitoring_advanced.py\n",
    "touch performance_benchmark.py\n",
    "\n",
    "# 실행 결과 보고서\n",
    "touch performance_report.md\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## 📋 학습 정리\n",
    "\n",
    "### 배운 내용\n",
    "1. **캐싱 시스템**: 다층 캐싱을 통한 응답 속도 향상\n",
    "2. **비동기 처리**: 동시 요청 처리를 통한 처리량 증대\n",
    "3. **토큰 최적화**: 비용 효율적인 AI 모델 사용\n",
    "4. **모니터링**: 실시간 성능 추적 및 분석\n",
    "5. **대시보드**: 시각적 성능 모니터링 도구\n",
    "\n",
    "### 핵심 개념\n",
    "- **성능 메트릭**: 응답시간, 처리량, 에러율, 리소스 사용률\n",
    "- **캐싱 전략**: LRU, 다층 캐싱, TTL 관리\n",
    "- **비동기 패턴**: 세마포어, 배치 처리, 커넥션 풀\n",
    "- **모니터링**: 메트릭 수집, 알림, 대시보드\n",
    "\n",
    "### 다음 단계\n",
    "다음 차시에서는 **배포 및 통합**을 다룹니다:\n",
    "- Docker 컨테이너화\n",
    "- FastAPI REST API 구현\n",
    "- CI/CD 파이프라인 구축\n",
    "- 프로덕션 환경 배포"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}