{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🤖 AI 챗봇 멘토링 - 1차시: 기본 챗봇 구현\n",
    "\n",
    "## 🎯 학습 목표\n",
    "- OpenAI API 연동 방법 이해\n",
    "- 스트리밍 응답 구현\n",
    "- 토큰 사용량 모니터링\n",
    "- API 키 로테이션 로직\n",
    "- 실무용 로깅 시스템\n",
    "\n",
    "## 📋 사전 준비사항\n",
    "1. OpenAI API 키 발급\n",
    "2. Python 3.8+ 설치\n",
    "3. 필요한 라이브러리 설치 (`pip install -r requirements.txt`)\n",
    "4. `.env` 파일 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1️⃣ 환경 설정 및 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import logging\n",
    "from typing import Iterator, Dict, Any, Optional, List\n",
    "from datetime import datetime, timedelta\n",
    "from dataclasses import dataclass, asdict\n",
    "from functools import wraps\n",
    "from openai import OpenAI\n",
    "import redis\n",
    "\n",
    "# 환경변수 로드 (개발용)\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "print(\"✅ 라이브러리 임포트 완료\")\n",
    "print(f\"📍 현재 작업 디렉토리: {os.getcwd()}\")\n",
    "print(f\"🔑 API 키 설정 상태: {'✅ 설정됨' if os.getenv('OPENAI_API_KEY') else '❌ 미설정'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2️⃣ 로깅 시스템 설정\n",
    "\n",
    "실무에서는 **상세한 로깅**이 필수입니다. API 호출, 토큰 사용량, 에러 상황을 모두 추적해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로깅 설정\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.StreamHandler(),  # 콘솔 출력\n",
    "        logging.FileHandler('chatbot_lesson1.log', encoding='utf-8')  # 파일 저장\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def log_function_call(func):\n",
    "    \"\"\"함수 호출을 로깅하는 데코레이터\"\"\"\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        logger.debug(f\"[ENTER] {func.__name__}\", extra={\n",
    "            \"function\": func.__name__, \n",
    "            \"args_count\": len(args),\n",
    "            \"kwargs_keys\": list(kwargs.keys())\n",
    "        })\n",
    "        \n",
    "        try:\n",
    "            result = func(*args, **kwargs)\n",
    "            elapsed = time.time() - start_time\n",
    "            logger.debug(f\"[EXIT] {func.__name__} - SUCCESS ({elapsed:.3f}s)\")\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            elapsed = time.time() - start_time\n",
    "            logger.error(f\"[EXIT] {func.__name__} - ERROR: {str(e)} ({elapsed:.3f}s)\")\n",
    "            raise\n",
    "    return wrapper\n",
    "\n",
    "print(\"✅ 로깅 시스템 설정 완료\")\n",
    "logger.info(\"Jupyter Notebook 실습 시작\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3️⃣ 기본 설정 및 데이터 모델\n",
    "\n",
    "실무에서는 **타입 힌트**와 **데이터 클래스**를 활용해 코드의 안정성을 높입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ChatMessage:\n",
    "    \"\"\"채팅 메시지 구조\"\"\"\n",
    "    role: str  # \"user\" or \"assistant\" or \"system\"\n",
    "    content: str\n",
    "    timestamp: datetime\n",
    "    tokens_used: int = 0\n",
    "    processing_time: float = 0.0\n",
    "    model: str = \"\"\n",
    "\n",
    "# 기본 설정값\n",
    "DEFAULT_CONFIG = {\n",
    "    \"model\": os.getenv(\"OPENAI_MODEL\", \"gpt-4o-mini\"),\n",
    "    \"max_tokens\": int(os.getenv(\"MAX_TOKENS\", \"500\")),\n",
    "    \"temperature\": float(os.getenv(\"TEMPERATURE\", \"0.7\")),\n",
    "    \"api_key\": os.getenv(\"OPENAI_API_KEY\"),\n",
    "    \"daily_token_limit\": int(os.getenv(\"DAILY_TOKEN_LIMIT\", \"10000\"))\n",
    "}\n",
    "\n",
    "# 설정 출력\n",
    "print(\"⚙️ 현재 설정:\")\n",
    "for key, value in DEFAULT_CONFIG.items():\n",
    "    if key == \"api_key\":\n",
    "        display_value = f\"{value[:8]}...{value[-4:]}\" if value else \"❌ 미설정\"\n",
    "    else:\n",
    "        display_value = value\n",
    "    print(f\"  {key}: {display_value}\")\n",
    "\n",
    "# API 키 검증\n",
    "if not DEFAULT_CONFIG[\"api_key\"]:\n",
    "    print(\"\\n❌ OpenAI API 키가 설정되지 않았습니다!\")\n",
    "    print(\"   다음 중 하나를 실행하세요:\")\n",
    "    print(\"   1. .env 파일에 OPENAI_API_KEY 추가\")\n",
    "    print(\"   2. 환경변수 설정: export OPENAI_API_KEY='your-key'\")\n",
    "    \n",
    "    # 노트북에서 직접 입력 (개발용)\n",
    "    api_key_input = input(\"\\n🔑 API 키를 직접 입력하세요 (선택사항): \")\n",
    "    if api_key_input.strip():\n",
    "        os.environ[\"OPENAI_API_KEY\"] = api_key_input.strip()\n",
    "        DEFAULT_CONFIG[\"api_key\"] = api_key_input.strip()\n",
    "        print(\"✅ API 키가 설정되었습니다.\")\nelse:\n    print(\"✅ API 키 설정 확인\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4️⃣ 토큰 사용량 모니터링 클래스\n",
    "\n",
    "실무에서는 **비용 관리**가 중요합니다. 토큰 사용량을 추적하고 제한을 설정해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenMonitor:\n",
    "    \"\"\"토큰 사용량 모니터링 및 비용 계산\"\"\"\n",
    "    \n",
    "    # 2024년 8월 기준 모델별 토큰당 가격 (USD)\n",
    "    TOKEN_PRICES = {\n",
    "        \"gpt-4o-mini\": {\"input\": 0.00015 / 1000, \"output\": 0.0006 / 1000},\n",
    "        \"gpt-4o\": {\"input\": 0.005 / 1000, \"output\": 0.015 / 1000},\n",
    "        \"gpt-3.5-turbo\": {\"input\": 0.001 / 1000, \"output\": 0.002 / 1000},\n",
    "    }\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.daily_usage = {}  # 사용자별 일일 사용량\n",
    "        self.session_stats = {\n",
    "            \"total_requests\": 0,\n",
    "            \"total_tokens\": 0,\n",
    "            \"total_cost\": 0.0,\n",
    "            \"start_time\": datetime.now()\n",
    "        }\n",
    "        logger.info(\"토큰 모니터 초기화 완료\")\n",
    "    \n",
    "    def calculate_cost(self, model: str, input_tokens: int, output_tokens: int) -> float:\n",
    "        \"\"\"토큰 사용량 기반 비용 계산\"\"\"\n",
    "        if model not in self.TOKEN_PRICES:\n",
    "            logger.warning(f\"알 수 없는 모델: {model}, gpt-4o-mini 가격 적용\")\n",
    "            model = \"gpt-4o-mini\"\n",
    "        \n",
    "        prices = self.TOKEN_PRICES[model]\n",
    "        input_cost = input_tokens * prices[\"input\"]\n",
    "        output_cost = output_tokens * prices[\"output\"]\n",
    "        \n",
    "        return round(input_cost + output_cost, 6)\n",
    "    \n",
    "    @log_function_call\n",
    "    def track_usage(self, user_id: str, model: str, input_tokens: int, \n",
    "                   output_tokens: int, processing_time: float):\n",
    "        \"\"\"사용량 추적 및 저장\"\"\"\n",
    "        total_tokens = input_tokens + output_tokens\n",
    "        cost = self.calculate_cost(model, input_tokens, output_tokens)\n",
    "        today = datetime.now().strftime('%Y-%m-%d')\n",
    "        \n",
    "        # 일일 사용량 업데이트\n",
    "        if user_id not in self.daily_usage:\n",
    "            self.daily_usage[user_id] = {}\n",
    "        if today not in self.daily_usage[user_id]:\n",
    "            self.daily_usage[user_id][today] = {\n",
    "                \"requests\": 0, \"tokens\": 0, \"cost\": 0.0, \"first_request\": datetime.now()\n",
    "            }\n",
    "        \n",
    "        # 통계 업데이트\n",
    "        self.daily_usage[user_id][today][\"requests\"] += 1\n",
    "        self.daily_usage[user_id][today][\"tokens\"] += total_tokens\n",
    "        self.daily_usage[user_id][today][\"cost\"] += cost\n",
    "        \n",
    "        # 세션 통계 업데이트\n",
    "        self.session_stats[\"total_requests\"] += 1\n",
    "        self.session_stats[\"total_tokens\"] += total_tokens\n",
    "        self.session_stats[\"total_cost\"] += cost\n",
    "        \n",
    "        # 상세 로깅\n",
    "        logger.info(\n",
    "            f\"토큰 사용량 추적 - 사용자: {user_id}, 모델: {model}, \"\n",
    "            f\"입력: {input_tokens}, 출력: {output_tokens}, 총합: {total_tokens}, \"\n",
    "            f\"비용: ${cost:.4f}, 처리시간: {processing_time:.2f}초\"\n",
    "        )\n",
    "    \n",
    "    def get_user_stats(self, user_id: str) -> Dict[str, Any]:\n",
    "        \"\"\"사용자 통계 조회\"\"\"\n",
    "        today = datetime.now().strftime('%Y-%m-%d')\n",
    "        \n",
    "        if user_id in self.daily_usage and today in self.daily_usage[user_id]:\n",
    "            stats = self.daily_usage[user_id][today]\n",
    "            return {\n",
    "                \"date\": today,\n",
    "                \"requests\": stats[\"requests\"],\n",
    "                \"tokens_used\": stats[\"tokens\"],\n",
    "                \"cost\": round(stats[\"cost\"], 4),\n",
    "                \"remaining_tokens\": max(0, DEFAULT_CONFIG[\"daily_token_limit\"] - stats[\"tokens\"]),\n",
    "                \"limit_exceeded\": stats[\"tokens\"] >= DEFAULT_CONFIG[\"daily_token_limit\"]\n",
    "            }\n",
    "        \n",
    "        return {\n",
    "            \"date\": today,\n",
    "            \"requests\": 0,\n",
    "            \"tokens_used\": 0,\n",
    "            \"cost\": 0.0,\n",
    "            \"remaining_tokens\": DEFAULT_CONFIG[\"daily_token_limit\"],\n",
    "            \"limit_exceeded\": False\n",
    "        }\n",
    "\n",
    "# 테스트\n",
    "monitor = TokenMonitor()\n",
    "print(\"✅ 토큰 모니터 생성 완료\")\n",
    "\n",
    "# 비용 계산 테스트\n",
    "test_cost = monitor.calculate_cost(\"gpt-4o-mini\", 100, 50)\n",
    "print(f\"💰 테스트 비용 계산 (gpt-4o-mini, 100+50 토큰): ${test_cost:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5️⃣ API 키 로테이션 시스템\n",
    "\n",
    "실무에서는 **안정성**을 위해 여러 API 키를 준비하고 로테이션하는 것이 좋습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class APIKeyRotator:\n",
    "    \"\"\"API 키 로테이션 및 실패 처리\"\"\"\n",
    "    \n",
    "    def __init__(self, primary_key: str, backup_key: Optional[str] = None):\n",
    "        self.primary_key = primary_key\n",
    "        self.backup_key = backup_key\n",
    "        self.current_key = primary_key\n",
    "        self.failure_count = 0\n",
    "        self.last_rotation = datetime.now()\n",
    "        self.max_failures = 3\n",
    "        logger.info(f\"API 키 로테이터 초기화 - 백업 키: {'있음' if backup_key else '없음'}\")\n",
    "    \n",
    "    def get_current_key(self) -> str:\n",
    "        \"\"\"현재 사용할 API 키 반환\"\"\"\n",
    "        return self.current_key\n",
    "    \n",
    "    def handle_api_error(self, error: Exception) -> bool:\n",
    "        \"\"\"\n",
    "        API 에러 처리 및 키 로테이션\n",
    "        \n",
    "        Returns:\n",
    "            bool: 로테이션 성공 여부 (재시도 가능)\n",
    "        \"\"\"\n",
    "        self.failure_count += 1\n",
    "        error_msg = str(error)\n",
    "        \n",
    "        logger.warning(f\"API 호출 실패 ({self.failure_count}/{self.max_failures}): {error_msg}\")\n",
    "        \n",
    "        # Rate limit 또는 반복 실패 시 백업 키로 전환\n",
    "        if (self.failure_count >= self.max_failures and \n",
    "            self.backup_key and self.current_key != self.backup_key):\n",
    "            \n",
    "            logger.info(\"백업 API 키로 전환\")\n",
    "            self.current_key = self.backup_key\n",
    "            self.failure_count = 0\n",
    "            self.last_rotation = datetime.now()\n",
    "            return True\n",
    "        \n",
    "        # 백업 키도 실패하면 쿨다운 후 primary로 복원\n",
    "        if (self.current_key == self.backup_key and \n",
    "            self.failure_count >= self.max_failures):\n",
    "            \n",
    "            cooldown_period = timedelta(minutes=5)\n",
    "            if datetime.now() - self.last_rotation > cooldown_period:\n",
    "                logger.info(\"쿨다운 완료, Primary 키로 복원\")\n",
    "                self.current_key = self.primary_key\n",
    "                self.failure_count = 0\n",
    "                self.last_rotation = datetime.now()\n",
    "                return True\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    def reset_failure_count(self):\n",
    "        \"\"\"성공 시 실패 카운트 리셋\"\"\"\n",
    "        if self.failure_count > 0:\n",
    "            logger.debug(\"API 호출 성공, 실패 카운트 리셋\")\n",
    "            self.failure_count = 0\n",
    "\n",
    "# API 키 로테이터 생성\n",
    "key_rotator = APIKeyRotator(\n",
    "    primary_key=DEFAULT_CONFIG[\"api_key\"],\n",
    "    backup_key=os.getenv(\"OPENAI_BACKUP_API_KEY\")  # 선택사항\n",
    ")\n",
    "\n",
    "print(\"✅ API 키 로테이터 생성 완료\")\n",
    "print(f\"🔑 현재 키: {key_rotator.get_current_key()[:8]}...{key_rotator.get_current_key()[-4:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6️⃣ 기본 챗봇 클래스 구현\n",
    "\n",
    "이제 실제 챗봇을 구현해봅시다. **일반 응답**과 **스트리밍 응답** 두 가지 방식을 지원합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicChatbot:\n",
    "    \"\"\"기본 AI 챗봇 클래스\"\"\"\n",
    "    \n",
    "    def __init__(self, token_monitor: TokenMonitor, key_rotator: APIKeyRotator):\n",
    "        self.token_monitor = token_monitor\n",
    "        self.key_rotator = key_rotator\n",
    "        self.client = None\n",
    "        self._init_openai_client()\n",
    "    \n",
    "    def _init_openai_client(self):\n",
    "        \"\"\"OpenAI 클라이언트 초기화\"\"\"\n",
    "        try:\n",
    "            self.client = OpenAI(api_key=self.key_rotator.get_current_key())\n",
    "            logger.info(\"OpenAI 클라이언트 초기화 완료\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"OpenAI 클라이언트 초기화 실패: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def _refresh_client_if_needed(self):\n",
    "        \"\"\"키 로테이션 후 클라이언트 갱신\"\"\"\n",
    "        current_key = self.key_rotator.get_current_key()\n",
    "        if self.client.api_key != current_key:\n",
    "            self.client.api_key = current_key\n",
    "            logger.info(\"클라이언트 API 키 갱신\")\n",
    "    \n",
    "    @log_function_call\n",
    "    def generate_response(self, messages: List[Dict[str, str]], \n",
    "                         user_id: str = \"anonymous\") -> ChatMessage:\n",
    "        \"\"\"\n",
    "        일반 응답 생성 (비스트리밍)\n",
    "        \n",
    "        Args:\n",
    "            messages: 대화 메시지 리스트 [{'role': 'user', 'content': '...'}, ...]\n",
    "            user_id: 사용자 ID (사용량 추적용)\n",
    "            \n",
    "        Returns:\n",
    "            ChatMessage: 생성된 응답 메시지\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # 사용량 제한 체크\n",
    "        user_stats = self.token_monitor.get_user_stats(user_id)\n",
    "        if user_stats[\"limit_exceeded\"]:\n",
    "            raise Exception(f\"일일 토큰 한도 초과 ({user_stats['tokens_used']} 토큰)\")\n",
    "        \n",
    "        try:\n",
    "            self._refresh_client_if_needed()\n",
    "            \n",
    "            # OpenAI API 호출\n",
    "            logger.info(f\"API 요청 시작 - 모델: {DEFAULT_CONFIG['model']}, 메시지 수: {len(messages)}\")\n",
    "            \n",
    "            response = self.client.chat.completions.create(\n",
    "                model=DEFAULT_CONFIG[\"model\"],\n",
    "                messages=messages,\n",
    "                max_tokens=DEFAULT_CONFIG[\"max_tokens\"],\n",
    "                temperature=DEFAULT_CONFIG[\"temperature\"],\n",
    "                stream=False\n",
    "            )\n",
    "            \n",
    "            # 응답 데이터 처리\n",
    "            processing_time = time.time() - start_time\n",
    "            input_tokens = response.usage.prompt_tokens\n",
    "            output_tokens = response.usage.completion_tokens\n",
    "            content = response.choices[0].message.content\n",
    "            \n",
    "            # 사용량 추적\n",
    "            self.token_monitor.track_usage(\n",
    "                user_id, DEFAULT_CONFIG[\"model\"], \n",
    "                input_tokens, output_tokens, processing_time\n",
    "            )\n",
    "            \n",
    "            # 성공 시 실패 카운트 리셋\n",
    "            self.key_rotator.reset_failure_count()\n",
    "            \n",
    "            # ChatMessage 객체 생성\n",
    "            message = ChatMessage(\n",
    "                role=\"assistant\",\n",
    "                content=content,\n",
    "                timestamp=datetime.now(),\n",
    "                tokens_used=response.usage.total_tokens,\n",
    "                processing_time=processing_time,\n",
    "                model=DEFAULT_CONFIG[\"model\"]\n",
    "            )\n",
    "            \n",
    "            logger.info(f\"응답 생성 완료 - 토큰: {response.usage.total_tokens}, 시간: {processing_time:.2f}초\")\n",
    "            return message\n",
    "            \n",
    "        except Exception as e:\n",
    "            # 에러 처리 및 키 로테이션\n",
    "            if self.key_rotator.handle_api_error(e):\n",
    "                logger.info(\"키 로테이션 후 재시도\")\n",
    "                return self.generate_response(messages, user_id)\n",
    "            \n",
    "            logger.error(f\"응답 생성 실패: {e}\")\n",
    "            raise\n",
    "    \n",
    "    @log_function_call\n",
    "    def generate_streaming_response(self, messages: List[Dict[str, str]], \n",
    "                                  user_id: str = \"anonymous\") -> Iterator[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        스트리밍 응답 생성\n",
    "        \n",
    "        Args:\n",
    "            messages: 대화 메시지 리스트\n",
    "            user_id: 사용자 ID\n",
    "            \n",
    "        Yields:\n",
    "            Dict: 스트리밍 청크 데이터\n",
    "                - type: \"content\" | \"complete\" | \"error\"\n",
    "                - content: 텍스트 내용\n",
    "                - finished: 완료 여부\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "        accumulated_content = \"\"\n",
    "        \n",
    "        # 사용량 제한 체크\n",
    "        user_stats = self.token_monitor.get_user_stats(user_id)\n",
    "        if user_stats[\"limit_exceeded\"]:\n",
    "            yield {\n",
    "                \"type\": \"error\",\n",
    "                \"content\": f\"일일 토큰 한도 초과 ({user_stats['tokens_used']} 토큰)\",\n",
    "                \"finished\": True\n",
    "            }\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            self._refresh_client_if_needed()\n",
    "            \n",
    "            logger.info(f\"스트리밍 응답 시작 - 사용자: {user_id}\")\n",
    "            \n",
    "            # OpenAI 스트리밍 API 호출\n",
    "            stream = self.client.chat.completions.create(\n",
    "                model=DEFAULT_CONFIG[\"model\"],\n",
    "                messages=messages,\n",
    "                max_tokens=DEFAULT_CONFIG[\"max_tokens\"],\n",
    "                temperature=DEFAULT_CONFIG[\"temperature\"],\n",
    "                stream=True\n",
    "            )\n",
    "            \n",
    "            # 스트리밍 청크 처리\n",
    "            chunk_count = 0\n",
    "            for chunk in stream:\n",
    "                if chunk.choices[0].delta.content:\n",
    "                    content_chunk = chunk.choices[0].delta.content\n",
    "                    accumulated_content += content_chunk\n",
    "                    chunk_count += 1\n",
    "                    \n",
    "                    yield {\n",
    "                        \"type\": \"content\",\n",
    "                        \"content\": content_chunk,\n",
    "                        \"accumulated\": accumulated_content,\n",
    "                        \"finished\": False,\n",
    "                        \"chunk_number\": chunk_count\n",
    "                    }\n",
    "            \n",
    "            # 완료 처리\n",
    "            processing_time = time.time() - start_time\n",
    "            \n",
    "            # 토큰 수 추정 (4 chars ≈ 1 token)\n",
    "            estimated_tokens = len(accumulated_content) // 4\n",
    "            estimated_input = len(str(messages)) // 4\n",
    "            estimated_output = estimated_tokens\n",
    "            \n",
    "            # 사용량 추적 (추정값)\n",
    "            self.token_monitor.track_usage(\n",
    "                user_id, DEFAULT_CONFIG[\"model\"],\n",
    "                estimated_input, estimated_output, processing_time\n",
    "            )\n",
    "            \n",
    "            self.key_rotator.reset_failure_count()\n",
    "            \n",
    "            yield {\n",
    "                \"type\": \"complete\",\n",
    "                \"content\": accumulated_content,\n",
    "                \"finished\": True,\n",
    "                \"processing_time\": processing_time,\n",
    "                \"estimated_tokens\": estimated_tokens,\n",
    "                \"chunk_count\": chunk_count\n",
    "            }\n",
    "            \n",
    "            logger.info(f\"스트리밍 완료 - 청크: {chunk_count}, 시간: {processing_time:.2f}초\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            if self.key_rotator.handle_api_error(e):\n",
    "                logger.info(\"키 로테이션 후 스트리밍 재시도\")\n",
    "                yield from self.generate_streaming_response(messages, user_id)\n",
    "                return\n",
    "            \n",
    "            logger.error(f\"스트리밍 응답 실패: {e}\")\n",
    "            yield {\n",
    "                \"type\": \"error\",\n",
    "                \"content\": f\"오류가 발생했습니다: {str(e)}\",\n",
    "                \"finished\": True\n",
    "            }\n",
    "\n",
    "# 챗봇 인스턴스 생성\n",
    "if DEFAULT_CONFIG[\"api_key\"]:\n",
    "    chatbot = BasicChatbot(monitor, key_rotator)\n",
    "    print(\"✅ 챗봇 인스턴스 생성 완료\")\nelse:\n    print(\"❌ API 키가 없어 챗봇을 생성할 수 없습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7️⃣ 테스트 1: 일반 응답 생성\n",
    "\n",
    "먼저 **비스트리밍** 방식으로 응답을 생성해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'chatbot' in locals():\n",
    "    # 테스트 메시지\n",
    "    test_messages = [\n",
    "        {\"role\": \"system\", \"content\": \"당신은 도움이 되는 AI 어시스턴트입니다. 간결하고 친근하게 답변해주세요.\"},\n",
    "        {\"role\": \"user\", \"content\": \"안녕하세요! AI 챗봇에 대해 간단히 소개해주세요.\"}\n",
    "    ]\n",
    "    \n",
    "    print(\"🚀 일반 응답 테스트 시작...\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    try:\n",
    "        # 일반 응답 생성\n",
    "        response = chatbot.generate_response(test_messages, \"test_user\")\n",
    "        \n",
    "        # 결과 출력\n",
    "        print(f\"🤖 응답: {response.content}\")\n",
    "        print(f\"\\n📊 메타데이터:\")\n",
    "        print(f\"  - 모델: {response.model}\")\n",
    "        print(f\"  - 토큰 사용량: {response.tokens_used}\")\n",
    "        print(f\"  - 처리 시간: {response.processing_time:.2f}초\")\n",
    "        print(f\"  - 생성 시각: {response.timestamp.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        \n",
    "        # 사용량 통계 확인\n",
    "        user_stats = monitor.get_user_stats(\"test_user\")\n",
    "        print(f\"\\n📈 사용자 통계:\")\n",
    "        print(f\"  - 오늘 요청 수: {user_stats['requests']}\")\n",
    "        print(f\"  - 오늘 토큰 사용량: {user_stats['tokens_used']}\")\n",
    "        print(f\"  - 오늘 예상 비용: ${user_stats['cost']:.4f}\")\n",
    "        print(f\"  - 남은 토큰 한도: {user_stats['remaining_tokens']}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 오류 발생: {e}\")\nelse:\n    print(\"❌ 챗봇이 초기화되지 않았습니다. API 키를 확인해주세요.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8️⃣ 테스트 2: 스트리밍 응답 생성\n",
    "\n",
    "이번에는 **스트리밍** 방식으로 실시간 응답을 확인해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'chatbot' in locals():\n",
    "    # 스트리밍 테스트 메시지\n",
    "    streaming_messages = [\n",
    "        {\"role\": \"system\", \"content\": \"당신은 도움이 되는 AI 어시스턴트입니다. 상세하고 친근하게 답변해주세요.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Python으로 ChatGPT와 같은 챗봇을 만드는 방법을 단계별로 설명해주세요.\"}\n",
    "    ]\n",
    "    \n",
    "    print(\"🌊 스트리밍 응답 테스트 시작...\")\n",
    "    print(\"-\" * 50)\n",
    "    print(\"🤖 AI (실시간): \", end=\"\", flush=True)\n",
    "    \n",
    "    try:\n",
    "        full_response = \"\"\n",
    "        chunk_count = 0\n",
    "        \n",
    "        # 스트리밍 응답 처리\n",
    "        for chunk in chatbot.generate_streaming_response(streaming_messages, \"streaming_test_user\"):\n",
    "            if chunk[\"type\"] == \"content\":\n",
    "                print(chunk[\"content\"], end=\"\", flush=True)\n",
    "                full_response += chunk[\"content\"]\n",
    "                chunk_count += 1\n",
    "            \n",
    "            elif chunk[\"type\"] == \"complete\":\n",
    "                print(f\"\\n\\n📊 스트리밍 완료:\")\n",
    "                print(f\"  - 총 청크 수: {chunk['chunk_count']}\")\n",
    "                print(f\"  - 처리 시간: {chunk['processing_time']:.2f}초\")\n",
    "                print(f\"  - 추정 토큰: {chunk['estimated_tokens']}\")\n",
    "                print(f\"  - 응답 길이: {len(full_response)} 문자\")\n",
    "                \n",
    "                # 청크당 평균 처리 시간\n",
    "                avg_chunk_time = chunk['processing_time'] / max(chunk['chunk_count'], 1)\n",
    "                print(f\"  - 평균 청크 시간: {avg_chunk_time:.3f}초\")\n",
    "            \n",
    "            elif chunk[\"type\"] == \"error\":\n",
    "                print(f\"\\n❌ 오류: {chunk['content']}\")\n",
    "                break\n",
    "        \n",
    "        # 스트리밍 사용자 통계 확인\n",
    "        streaming_stats = monitor.get_user_stats(\"streaming_test_user\")\n",
    "        print(f\"\\n📈 스트리밍 사용자 통계:\")\n",
    "        print(f\"  - 요청 수: {streaming_stats['requests']}\")\n",
    "        print(f\"  - 토큰 사용량: {streaming_stats['tokens_used']} (추정)\")\n",
    "        print(f\"  - 예상 비용: ${streaming_stats['cost']:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ 스트리밍 오류: {e}\")\nelse:\n    print(\"❌ 챗봇이 초기화되지 않았습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9️⃣ 테스트 3: 대화형 인터랙션\n",
    "\n",
    "실제 대화처럼 **연속적인 메시지 교환**을 테스트해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'chatbot' in locals():\n",
    "    print(\"💬 대화형 테스트 시작\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 대화 시뮬레이션\n",
    "    conversation = [\n",
    "        {\"role\": \"system\", \"content\": \"당신은 Python 프로그래밍 전문가입니다. 실무 경험을 바탕으로 답변해주세요.\"},\n",
    "    ]\n",
    "    \n",
    "    test_questions = [\n",
    "        \"Python에서 비동기 프로그래밍이란 무엇인가요?\",\n",
    "        \"async/await와 threading의 차이점을 설명해주세요.\",\n",
    "        \"실무에서 비동기를 언제 사용하면 좋을까요?\"\n",
    "    ]\n",
    "    \n",
    "    for i, question in enumerate(test_questions, 1):\n",
    "        print(f\"\\n👤 질문 {i}: {question}\")\n",
    "        conversation.append({\"role\": \"user\", \"content\": question})\n",
    "        \n",
    "        print(f\"🤖 답변 {i}: \", end=\"\", flush=True)\n",
    "        \n",
    "        try:\n",
    "            # 스트리밍으로 응답 생성\n",
    "            response_text = \"\"\n",
    "            for chunk in chatbot.generate_streaming_response(conversation, f\"conversation_test_{i}\"):\n",
    "                if chunk[\"type\"] == \"content\":\n",
    "                    print(chunk[\"content\"], end=\"\", flush=True)\n",
    "                    response_text += chunk[\"content\"]\n",
    "                elif chunk[\"type\"] == \"complete\":\n",
    "                    print(f\"\\n   ⏱️  {chunk['processing_time']:.2f}초 | 📊 ~{chunk['estimated_tokens']} 토큰\")\n",
    "                elif chunk[\"type\"] == \"error\":\n",
    "                    print(f\"\\n   ❌ {chunk['content']}\")\n",
    "                    break\n",
    "            \n",
    "            # 대화에 AI 응답 추가\n",
    "            if response_text:\n",
    "                conversation.append({\"role\": \"assistant\", \"content\": response_text})\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"\\n   ❌ 오류: {e}\")\n",
    "        \n",
    "        print(\"-\" * 40)\n",
    "    \n",
    "    # 전체 대화 통계\n",
    "    print(f\"\\n📊 전체 세션 통계:\")\n",
    "    session_stats = monitor.session_stats\n",
    "    session_duration = (datetime.now() - session_stats['start_time']).total_seconds()\n",
    "    print(f\"  - 총 요청 수: {session_stats['total_requests']}\")\n",
    "    print(f\"  - 총 토큰 수: {session_stats['total_tokens']}\")\n",
    "    print(f\"  - 총 비용: ${session_stats['total_cost']:.4f}\")\n",
    "    print(f\"  - 세션 시간: {session_duration:.1f}초\")\n",
    "    print(f\"  - 평균 응답 시간: {session_duration / max(session_stats['total_requests'], 1):.2f}초\")\nelse:\n    print(\"❌ 챗봇이 초기화되지 않았습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔟 테스트 4: 에러 처리 및 한도 제한\n",
    "\n",
    "실무에서는 **에러 상황**과 **사용량 제한**을 적절히 처리해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'chatbot' in locals():\n",
    "    print(\"🧪 에러 처리 및 한도 제한 테스트\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # 1. 사용량 한도 초과 시뮬레이션\n",
    "    print(\"\\n1️⃣ 사용량 한도 초과 테스트\")\n",
    "    \n",
    "    # 임시로 한도를 낮게 설정\n",
    "    original_limit = DEFAULT_CONFIG[\"daily_token_limit\"]\n",
    "    DEFAULT_CONFIG[\"daily_token_limit\"] = 10  # 매우 낮은 한도\n",
    "    \n",
    "    # 사용량을 인위적으로 증가\n",
    "    monitor.track_usage(\"limit_test_user\", \"gpt-4o-mini\", 5, 10, 0.5)\n",
    "    \n",
    "    try:\n",
    "        response = chatbot.generate_response(\n",
    "            [{\"role\": \"user\", \"content\": \"안녕하세요\"}], \n",
    "            \"limit_test_user\"\n",
    "        )\n",
    "        print(\"❌ 예상과 다름: 한도 초과 에러가 발생해야 함\")\n",
    "    except Exception as e:\n",
    "        print(f\"✅ 예상된 한도 초과 에러: {e}\")\n",
    "    \n",
    "    # 한도 복원\n",
    "    DEFAULT_CONFIG[\"daily_token_limit\"] = original_limit\n",
    "    \n",
    "    # 2. 잘못된 API 키 테스트 (백업이 없는 경우)\n",
    "    print(\"\\n2️⃣ 잘못된 API 키 처리 테스트\")\n",
    "    \n",
    "    # 임시로 잘못된 키 설정\n",
    "    original_key = key_rotator.primary_key\n",
    "    key_rotator.primary_key = \"sk-invalid-key-for-testing\"\n",
    "    key_rotator.current_key = \"sk-invalid-key-for-testing\"\n",
    "    \n",
    "    # 새 챗봇 인스턴스로 테스트\n",
    "    test_rotator = APIKeyRotator(\"sk-invalid-key\", None)\n",
    "    test_chatbot = BasicChatbot(TokenMonitor(), test_rotator)\n",
    "    \n",
    "    try:\n",
    "        response = test_chatbot.generate_response(\n",
    "            [{\"role\": \"user\", \"content\": \"테스트\"}], \n",
    "            \"error_test_user\"\n",
    "        )\n",
    "        print(\"❌ 예상과 다름: API 키 에러가 발생해야 함\")\n",
    "    except Exception as e:\n",
    "        print(f\"✅ 예상된 API 키 에러: {type(e).__name__}\")\n",
    "    \n",
    "    # 원래 키 복원\n",
    "    key_rotator.primary_key = original_key\n",
    "    key_rotator.current_key = original_key\n",
    "    \n",
    "    print(\"\\n✅ 에러 처리 테스트 완료\")\nelse:\n    print(\"❌ 챗봇이 초기화되지 않았습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1️⃣1️⃣ 실무 팁: 성능 비교 분석\n",
    "\n",
    "**스트리밍 vs 일반 응답**의 차이점을 실제로 측정해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'chatbot' in locals():\n",
    "    print(\"⚡ 성능 비교 분석\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    test_prompt = \"딥러닝과 머신러닝의 차이점을 자세히 설명해주세요.\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"당신은 AI/ML 전문가입니다.\"},\n",
    "        {\"role\": \"user\", \"content\": test_prompt}\n",
    "    ]\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # 1. 일반 응답 측정\n",
    "    print(\"\\n📊 일반 응답 모드 측정 중...\")\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        normal_response = chatbot.generate_response(messages, \"perf_test_normal\")\n",
    "        \n",
    "        results[\"normal\"] = {\n",
    "            \"total_time\": normal_response.processing_time,\n",
    "            \"tokens\": normal_response.tokens_used,\n",
    "            \"response_length\": len(normal_response.content),\n",
    "            \"first_token_time\": normal_response.processing_time,  # 전체 응답 완료 시간\n",
    "        }\n",
    "        \n",
    "        print(f\"  ✅ 완료 - {normal_response.processing_time:.2f}초, {normal_response.tokens_used} 토큰\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"  ❌ 실패: {e}\")\n",
    "        results[\"normal\"] = None\n",
    "    \n",
    "    # 2. 스트리밍 응답 측정\n",
    "    print(\"\\n🌊 스트리밍 응답 모드 측정 중...\")\n",
    "    try:\n",
    "        streaming_start = time.time()\n",
    "        first_chunk_time = None\n",
    "        chunk_times = []\n",
    "        total_chunks = 0\n",
    "        accumulated_text = \"\"\n",
    "        \n",
    "        for chunk in chatbot.generate_streaming_response(messages, \"perf_test_streaming\"):\n",
    "            current_time = time.time()\n",
    "            \n",
    "            if chunk[\"type\"] == \"content\":\n",
    "                if first_chunk_time is None:\n",
    "                    first_chunk_time = current_time - streaming_start\n",
    "                \n",
    "                chunk_times.append(current_time - streaming_start)\n",
    "                accumulated_text += chunk[\"content\"]\n",
    "                total_chunks += 1\n",
    "                \n",
    "                # 진행률 표시 (매 10청크마다)\n",
    "                if total_chunks % 10 == 0:\n",
    "                    print(f\"  📊 청크 {total_chunks}: {len(accumulated_text)} 문자 누적\")\n",
    "            \n",
    "            elif chunk[\"type\"] == \"complete\":\n",
    "                results[\"streaming\"] = {\n",
    "                    \"total_time\": chunk[\"processing_time\"],\n",
    "                    \"tokens\": chunk[\"estimated_tokens\"],\n",
    "                    \"response_length\": len(accumulated_text),\n",
    "                    \"first_token_time\": first_chunk_time,\n",
    "                    \"total_chunks\": total_chunks,\n",
    "                    \"avg_chunk_interval\": chunk[\"processing_time\"] / max(total_chunks, 1)\n",
    "                }\n",
    "                print(f\"  ✅ 완료 - {chunk['processing_time']:.2f}초, {total_chunks} 청크\")\n",
    "                break\n",
    "            \n",
    "            elif chunk[\"type\"] == \"error\":\n",
    "                print(f\"  ❌ 에러: {chunk['content']}\")\n",
    "                results[\"streaming\"] = None\n",
    "                break\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"  ❌ 스트리밍 실패: {e}\")\n",
    "        results[\"streaming\"] = None\n",
    "    \n",
    "    # 3. 결과 비교 분석\n",
    "    print(\"\\n📈 성능 비교 결과\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    if results[\"normal\"] and results[\"streaming\"]:\n",
    "        normal = results[\"normal\"]\n",
    "        streaming = results[\"streaming\"]\n",
    "        \n",
    "        print(f\"📊 **처리 시간 비교**\")\n",
    "        print(f\"  일반 모드: {normal['total_time']:.2f}초 (전체 응답 완료까지)\")\n",
    "        print(f\"  스트리밍: {streaming['total_time']:.2f}초 (전체 응답 완료까지)\")\n",
    "        print(f\"  첫 토큰: {streaming['first_token_time']:.2f}초 (사용자가 응답을 보기 시작)\")\n",
    "        \n",
    "        # 사용자 경험 개선 계산\n",
    "        ux_improvement = ((normal['total_time'] - streaming['first_token_time']) / normal['total_time']) * 100\n",
    "        print(f\"  🚀 UX 개선: {ux_improvement:.1f}% (첫 응답까지 시간 단축)\")\n",
    "        \n",
    "        print(f\"\\n📊 **응답 품질 비교**\")\n",
    "        print(f\"  일반 모드: {normal['response_length']} 문자, {normal['tokens']} 토큰\")\n",
    "        print(f\"  스트리밍: {streaming['response_length']} 문자, ~{streaming['tokens']} 토큰 (추정)\")\n",
    "        \n",
    "        print(f\"\\n⚡ **스트리밍 세부 정보**\")\n",
    "        print(f\"  총 청크 수: {streaming['total_chunks']}\")\n",
    "        print(f\"  평균 청크 간격: {streaming['avg_chunk_interval']:.3f}초\")\n",
    "        print(f\"  초당 문자 수: {streaming['response_length'] / streaming['total_time']:.1f} chars/sec\")\n",
    "    \n",
    "    else:\n",
    "        print(\"❌ 비교할 수 있는 데이터가 부족합니다.\")\nelse:\n    print(\"❌ 챗봇이 초기화되지 않았습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1️⃣2️⃣ 로그 분석 및 디버깅\n",
    "\n",
    "생성된 **로그 파일**을 분석하여 시스템 동작을 확인해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로그 파일 분석\n",
    "log_file = \"chatbot_lesson1.log\"\n",
    "\n",
    "if os.path.exists(log_file):\n",
    "    print(f\"📋 로그 파일 분석: {log_file}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    with open(log_file, 'r', encoding='utf-8') as f:\n",
    "        log_lines = f.readlines()\n",
    "    \n",
    "    # 로그 통계\n",
    "    stats = {\n",
    "        \"총 로그 라인\": len(log_lines),\n",
    "        \"INFO 로그\": sum(1 for line in log_lines if \" - INFO - \" in line),\n",
    "        \"DEBUG 로그\": sum(1 for line in log_lines if \" - DEBUG - \" in line),\n",
    "        \"WARNING 로그\": sum(1 for line in log_lines if \" - WARNING - \" in line),\n",
    "        \"ERROR 로그\": sum(1 for line in log_lines if \" - ERROR - \" in line),\n",
    "    }\n",
    "    \n",
    "    print(\"📊 로그 통계:\")\n",
    "    for key, value in stats.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    \n",
    "    # 최근 로그 표시 (마지막 10줄)\n",
    "    print(\"\\n📄 최근 로그 (마지막 10줄):\")\n",
    "    print(\"-\" * 30)\n",
    "    for line in log_lines[-10:]:\n",
    "        print(f\"  {line.strip()}\")\n",
    "    \n",
    "    # API 호출 관련 로그 필터링\n",
    "    api_logs = [line for line in log_lines if \"API\" in line or \"토큰\" in line]\n",
    "    if api_logs:\n",
    "        print(f\"\\n🔍 API 관련 로그 ({len(api_logs)}개):\")\n",
    "        print(\"-\" * 30)\n",
    "        for log in api_logs[-5:]:  # 최근 5개만\n",
    "            print(f\"  {log.strip()}\")\nelse:\n    print(f\"❌ 로그 파일을 찾을 수 없습니다: {log_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1️⃣3️⃣ 종합 데모 및 결과 정리\n",
    "\n",
    "지금까지 구현한 기능들을 종합하여 **최종 데모**를 실행해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🎉 1차시 종합 데모\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if 'chatbot' in locals():\n",
    "    # 최종 통계 수집\n",
    "    session_stats = monitor.session_stats\n",
    "    session_duration = (datetime.now() - session_stats['start_time']).total_seconds()\n",
    "    \n",
    "    print(f\"📊 **전체 세션 요약**\")\n",
    "    print(f\"  - 세션 시간: {session_duration:.1f}초\")\n",
    "    print(f\"  - 총 API 요청: {session_stats['total_requests']}회\")\n",
    "    print(f\"  - 총 토큰 사용: {session_stats['total_tokens']}개\")\n",
    "    print(f\"  - 총 예상 비용: ${session_stats['total_cost']:.4f}\")\n",
    "    \n",
    "    if session_stats['total_requests'] > 0:\n",
    "        avg_tokens = session_stats['total_tokens'] / session_stats['total_requests']\n",
    "        avg_cost = session_stats['total_cost'] / session_stats['total_requests']\n",
    "        print(f\"  - 평균 토큰/요청: {avg_tokens:.1f}개\")\n",
    "        print(f\"  - 평균 비용/요청: ${avg_cost:.4f}\")\n",
    "    \n",
    "    print(f\"\\n🎯 **1차시 핵심 학습 내용**\")\n",
    "    print(f\"  ✅ OpenAI API 연동 및 클라이언트 설정\")\n",
    "    print(f\"  ✅ 스트리밍 vs 일반 응답 구현\")\n",
    "    print(f\"  ✅ 토큰 사용량 모니터링 및 비용 계산\")\n",
    "    print(f\"  ✅ API 키 로테이션 및 에러 처리\")\n",
    "    print(f\"  ✅ 구조화된 로깅 시스템\")\n",
    "    print(f\"  ✅ 사용량 제한 및 보안 고려사항\")\n",
    "    \n",
    "    print(f\"\\n🚀 **다음 차시 미리보기**\")\n",
    "    print(f\"  - 2차시: 프롬프트 엔지니어링 및 템플릿 시스템\")\n",
    "    print(f\"  - 3차시: RAG 구현 (문서 검색 기반 답변)\")\n",
    "    print(f\"  - 4차시: 대화 상태 관리 및 멀티턴 최적화\")\n",
    "    \n",
    "    print(f\"\\n💡 **실무 적용 팁**\")\n",
    "    print(f\"  - 프로덕션에서는 Redis 클러스터 사용 권장\")\n",
    "    print(f\"  - API 키는 환경변수나 비밀 관리 서비스 사용\")\n",
    "    print(f\"  - 로그는 ELK 스택이나 클라우드 로깅 서비스 연동\")\n",
    "    print(f\"  - 사용량 알림 시스템 구축 (Slack, 이메일)\")\n",
    "    print(f\"  - A/B 테스트를 위한 모델별 응답 비교\")\n",
    "\nelse:\n    print(\"❌ 챗봇이 초기화되지 않았습니다.\")\n\nprint(\"\\n🎊 1차시 실습 완료! 수고하셨습니다!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📝 숙제 및 확장 과제\n",
    "\n",
    "### 🏠 숙제\n",
    "1. **다른 LLM 모델 테스트**: GPT-4, Claude, Gemini 등 비교 분석\n",
    "2. **사용량 알림 시스템**: 일정 토큰 수 초과 시 이메일/Slack 알림\n",
    "3. **응답 품질 평가**: 같은 질문에 대한 모델별 응답 점수화\n",
    "\n",
    "### 🚀 확장 과제\n",
    "1. **멀티 모델 지원**: 질문 유형에 따라 최적 모델 자동 선택\n",
    "2. **캐싱 시스템**: 동일 질문 빠른 응답 (Redis)\n",
    "3. **대화 히스토리**: 이전 대화 맥락 유지\n",
    "4. **A/B 테스트**: 프롬프트 변경에 따른 응답 품질 측정\n",
    "\n",
    "### 📚 추천 자료\n",
    "- [OpenAI API 공식 문서](https://platform.openai.com/docs)\n",
    "- [Streamlit 공식 튜토리얼](https://docs.streamlit.io)\n",
    "- [Python 로깅 베스트 프랙티스](https://docs.python.org/3/howto/logging.html)\n",
    "\n",
    "---\n",
    "\n",
    "**다음 시간에는 프롬프트 최적화와 템플릿 시스템을 배워봅시다! 🎯**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}