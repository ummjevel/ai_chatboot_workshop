#!/usr/bin/env python3
"""
1ì°¨ì‹œ: ì‹¤ë¬´ í™˜ê²½ êµ¬ì¶• & ë¹ ë¥¸ í”„ë¡œí† íƒ€ì…
Author: AI Chatbot Workshop
Date: 2024-08-30
Description: OpenAI API ì—°ë™ ê¸°ë³¸ ì±—ë´‡ê³¼ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ êµ¬í˜„, Streamlit ì¸í„°í˜ì´ìŠ¤
"""

import os
import time
import json
import logging
import asyncio
from typing import Iterator, Dict, Any, Optional, List
from datetime import datetime, timedelta
from dataclasses import dataclass, asdict
from functools import wraps
import streamlit as st
from openai import OpenAI
import redis

# ë¡œì»¬ ì„¤ì • ì„í¬íŠ¸
from config import get_config

# ì„¤ì • ë¡œë“œ
config = get_config()

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)

@dataclass
class ChatMessage:
    """ì±„íŒ… ë©”ì‹œì§€ êµ¬ì¡°"""
    role: str  # "user" or "assistant" or "system"
    content: str
    timestamp: datetime
    tokens_used: int = 0
    processing_time: float = 0.0
    model: str = ""

@dataclass
class APIUsageStats:
    """API ì‚¬ìš©ëŸ‰ í†µê³„"""
    total_requests: int = 0
    total_tokens: int = 0
    total_cost: float = 0.0
    avg_response_time: float = 0.0
    error_count: int = 0
    last_reset: datetime = None

class TokenMonitor:
    """í† í° ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§ í´ë˜ìŠ¤"""
    
    # ëª¨ë¸ë³„ í† í°ë‹¹ ê°€ê²© (2024ë…„ 8ì›” ê¸°ì¤€)
    TOKEN_PRICES = {
        "gpt-4o-mini": {"input": 0.00015 / 1000, "output": 0.0006 / 1000},
        "gpt-4o": {"input": 0.005 / 1000, "output": 0.015 / 1000},
        "gpt-3.5-turbo": {"input": 0.001 / 1000, "output": 0.002 / 1000},
    }
    
    def __init__(self):
        self.redis_client = None
        self._init_redis()
    
    def _init_redis(self):
        """Redis ì—°ê²° ì´ˆê¸°í™”"""
        try:
            self.redis_client = redis.from_url(config.get_redis_url())
            self.redis_client.ping()
            logger.info("Redis ì—°ê²° ì„±ê³µ")
        except Exception as e:
            logger.warning(f"Redis ì—°ê²° ì‹¤íŒ¨, ë©”ëª¨ë¦¬ ëª¨ë“œë¡œ ì „í™˜: {e}")
            self.redis_client = None
    
    def calculate_cost(self, model: str, input_tokens: int, output_tokens: int) -> float:
        """í† í° ì‚¬ìš©ëŸ‰ ê¸°ë°˜ ë¹„ìš© ê³„ì‚°"""
        if model not in self.TOKEN_PRICES:
            logger.warning(f"ì•Œ ìˆ˜ ì—†ëŠ” ëª¨ë¸: {model}, ê¸°ë³¸ ìš”ê¸ˆ ì ìš©")
            model = "gpt-4o-mini"
        
        prices = self.TOKEN_PRICES[model]
        input_cost = input_tokens * prices["input"]
        output_cost = output_tokens * prices["output"]
        
        return round(input_cost + output_cost, 6)
    
    def track_usage(self, user_id: str, model: str, input_tokens: int, 
                   output_tokens: int, processing_time: float):
        """ì‚¬ìš©ëŸ‰ ì¶”ì  ë° ì €ì¥"""
        total_tokens = input_tokens + output_tokens
        cost = self.calculate_cost(model, input_tokens, output_tokens)
        
        # ì‚¬ìš©ëŸ‰ ë°ì´í„° ìƒì„±
        usage_data = {
            "timestamp": datetime.now().isoformat(),
            "user_id": user_id,
            "model": model,
            "input_tokens": input_tokens,
            "output_tokens": output_tokens,
            "total_tokens": total_tokens,
            "cost": cost,
            "processing_time": processing_time
        }
        
        try:
            if self.redis_client:
                # Redisì— ì €ì¥
                key = f"usage:{user_id}:{datetime.now().strftime('%Y%m%d')}"
                self.redis_client.lpush(key, json.dumps(usage_data))
                self.redis_client.expire(key, 86400 * 30)  # 30ì¼ ë³´ê´€
            
            # ë¡œê·¸ì— ê¸°ë¡
            logger.info(
                f"í† í° ì‚¬ìš©ëŸ‰ - ì‚¬ìš©ì: {user_id}, ëª¨ë¸: {model}, "
                f"í† í°: {total_tokens}, ë¹„ìš©: ${cost:.4f}, ì‹œê°„: {processing_time:.2f}s"
            )
            
        except Exception as e:
            logger.error(f"ì‚¬ìš©ëŸ‰ ì¶”ì  ì¤‘ ì˜¤ë¥˜: {e}")
    
    def get_daily_usage(self, user_id: str) -> Dict[str, Any]:
        """ì¼ì¼ ì‚¬ìš©ëŸ‰ ì¡°íšŒ"""
        today = datetime.now().strftime('%Y%m%d')
        key = f"usage:{user_id}:{today}"
        
        try:
            if self.redis_client:
                usage_list = self.redis_client.lrange(key, 0, -1)
                total_tokens = 0
                total_cost = 0.0
                request_count = len(usage_list)
                
                for usage_json in usage_list:
                    usage = json.loads(usage_json.decode())
                    total_tokens += usage.get("total_tokens", 0)
                    total_cost += usage.get("cost", 0.0)
                
                return {
                    "date": today,
                    "request_count": request_count,
                    "total_tokens": total_tokens,
                    "total_cost": round(total_cost, 4),
                    "limit_remaining": max(0, config.performance.max_tokens_per_user_day - total_tokens)
                }
        except Exception as e:
            logger.error(f"ì‚¬ìš©ëŸ‰ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}")
        
        # ê¸°ë³¸ê°’ ë°˜í™˜
        return {
            "date": today,
            "request_count": 0,
            "total_tokens": 0,
            "total_cost": 0.0,
            "limit_remaining": config.performance.max_tokens_per_user_day
        }

class APIKeyRotator:
    """API í‚¤ ë¡œí…Œì´ì…˜ ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.primary_key = config.llm.openai_api_key
        self.backup_key = config.llm.backup_api_key
        self.current_key = self.primary_key
        self.failure_count = 0
        self.last_rotation = datetime.now()
    
    def get_current_key(self) -> str:
        """í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ API í‚¤ ë°˜í™˜"""
        return self.current_key
    
    def handle_api_error(self, error: Exception) -> bool:
        """
        API ì—ëŸ¬ ì²˜ë¦¬ ë° í‚¤ ë¡œí…Œì´ì…˜
        
        Returns:
            bool: ë¡œí…Œì´ì…˜ ì„±ê³µ ì—¬ë¶€
        """
        self.failure_count += 1
        logger.warning(f"API í˜¸ì¶œ ì‹¤íŒ¨ (íšŸìˆ˜: {self.failure_count}): {error}")
        
        # 3ë²ˆ ì‹¤íŒ¨ ì‹œ ë°±ì—… í‚¤ë¡œ ì „í™˜
        if self.failure_count >= 3 and self.backup_key and self.current_key != self.backup_key:
            logger.info("ë°±ì—… API í‚¤ë¡œ ì „í™˜")
            self.current_key = self.backup_key
            self.failure_count = 0
            self.last_rotation = datetime.now()
            return True
        
        # ë°±ì—… í‚¤ë„ ì‹¤íŒ¨ ì‹œ primaryë¡œ ë‹¤ì‹œ ì „í™˜ (ì¿¨ë‹¤ìš´ í›„)
        if self.current_key == self.backup_key and self.failure_count >= 3:
            cooldown = timedelta(minutes=5)
            if datetime.now() - self.last_rotation > cooldown:
                logger.info("Primary API í‚¤ë¡œ ë³µì› ì‹œë„")
                self.current_key = self.primary_key
                self.failure_count = 0
                self.last_rotation = datetime.now()
                return True
        
        return False
    
    def reset_failure_count(self):
        """ì„±ê³µ ì‹œ ì‹¤íŒ¨ ì¹´ìš´íŠ¸ ë¦¬ì…‹"""
        self.failure_count = 0

def log_function_call(func):
    """í•¨ìˆ˜ í˜¸ì¶œ ë¡œê¹… ë°ì½”ë ˆì´í„°"""
    @wraps(func)
    def wrapper(*args, **kwargs):
        start_time = time.time()
        logger.debug(f"[ENTER] {func.__name__}", extra={
            "function": func.__name__, 
            "args_count": len(args),
            "kwargs_keys": list(kwargs.keys())
        })
        
        try:
            result = func(*args, **kwargs)
            elapsed = time.time() - start_time
            logger.debug(
                f"[EXIT] {func.__name__} - SUCCESS (ì†Œìš”ì‹œê°„: {elapsed:.2f}s)",
                extra={"function": func.__name__, "elapsed_time": elapsed}
            )
            return result
        except Exception as e:
            elapsed = time.time() - start_time
            logger.error(
                f"[EXIT] {func.__name__} - ERROR: {str(e)} (ì†Œìš”ì‹œê°„: {elapsed:.2f}s)", 
                extra={
                    "error": str(e), 
                    "function": func.__name__,
                    "elapsed_time": elapsed
                }
            )
            raise
    return wrapper

class BasicChatbot:
    """ê¸°ë³¸ ì±—ë´‡ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.key_rotator = APIKeyRotator()
        self.token_monitor = TokenMonitor()
        self.client = None
        self._init_openai_client()
    
    def _init_openai_client(self):
        """OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        try:
            client_config = config.get_openai_client_config()
            client_config["api_key"] = self.key_rotator.get_current_key()
            self.client = OpenAI(**client_config)
            logger.info("OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            logger.error(f"OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
    
    def _refresh_client_if_needed(self):
        """í•„ìš”ì‹œ í´ë¼ì´ì–¸íŠ¸ ì¬ìƒì„± (í‚¤ ë¡œí…Œì´ì…˜ í›„)"""
        current_key = self.key_rotator.get_current_key()
        if self.client.api_key != current_key:
            self.client.api_key = current_key
            logger.info("API í‚¤ ê°±ì‹ ë¨")
    
    @log_function_call
    def generate_response(self, messages: List[Dict[str, str]], 
                         user_id: str = "anonymous") -> ChatMessage:
        """
        ì¼ë°˜ ì‘ë‹µ ìƒì„± (ë¹„ìŠ¤íŠ¸ë¦¬ë°)
        
        Args:
            messages: ëŒ€í™” ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸
            user_id: ì‚¬ìš©ì ID (ì‚¬ìš©ëŸ‰ ì¶”ì ìš©)
            
        Returns:
            ChatMessage: ìƒì„±ëœ ì‘ë‹µ ë©”ì‹œì§€
            
        Raises:
            Exception: API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ
        """
        start_time = time.time()
        
        # ì‚¬ìš©ëŸ‰ ì œí•œ ì²´í¬
        daily_usage = self.token_monitor.get_daily_usage(user_id)
        if daily_usage["limit_remaining"] <= 0:
            raise Exception(f"ì¼ì¼ í† í° í•œë„ ì´ˆê³¼ ({daily_usage['total_tokens']} í† í°)")
        
        try:
            self._refresh_client_if_needed()
            
            # API ìš”ì²­ ë¡œê¹…
            logger.info(
                f"OpenAI API ìš”ì²­ ì‹œì‘ - ì‚¬ìš©ì: {user_id}, ëª¨ë¸: {config.llm.openai_model}",
                extra={
                    "user_id": user_id,
                    "model": config.llm.openai_model,
                    "message_count": len(messages)
                }
            )
            
            # OpenAI API í˜¸ì¶œ
            response = self.client.chat.completions.create(
                model=config.llm.openai_model,
                messages=messages,
                max_tokens=config.llm.max_tokens,
                temperature=config.llm.temperature,
                stream=False
            )
            
            # ì‘ë‹µ ì²˜ë¦¬
            processing_time = time.time() - start_time
            input_tokens = response.usage.prompt_tokens
            output_tokens = response.usage.completion_tokens
            content = response.choices[0].message.content
            
            # ì‚¬ìš©ëŸ‰ ì¶”ì 
            self.token_monitor.track_usage(
                user_id, config.llm.openai_model, 
                input_tokens, output_tokens, processing_time
            )
            
            # ì„±ê³µ ì‹œ ì‹¤íŒ¨ ì¹´ìš´íŠ¸ ë¦¬ì…‹
            self.key_rotator.reset_failure_count()
            
            # ChatMessage ìƒì„±
            message = ChatMessage(
                role="assistant",
                content=content,
                timestamp=datetime.now(),
                tokens_used=response.usage.total_tokens,
                processing_time=processing_time,
                model=config.llm.openai_model
            )
            
            logger.info(
                f"OpenAI API ì‘ë‹µ ì™„ë£Œ - í† í°: {response.usage.total_tokens}, "
                f"ì‹œê°„: {processing_time:.2f}s",
                extra={
                    "user_id": user_id,
                    "tokens_used": response.usage.total_tokens,
                    "processing_time": processing_time
                }
            )
            
            return message
            
        except Exception as e:
            # API ì—ëŸ¬ ì²˜ë¦¬ ë° í‚¤ ë¡œí…Œì´ì…˜
            if self.key_rotator.handle_api_error(e):
                logger.info("í‚¤ ë¡œí…Œì´ì…˜ í›„ ì¬ì‹œë„")
                return self.generate_response(messages, user_id)
            
            logger.error(f"ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")
            raise
    
    @log_function_call
    def generate_streaming_response(self, messages: List[Dict[str, str]], 
                                  user_id: str = "anonymous") -> Iterator[Dict[str, Any]]:
        """
        ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„±
        
        Args:
            messages: ëŒ€í™” ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸
            user_id: ì‚¬ìš©ì ID
            
        Yields:
            Dict: ìŠ¤íŠ¸ë¦¬ë° ì²­í¬ ë°ì´í„°
        """
        start_time = time.time()
        accumulated_content = ""
        total_tokens = 0
        
        # ì‚¬ìš©ëŸ‰ ì œí•œ ì²´í¬
        daily_usage = self.token_monitor.get_daily_usage(user_id)
        if daily_usage["limit_remaining"] <= 0:
            yield {
                "type": "error",
                "content": f"ì¼ì¼ í† í° í•œë„ ì´ˆê³¼ ({daily_usage['total_tokens']} í† í°)",
                "finished": True
            }
            return
        
        try:
            self._refresh_client_if_needed()
            
            logger.info(f"ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì‹œì‘ - ì‚¬ìš©ì: {user_id}")
            
            # OpenAI ìŠ¤íŠ¸ë¦¬ë° API í˜¸ì¶œ
            stream = self.client.chat.completions.create(
                model=config.llm.openai_model,
                messages=messages,
                max_tokens=config.llm.max_tokens,
                temperature=config.llm.temperature,
                stream=True
            )
            
            # ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬
            for chunk in stream:
                if chunk.choices[0].delta.content:
                    content_chunk = chunk.choices[0].delta.content
                    accumulated_content += content_chunk
                    
                    yield {
                        "type": "content",
                        "content": content_chunk,
                        "accumulated": accumulated_content,
                        "finished": False
                    }
            
            # ì™„ë£Œ ì²˜ë¦¬
            processing_time = time.time() - start_time
            
            # TODO: ìŠ¤íŠ¸ë¦¬ë°ì—ì„œëŠ” ì •í™•í•œ í† í° ìˆ˜ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ì•Œ ìˆ˜ ì—†ìŒ
            # ê·¼ì‚¬ì¹˜ ê³„ì‚° (4 chars â‰ˆ 1 token)
            estimated_tokens = len(accumulated_content) // 4
            
            # ì‚¬ìš©ëŸ‰ ì¶”ì  (ì¶”ì •ê°’)
            self.token_monitor.track_usage(
                user_id, config.llm.openai_model,
                estimated_tokens // 2,  # ì¶”ì • input
                estimated_tokens // 2,  # ì¶”ì • output
                processing_time
            )
            
            self.key_rotator.reset_failure_count()
            
            yield {
                "type": "complete",
                "content": accumulated_content,
                "finished": True,
                "processing_time": processing_time,
                "estimated_tokens": estimated_tokens
            }
            
            logger.info(f"ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ - ì‹œê°„: {processing_time:.2f}s, ì¶”ì • í† í°: {estimated_tokens}")
            
        except Exception as e:
            if self.key_rotator.handle_api_error(e):
                logger.info("í‚¤ ë¡œí…Œì´ì…˜ í›„ ìŠ¤íŠ¸ë¦¬ë° ì¬ì‹œë„")
                yield from self.generate_streaming_response(messages, user_id)
                return
            
            logger.error(f"ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì‹¤íŒ¨: {e}")
            yield {
                "type": "error",
                "content": f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                "finished": True
            }

def create_streamlit_ui():
    """Streamlit ì›¹ ì¸í„°í˜ì´ìŠ¤ ìƒì„±"""
    st.set_page_config(
        page_title="AI ì±—ë´‡ ë©˜í† ë§ - 1ì°¨ì‹œ",
        page_icon="ğŸ¤–",
        layout="wide"
    )
    
    st.title("ğŸ¤– AI ì±—ë´‡ ë©˜í† ë§ - 1ì°¨ì‹œ: ê¸°ë³¸ ì±—ë´‡")
    st.caption("OpenAI API ì—°ë™ê³¼ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ êµ¬í˜„")
    
    # ì‚¬ì´ë“œë°” - ì„¤ì • ë° í†µê³„
    with st.sidebar:
        st.header("âš™ï¸ ì„¤ì •")
        
        # ì‚¬ìš©ì ID ì…ë ¥
        user_id = st.text_input("ì‚¬ìš©ì ID", value="user123", key="user_id")
        
        # ëª¨ë¸ ì„ íƒ
        model_options = ["gpt-4o-mini", "gpt-4o", "gpt-3.5-turbo"]
        selected_model = st.selectbox("ëª¨ë¸ ì„ íƒ", model_options, index=0)
        
        # ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ
        streaming_mode = st.checkbox("ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ", value=True)
        
        # Temperature ì¡°ì •
        temperature = st.slider("Temperature", 0.0, 2.0, 0.7, 0.1)
        
        st.divider()
        
        # ì‚¬ìš©ëŸ‰ í†µê³„
        if st.button("ğŸ“Š ì‚¬ìš©ëŸ‰ ì¡°íšŒ"):
            chatbot = BasicChatbot()
            daily_usage = chatbot.token_monitor.get_daily_usage(user_id)
            
            st.subheader("ì˜¤ëŠ˜ì˜ ì‚¬ìš©ëŸ‰")
            col1, col2 = st.columns(2)
            with col1:
                st.metric("ìš”ì²­ ìˆ˜", daily_usage["request_count"])
                st.metric("ì‚¬ìš© í† í°", daily_usage["total_tokens"])
            with col2:
                st.metric("ì˜ˆìƒ ë¹„ìš©", f"${daily_usage['total_cost']:.4f}")
                st.metric("ë‚¨ì€ í•œë„", daily_usage["limit_remaining"])
    
    # ë©”ì¸ ì˜ì—­
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.header("ğŸ’¬ ì±„íŒ…")
        
        # ì±„íŒ… íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”
        if "messages" not in st.session_state:
            st.session_state.messages = [
                {
                    "role": "system", 
                    "content": "ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì¹œê·¼í•˜ê³  ì •í™•í•œ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”."
                }
            ]
            st.session_state.display_messages = []
        
        # ì´ì „ ë©”ì‹œì§€ í‘œì‹œ
        for msg in st.session_state.display_messages:
            with st.chat_message(msg["role"]):
                st.write(msg["content"])
                if "metadata" in msg:
                    st.caption(f"ğŸ• {msg['metadata']['processing_time']:.2f}ì´ˆ | "
                              f"ğŸ¯ {msg['metadata']['tokens_used']} í† í°")
        
        # ì‚¬ìš©ì ì…ë ¥
        if prompt := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”..."):
            # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
            user_msg = {"role": "user", "content": prompt}
            st.session_state.messages.append(user_msg)
            st.session_state.display_messages.append(user_msg)
            
            with st.chat_message("user"):
                st.write(prompt)
            
            # AI ì‘ë‹µ ìƒì„±
            with st.chat_message("assistant"):
                try:
                    chatbot = BasicChatbot()
                    
                    if streaming_mode:
                        # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ
                        message_placeholder = st.empty()
                        full_response = ""
                        
                        for chunk in chatbot.generate_streaming_response(
                            st.session_state.messages, user_id
                        ):
                            if chunk["type"] == "content":
                                full_response += chunk["content"]
                                message_placeholder.markdown(full_response + "â–Œ")
                            elif chunk["type"] == "complete":
                                message_placeholder.markdown(full_response)
                                st.caption(f"ğŸ• {chunk['processing_time']:.2f}ì´ˆ | "
                                          f"ğŸ¯ ~{chunk['estimated_tokens']} í† í° (ì¶”ì •)")
                            elif chunk["type"] == "error":
                                st.error(chunk["content"])
                                break
                        
                        if full_response:
                            assistant_msg = {"role": "assistant", "content": full_response}
                            st.session_state.messages.append(assistant_msg)
                            st.session_state.display_messages.append({
                                **assistant_msg,
                                "metadata": {
                                    "processing_time": chunk.get("processing_time", 0),
                                    "tokens_used": chunk.get("estimated_tokens", 0)
                                }
                            })
                    else:
                        # ì¼ë°˜ ì‘ë‹µ
                        response = chatbot.generate_response(st.session_state.messages, user_id)
                        st.write(response.content)
                        st.caption(f"ğŸ• {response.processing_time:.2f}ì´ˆ | "
                                  f"ğŸ¯ {response.tokens_used} í† í°")
                        
                        assistant_msg = {"role": "assistant", "content": response.content}
                        st.session_state.messages.append(assistant_msg)
                        st.session_state.display_messages.append({
                            **assistant_msg,
                            "metadata": {
                                "processing_time": response.processing_time,
                                "tokens_used": response.tokens_used
                            }
                        })
                
                except Exception as e:
                    st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
    
    with col2:
        st.header("ğŸ“‹ ì‹¤ìŠµ ê°€ì´ë“œ")
        
        with st.expander("ğŸ¯ 1ì°¨ì‹œ ëª©í‘œ", expanded=True):
            st.write("""
            - OpenAI API ì—°ë™ ì´í•´
            - ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ êµ¬í˜„
            - í† í° ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
            - API í‚¤ ë¡œí…Œì´ì…˜ ë¡œì§
            - ê¸°ë³¸ ì›¹ ì¸í„°í˜ì´ìŠ¤
            """)
        
        with st.expander("ğŸ’¡ ì‹¤ìŠµ í¬ì¸íŠ¸"):
            st.write("""
            1. **ìŠ¤íŠ¸ë¦¬ë° vs ì¼ë°˜ ì‘ë‹µ** ë¹„êµ
            2. **í† í° ì‚¬ìš©ëŸ‰** ì‹¤ì‹œê°„ í™•ì¸
            3. **ì—ëŸ¬ ì²˜ë¦¬** ë° ì¬ì‹œë„ ë¡œì§
            4. **ì‚¬ìš©ëŸ‰ ì œí•œ** ë™ì‘ í™•ì¸
            5. **ë¡œê¹…** ë©”ì‹œì§€ í™•ì¸ (í„°ë¯¸ë„)
            """)
        
        with st.expander("ğŸš€ í™•ì¥ ì•„ì´ë””ì–´"):
            st.write("""
            - ëŒ€í™” íˆìŠ¤í† ë¦¬ ì €ì¥
            - ë‹¤ì–‘í•œ LLM ëª¨ë¸ ì§€ì›
            - ì‚¬ìš©ìë³„ ì„¤ì • ì €ì¥
            - ì‘ë‹µ í’ˆì§ˆ í‰ê°€
            - ë¹„ìš© ë¶„ì„ ëŒ€ì‹œë³´ë“œ
            """)
        
        # ì‹œìŠ¤í…œ ì •ë³´
        st.divider()
        st.subheader("ğŸ”§ ì‹œìŠ¤í…œ ì •ë³´")
        st.code(f"""
í™˜ê²½: {config.app.env}
ëª¨ë¸: {config.llm.openai_model}
ìµœëŒ€ í† í°: {config.llm.max_tokens}
Temperature: {config.llm.temperature}
        """)

def run_cli_demo():
    """CLI ë°ëª¨ ì‹¤í–‰"""
    print("=== AI ì±—ë´‡ ë©˜í† ë§ 1ì°¨ì‹œ CLI ë°ëª¨ ===")
    print("ì¢…ë£Œí•˜ë ¤ë©´ 'quit' ë˜ëŠ” 'exit'ë¥¼ ì…ë ¥í•˜ì„¸ìš”.\n")
    
    chatbot = BasicChatbot()
    messages = [
        {
            "role": "system", 
            "content": "ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì¹œê·¼í•˜ê³  ì •í™•í•œ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”."
        }
    ]
    
    while True:
        try:
            user_input = input("\nì‚¬ìš©ì: ")
            if user_input.lower() in ['quit', 'exit']:
                print("ì±—ë´‡ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
            
            if not user_input.strip():
                continue
            
            messages.append({"role": "user", "content": user_input})
            
            print("\nAI (ìŠ¤íŠ¸ë¦¬ë°): ", end="", flush=True)
            
            # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì²˜ë¦¬
            full_response = ""
            for chunk in chatbot.generate_streaming_response(messages, "cli_user"):
                if chunk["type"] == "content":
                    print(chunk["content"], end="", flush=True)
                    full_response += chunk["content"]
                elif chunk["type"] == "complete":
                    print(f"\n\nğŸ“Š ì²˜ë¦¬ì‹œê°„: {chunk['processing_time']:.2f}ì´ˆ, "
                          f"ì¶”ì • í† í°: {chunk['estimated_tokens']}")
                elif chunk["type"] == "error":
                    print(f"\nâŒ ì˜¤ë¥˜: {chunk['content']}")
                    break
            
            if full_response:
                messages.append({"role": "assistant", "content": full_response})
        
        except KeyboardInterrupt:
            print("\n\nì±—ë´‡ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
        except Exception as e:
            print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")

if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == "cli":
        # CLI ëª¨ë“œ
        run_cli_demo()
    else:
        # Streamlit ëª¨ë“œ (ê¸°ë³¸)
        print("Streamlit ì›¹ ì¸í„°í˜ì´ìŠ¤ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
        print("ë¸Œë¼ìš°ì €ì—ì„œ http://localhost:8501 ì— ì ‘ì†í•˜ì„¸ìš”.")
        print("CLI ëª¨ë“œë¡œ ì‹¤í–‰í•˜ë ¤ë©´: python lesson1_basic_chatbot.py cli")
        create_streamlit_ui()