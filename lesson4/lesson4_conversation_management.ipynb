{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4차시: 대화 상태 관리 & 멀티턴 최적화\n",
    "\n",
    "## 학습 목표\n",
    "- Redis 기반 세션 관리 이해\n",
    "- 컨텍스트 윈도우 최적화 구현\n",
    "- 대화 상태 추적 및 흐름 제어\n",
    "- 멀티 사용자 환경에서의 동시성 처리\n",
    "\n",
    "## 주요 구현 내용\n",
    "1. **세션 관리 시스템**: Redis 기반 대화 히스토리 저장\n",
    "2. **컨텍스트 최적화**: 토큰 수 기반 메시지 압축\n",
    "3. **대화 흐름 제어**: 의도 분류 및 상태 전환\n",
    "4. **멀티턴 최적화**: 중요도 기반 메시지 선별"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 환경 설정 및 라이브러리 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import uuid\n",
    "import logging\n",
    "from typing import Dict, List, Any, Optional, Tuple\n",
    "from dataclasses import dataclass, asdict\n",
    "from datetime import datetime, timedelta\n",
    "from enum import Enum\n",
    "\n",
    "# 외부 라이브러리\n",
    "import redis\n",
    "from openai import OpenAI\n",
    "import tiktoken\n",
    "\n",
    "# 로컬 설정\n",
    "sys.path.append('..')\n",
    "from config import get_config\n",
    "\n",
    "config = get_config()\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"✅ 환경 설정 완료\")\n",
    "print(f\"📊 설정된 모델: {config.llm.openai_model}\")\n",
    "print(f\"🔧 최대 토큰: {config.llm.max_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 데이터 구조 정의\n",
    "\n",
    "대화 관리를 위한 핵심 데이터 클래스들을 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConversationState(Enum):\n",
    "    \"\"\"대화 상태 정의\"\"\"\n",
    "    GREETING = \"greeting\"\n",
    "    INFORMATION_SEEKING = \"information_seeking\"\n",
    "    TASK_EXECUTION = \"task_execution\"\n",
    "    PROBLEM_SOLVING = \"problem_solving\"\n",
    "    CASUAL_CHAT = \"casual_chat\"\n",
    "    ENDING = \"ending\"\n",
    "    UNKNOWN = \"unknown\"\n",
    "\n",
    "class MessageType(Enum):\n",
    "    \"\"\"메시지 유형\"\"\"\n",
    "    USER = \"user\"\n",
    "    ASSISTANT = \"assistant\"\n",
    "    SYSTEM = \"system\"\n",
    "    FUNCTION = \"function\"\n",
    "\n",
    "@dataclass\n",
    "class ConversationMessage:\n",
    "    \"\"\"대화 메시지 구조\"\"\"\n",
    "    id: str\n",
    "    role: MessageType\n",
    "    content: str\n",
    "    timestamp: datetime\n",
    "    metadata: Dict[str, Any]\n",
    "    tokens: int = 0\n",
    "    importance_score: float = 0.0\n",
    "    \n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        return {\n",
    "            'id': self.id,\n",
    "            'role': self.role.value,\n",
    "            'content': self.content,\n",
    "            'timestamp': self.timestamp.isoformat(),\n",
    "            'metadata': self.metadata,\n",
    "            'tokens': self.tokens,\n",
    "            'importance_score': self.importance_score\n",
    "        }\n",
    "\n",
    "# 테스트: 메시지 객체 생성\n",
    "test_message = ConversationMessage(\n",
    "    id=str(uuid.uuid4()),\n",
    "    role=MessageType.USER,\n",
    "    content=\"안녕하세요! AI 챗봇에 대해 알고 싶습니다.\",\n",
    "    timestamp=datetime.now(),\n",
    "    metadata={'source': 'test'}\n",
    ")\n",
    "\n",
    "print(\"✅ 데이터 구조 정의 완료\")\n",
    "print(f\"📝 테스트 메시지 ID: {test_message.id[:8]}...\")\n",
    "print(f\"🕐 생성 시간: {test_message.timestamp.strftime('%H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 세션 관리 시스템 구현\n",
    "\n",
    "Redis 기반으로 대화 세션을 관리하는 시스템을 구현합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SessionManager:\n",
    "    \"\"\"Redis 기반 세션 관리자\"\"\"\n",
    "    \n",
    "    def __init__(self, redis_url: str = None, session_timeout: int = 3600):\n",
    "        self.redis_url = redis_url or config.get_redis_url()\n",
    "        self.session_timeout = session_timeout\n",
    "        self.client = None\n",
    "        self.fallback_sessions = {}  # Redis 실패 시 메모리 백업\n",
    "        \n",
    "        self._init_redis()\n",
    "        logger.info(f\"세션 매니저 초기화 완료 - 만료시간: {session_timeout}초\")\n",
    "    \n",
    "    def _init_redis(self):\n",
    "        \"\"\"Redis 연결 초기화\"\"\"\n",
    "        try:\n",
    "            self.client = redis.from_url(\n",
    "                self.redis_url,\n",
    "                decode_responses=True,\n",
    "                socket_connect_timeout=5\n",
    "            )\n",
    "            self.client.ping()\n",
    "            logger.info(\"Redis 연결 성공\")\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Redis 연결 실패, 메모리 모드로 전환: {e}\")\n",
    "            self.client = None\n",
    "    \n",
    "    def create_session(self, user_id: str):\n",
    "        \"\"\"새 대화 세션 생성\"\"\"\n",
    "        session_id = str(uuid.uuid4())\n",
    "        now = datetime.now()\n",
    "        \n",
    "        session_data = {\n",
    "            'session_id': session_id,\n",
    "            'user_id': user_id,\n",
    "            'created_at': now.isoformat(),\n",
    "            'last_activity': now.isoformat(),\n",
    "            'messages': [],\n",
    "            'current_state': ConversationState.GREETING.value,\n",
    "            'total_tokens': 0,\n",
    "            'context_metadata': {\n",
    "                'topic_history': [],\n",
    "                'user_preferences': {}\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        self._save_session_data(session_id, session_data)\n",
    "        logger.info(f\"새 세션 생성: {session_id} (사용자: {user_id})\")\n",
    "        \n",
    "        return session_id, session_data\n",
    "    \n",
    "    def get_session(self, session_id: str) -> Optional[Dict]:\n",
    "        \"\"\"세션 조회\"\"\"\n",
    "        try:\n",
    "            if self.client:\n",
    "                session_data = self.client.get(f\"session:{session_id}\")\n",
    "                if session_data:\n",
    "                    return json.loads(session_data)\n",
    "            else:\n",
    "                return self.fallback_sessions.get(session_id)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"세션 조회 실패: {e}\")\n",
    "        return None\n",
    "    \n",
    "    def _save_session_data(self, session_id: str, data: Dict):\n",
    "        \"\"\"세션 데이터 저장\"\"\"\n",
    "        try:\n",
    "            session_json = json.dumps(data, ensure_ascii=False)\n",
    "            \n",
    "            if self.client:\n",
    "                self.client.setex(f\"session:{session_id}\", self.session_timeout, session_json)\n",
    "            else:\n",
    "                self.fallback_sessions[session_id] = data\n",
    "        except Exception as e:\n",
    "            logger.error(f\"세션 저장 실패: {e}\")\n",
    "    \n",
    "    def _count_tokens(self, text: str) -> int:\n",
    "        \"\"\"토큰 수 계산\"\"\"\n",
    "        try:\n",
    "            encoding = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "            return len(encoding.encode(text))\n",
    "        except:\n",
    "            # 대략적 계산\n",
    "            return len(text) // 4\n",
    "\n",
    "# 세션 관리자 테스트\n",
    "session_manager = SessionManager()\n",
    "test_session_id, test_session = session_manager.create_session(\"test_user\")\n",
    "\n",
    "print(\"✅ 세션 관리 시스템 구현 완료\")\n",
    "print(f\"🆔 테스트 세션 ID: {test_session_id[:8]}...\")\n",
    "print(f\"👤 사용자 ID: {test_session['user_id']}\")\n",
    "print(f\"🔄 현재 상태: {test_session['current_state']}\")\n",
    "print(f\"🔗 Redis 연결: {'성공' if session_manager.client else '메모리 모드'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 컨텍스트 윈도우 최적화\n",
    "\n",
    "토큰 제한을 고려한 컨텍스트 압축 및 최적화를 구현합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextWindowOptimizer:\n",
    "    \"\"\"컨텍스트 윈도우 최적화\"\"\"\n",
    "    \n",
    "    def __init__(self, max_tokens: int = 4000, compression_ratio: float = 0.5):\n",
    "        self.max_tokens = max_tokens\n",
    "        self.compression_ratio = compression_ratio\n",
    "        self.client = OpenAI(api_key=config.llm.openai_api_key)\n",
    "        \n",
    "        print(f\"✅ 컨텍스트 최적화기 초기화 - 최대 토큰: {max_tokens}\")\n",
    "    \n",
    "    def optimize_messages(self, messages: List[Dict], current_tokens: int) -> Tuple[List[Dict], Dict]:\n",
    "        \"\"\"메시지 최적화\"\"\"\n",
    "        print(f\"📊 컨텍스트 최적화 시작 - 현재 토큰: {current_tokens}\")\n",
    "        \n",
    "        if current_tokens <= self.max_tokens:\n",
    "            return messages, {'optimization': 'none', 'tokens': current_tokens}\n",
    "        \n",
    "        # 최근 메시지 우선 보존\n",
    "        target_tokens = int(self.max_tokens * self.compression_ratio)\n",
    "        optimized_messages = []\n",
    "        token_count = 0\n",
    "        \n",
    "        # 시스템 메시지는 항상 포함\n",
    "        system_messages = [msg for msg in messages if msg.get('role') == 'system']\n",
    "        optimized_messages.extend(system_messages)\n",
    "        token_count += sum(self._estimate_tokens(msg['content']) for msg in system_messages)\n",
    "        \n",
    "        # 최근 메시지부터 역순으로 추가\n",
    "        recent_messages = [msg for msg in messages if msg.get('role') != 'system']\n",
    "        for msg in reversed(recent_messages):\n",
    "            msg_tokens = self._estimate_tokens(msg['content'])\n",
    "            if token_count + msg_tokens <= target_tokens:\n",
    "                optimized_messages.insert(-len(system_messages) if system_messages else 0, msg)\n",
    "                token_count += msg_tokens\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        metadata = {\n",
    "            'optimization': 'token_filtering',\n",
    "            'original_count': len(messages),\n",
    "            'optimized_count': len(optimized_messages),\n",
    "            'original_tokens': current_tokens,\n",
    "            'optimized_tokens': token_count,\n",
    "            'compression_ratio': token_count / current_tokens if current_tokens > 0 else 0\n",
    "        }\n",
    "        \n",
    "        print(f\"🎯 최적화 완료: {len(messages)} -> {len(optimized_messages)} 메시지\")\n",
    "        print(f\"📉 토큰 압축: {current_tokens} -> {token_count} ({metadata['compression_ratio']:.1%})\")\n",
    "        \n",
    "        return optimized_messages, metadata\n",
    "    \n",
    "    def _estimate_tokens(self, text: str) -> int:\n",
    "        \"\"\"토큰 수 추정\"\"\"\n",
    "        try:\n",
    "            encoding = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "            return len(encoding.encode(text))\n",
    "        except:\n",
    "            return len(text) // 4\n",
    "\n",
    "    def create_conversation_summary(self, messages: List[Dict]) -> str:\n",
    "        \"\"\"대화 요약 생성\"\"\"\n",
    "        try:\n",
    "            conversation_text = \"\\n\".join([\n",
    "                f\"{msg['role']}: {msg['content'][:200]}...\"\n",
    "                for msg in messages if msg['role'] in ['user', 'assistant']\n",
    "            ])\n",
    "            \n",
    "            summary_prompt = f\"\"\"다음 대화를 간결하게 요약해주세요:\n",
    "\n",
    "{conversation_text}\n",
    "\n",
    "요약:\"\"\"\n",
    "            \n",
    "            response = self.client.chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"대화 내용을 간결하게 요약하세요.\"},\n",
    "                    {\"role\": \"user\", \"content\": summary_prompt}\n",
    "                ],\n",
    "                max_tokens=300,\n",
    "                temperature=0.3\n",
    "            )\n",
    "            \n",
    "            return response.choices[0].message.content\n",
    "        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"대화 요약 실패: {e}\")\n",
    "            return \"이전 대화 요약을 생성할 수 없습니다.\"\n",
    "\n",
    "# 컨텍스트 최적화 테스트\n",
    "optimizer = ContextWindowOptimizer(max_tokens=1000)\n",
    "\n",
    "# 테스트 메시지 생성\n",
    "test_messages = [\n",
    "    {\"role\": \"system\", \"content\": \"당신은 도움이 되는 AI 어시스턴트입니다.\"},\n",
    "    {\"role\": \"user\", \"content\": \"안녕하세요! AI에 대해 설명해주세요.\" * 50},  # 긴 메시지\n",
    "    {\"role\": \"assistant\", \"content\": \"안녕하세요! AI는 인공지능을 의미합니다.\" * 30},\n",
    "    {\"role\": \"user\", \"content\": \"더 자세히 알고 싶습니다.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"물론입니다! 더 자세히 설명해드리겠습니다.\"},\n",
    "]\n",
    "\n",
    "total_tokens = sum(optimizer._estimate_tokens(msg['content']) for msg in test_messages)\n",
    "optimized_messages, opt_metadata = optimizer.optimize_messages(test_messages, total_tokens)\n",
    "\n",
    "print(\"\\n📋 최적화 결과:\")\n",
    "for key, value in opt_metadata.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 의도 분류 및 대화 상태 관리\n",
    "\n",
    "사용자 의도를 분류하고 대화 상태를 추적하는 시스템을 구현합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntentClassifier:\n",
    "    \"\"\"의도 분류기\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.client = OpenAI(api_key=config.llm.openai_api_key)\n",
    "        \n",
    "        # 의도별 키워드 정의\n",
    "        self.intent_keywords = {\n",
    "            ConversationState.GREETING: ['안녕', '반갑', '처음', 'hello', 'hi'],\n",
    "            ConversationState.INFORMATION_SEEKING: ['알려', '설명', '뭐야', '무엇', '어떻게', '왜'],\n",
    "            ConversationState.TASK_EXECUTION: ['해줘', '만들어', '생성', '작성', '실행'],\n",
    "            ConversationState.PROBLEM_SOLVING: ['문제', '오류', '에러', '안돼', '도움'],\n",
    "            ConversationState.ENDING: ['고마워', '감사', '잘가', '안녕히', 'bye'],\n",
    "            ConversationState.CASUAL_CHAT: ['재미있', '웃긴', '농담', '이야기']\n",
    "        }\n",
    "        \n",
    "        print(\"✅ 의도 분류기 초기화 완료\")\n",
    "    \n",
    "    def classify_intent(self, message: str) -> ConversationState:\n",
    "        \"\"\"메시지의 의도 분류\"\"\"\n",
    "        print(f\"🎯 의도 분류: {message[:30]}...\")\n",
    "        \n",
    "        # 1단계: 키워드 기반 빠른 분류\n",
    "        quick_intent = self._classify_by_keywords(message)\n",
    "        if quick_intent != ConversationState.UNKNOWN:\n",
    "            print(f\"  ⚡ 키워드 매칭: {quick_intent.value}\")\n",
    "            return quick_intent\n",
    "        \n",
    "        # 2단계: LLM 기반 정확한 분류\n",
    "        return self._classify_by_llm(message)\n",
    "    \n",
    "    def _classify_by_keywords(self, message: str) -> ConversationState:\n",
    "        \"\"\"키워드 기반 빠른 의도 분류\"\"\"\n",
    "        message_lower = message.lower()\n",
    "        \n",
    "        for intent, keywords in self.intent_keywords.items():\n",
    "            if any(keyword in message_lower for keyword in keywords):\n",
    "                return intent\n",
    "        \n",
    "        return ConversationState.UNKNOWN\n",
    "    \n",
    "    def _classify_by_llm(self, message: str) -> ConversationState:\n",
    "        \"\"\"LLM 기반 정확한 의도 분류\"\"\"\n",
    "        try:\n",
    "            prompt = f\"\"\"다음 메시지의 의도를 분류하세요.\n",
    "\n",
    "가능한 의도:\n",
    "- greeting: 인사, 첫 만남\n",
    "- information_seeking: 정보 요청, 질문\n",
    "- task_execution: 작업 요청, 실행 명령\n",
    "- problem_solving: 문제 해결, 도움 요청\n",
    "- casual_chat: 일상 대화, 잡담\n",
    "- ending: 대화 종료, 작별인사\n",
    "\n",
    "메시지: {message}\n",
    "\n",
    "의도 (위 카테고리 중 하나만):\"\"\"\n",
    "            \n",
    "            response = self.client.chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"대화 의도를 정확하게 분류하세요.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                max_tokens=20,\n",
    "                temperature=0.1\n",
    "            )\n",
    "            \n",
    "            result = response.choices[0].message.content.strip().lower()\n",
    "            \n",
    "            # 결과를 ConversationState로 변환\n",
    "            intent_mapping = {\n",
    "                'greeting': ConversationState.GREETING,\n",
    "                'information_seeking': ConversationState.INFORMATION_SEEKING,\n",
    "                'task_execution': ConversationState.TASK_EXECUTION,\n",
    "                'problem_solving': ConversationState.PROBLEM_SOLVING,\n",
    "                'casual_chat': ConversationState.CASUAL_CHAT,\n",
    "                'ending': ConversationState.ENDING\n",
    "            }\n",
    "            \n",
    "            classified_intent = intent_mapping.get(result, ConversationState.UNKNOWN)\n",
    "            print(f\"  🤖 LLM 분류: {classified_intent.value}\")\n",
    "            \n",
    "            return classified_intent\n",
    "        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"LLM 의도 분류 실패: {e}\")\n",
    "            return ConversationState.UNKNOWN\n",
    "\n",
    "# 의도 분류 테스트\n",
    "classifier = IntentClassifier()\n",
    "\n",
    "test_messages = [\n",
    "    \"안녕하세요! 처음 뵙겠습니다.\",\n",
    "    \"Python으로 웹 크롤링하는 방법을 알려주세요.\",\n",
    "    \"코드를 작성해주세요.\",\n",
    "    \"오류가 발생했는데 도움이 필요합니다.\",\n",
    "    \"오늘 날씨가 좋네요.\",\n",
    "    \"감사합니다. 안녕히 계세요.\"\n",
    "]\n",
    "\n",
    "print(\"\\n🧪 의도 분류 테스트:\")\n",
    "for i, msg in enumerate(test_messages, 1):\n",
    "    intent = classifier.classify_intent(msg)\n",
    "    print(f\"{i}. '{msg[:30]}...' -> {intent.value}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 통합 멀티턴 챗봇 구현\n",
    "\n",
    "모든 컴포넌트를 통합한 완전한 멀티턴 대화 시스템을 구현합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTurnChatbot:\n",
    "    \"\"\"통합 멀티턴 대화 챗봇\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.session_manager = SessionManager()\n",
    "        self.context_optimizer = ContextWindowOptimizer()\n",
    "        self.intent_classifier = IntentClassifier()\n",
    "        self.client = OpenAI(api_key=config.llm.openai_api_key)\n",
    "        \n",
    "        print(\"✅ 멀티턴 챗봇 초기화 완료\")\n",
    "    \n",
    "    def start_conversation(self, user_id: str) -> str:\n",
    "        \"\"\"새 대화 시작\"\"\"\n",
    "        session_id, session_data = self.session_manager.create_session(user_id)\n",
    "        print(f\"🆕 새 대화 시작: {session_id[:8]}... (사용자: {user_id})\")\n",
    "        return session_id\n",
    "    \n",
    "    def chat(self, session_id: str, user_message: str) -> Dict[str, Any]:\n",
    "        \"\"\"대화 처리\"\"\"\n",
    "        start_time = time.time()\n",
    "        print(f\"\\n💬 대화 처리 시작: {user_message[:50]}...\")\n",
    "        \n",
    "        try:\n",
    "            # 1. 세션 조회\n",
    "            session_data = self.session_manager.get_session(session_id)\n",
    "            if not session_data:\n",
    "                return {'error': '세션을 찾을 수 없습니다'}\n",
    "            \n",
    "            # 2. 의도 분류\n",
    "            intent = self.intent_classifier.classify_intent(user_message)\n",
    "            \n",
    "            # 3. 사용자 메시지 추가\n",
    "            user_msg = {\n",
    "                'id': str(uuid.uuid4()),\n",
    "                'role': 'user',\n",
    "                'content': user_message,\n",
    "                'timestamp': datetime.now().isoformat(),\n",
    "                'metadata': {'intent': intent.value}\n",
    "            }\n",
    "            \n",
    "            session_data['messages'].append(user_msg)\n",
    "            session_data['current_state'] = intent.value\n",
    "            session_data['last_activity'] = datetime.now().isoformat()\n",
    "            \n",
    "            # 4. 컨텍스트 최적화\n",
    "            messages_for_api = [{'role': msg['role'], 'content': msg['content']} \n",
    "                               for msg in session_data['messages']]\n",
    "            \n",
    "            total_tokens = sum(self.context_optimizer._estimate_tokens(msg['content']) \n",
    "                             for msg in messages_for_api)\n",
    "            \n",
    "            optimized_messages, opt_metadata = self.context_optimizer.optimize_messages(\n",
    "                messages_for_api, total_tokens\n",
    "            )\n",
    "            \n",
    "            # 5. 시스템 프롬프트 추가\n",
    "            system_prompt = self._generate_system_prompt(intent)\n",
    "            final_messages = [{'role': 'system', 'content': system_prompt}] + optimized_messages\n",
    "            \n",
    "            # 6. AI 응답 생성\n",
    "            print(f\"🤖 AI 응답 생성 중... (메시지 수: {len(final_messages)})\")\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=config.llm.openai_model,\n",
    "                messages=final_messages,\n",
    "                temperature=config.llm.temperature,\n",
    "                max_tokens=config.llm.max_tokens\n",
    "            )\n",
    "            \n",
    "            ai_response = response.choices[0].message.content\n",
    "            tokens_used = response.usage.total_tokens\n",
    "            \n",
    "            # 7. AI 응답 저장\n",
    "            ai_msg = {\n",
    "                'id': str(uuid.uuid4()),\n",
    "                'role': 'assistant',\n",
    "                'content': ai_response,\n",
    "                'timestamp': datetime.now().isoformat(),\n",
    "                'metadata': {\n",
    "                    'model': config.llm.openai_model,\n",
    "                    'tokens': tokens_used,\n",
    "                    'state': intent.value\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            session_data['messages'].append(ai_msg)\n",
    "            session_data['total_tokens'] += tokens_used\n",
    "            \n",
    "            # 8. 세션 업데이트\n",
    "            self.session_manager._save_session_data(session_id, session_data)\n",
    "            \n",
    "            processing_time = time.time() - start_time\n",
    "            \n",
    "            # 결과 반환\n",
    "            result = {\n",
    "                'session_id': session_id,\n",
    "                'response': ai_response,\n",
    "                'intent': intent.value,\n",
    "                'conversation_state': session_data['current_state'],\n",
    "                'processing_time': processing_time,\n",
    "                'tokens_used': tokens_used,\n",
    "                'optimization': opt_metadata,\n",
    "                'session_stats': {\n",
    "                    'message_count': len(session_data['messages']),\n",
    "                    'total_tokens': session_data['total_tokens'],\n",
    "                    'session_age': (datetime.now() - datetime.fromisoformat(\n",
    "                        session_data['created_at'])).total_seconds()\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            print(f\"✅ 대화 처리 완료 - 시간: {processing_time:.2f}초, 토큰: {tokens_used}\")\n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"대화 처리 실패: {e}\")\n",
    "            return {'error': f'대화 처리 중 오류: {str(e)}'}\n",
    "    \n",
    "    def _generate_system_prompt(self, intent: ConversationState) -> str:\n",
    "        \"\"\"상태별 시스템 프롬프트 생성\"\"\"\n",
    "        base_prompt = \"당신은 도움이 되는 AI 어시스턴트입니다.\"\n",
    "        \n",
    "        state_prompts = {\n",
    "            ConversationState.GREETING: f\"{base_prompt} 사용자와 첫 만남이므로 친근하게 인사하세요.\",\n",
    "            ConversationState.INFORMATION_SEEKING: f\"{base_prompt} 정확한 정보를 제공하세요.\",\n",
    "            ConversationState.TASK_EXECUTION: f\"{base_prompt} 단계별로 명확한 안내를 제공하세요.\",\n",
    "            ConversationState.PROBLEM_SOLVING: f\"{base_prompt} 문제를 체계적으로 해결해주세요.\",\n",
    "            ConversationState.CASUAL_CHAT: f\"{base_prompt} 자연스럽고 친근한 대화를 하세요.\",\n",
    "            ConversationState.ENDING: f\"{base_prompt} 따뜻한 작별인사를 해주세요.\"\n",
    "        }\n",
    "        \n",
    "        return state_prompts.get(intent, base_prompt)\n",
    "    \n",
    "    def get_conversation_history(self, session_id: str) -> Dict[str, Any]:\n",
    "        \"\"\"대화 히스토리 조회\"\"\"\n",
    "        session_data = self.session_manager.get_session(session_id)\n",
    "        if not session_data:\n",
    "            return {'error': '세션을 찾을 수 없습니다'}\n",
    "        \n",
    "        return {\n",
    "            'session_id': session_id,\n",
    "            'user_id': session_data['user_id'],\n",
    "            'created_at': session_data['created_at'],\n",
    "            'current_state': session_data['current_state'],\n",
    "            'message_count': len(session_data['messages']),\n",
    "            'total_tokens': session_data['total_tokens'],\n",
    "            'messages': session_data['messages'][-10:],  # 최근 10개 메시지만\n",
    "        }\n",
    "\n",
    "print(\"✅ 멀티턴 챗봇 클래스 정의 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 멀티턴 대화 시나리오 테스트\n",
    "\n",
    "실제 대화 시나리오로 시스템을 테스트합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 멀티턴 챗봇 인스턴스 생성\n",
    "chatbot = MultiTurnChatbot()\n",
    "\n",
    "# 대화 시나리오 테스트\n",
    "print(\"🎬 멀티턴 대화 시나리오 테스트 시작\\n\")\n",
    "\n",
    "# 새 대화 시작\n",
    "session_id = chatbot.start_conversation(\"demo_user\")\n",
    "\n",
    "# 대화 시나리오\n",
    "conversation_script = [\n",
    "    \"안녕하세요! 처음 사용해봅니다.\",\n",
    "    \"Python으로 웹 크롤링을 배우고 싶은데, 어디서 시작해야 할까요?\",\n",
    "    \"requests와 BeautifulSoup을 사용한 예제 코드를 작성해주세요.\",\n",
    "    \"코드에서 오류가 발생했어요. 도움이 필요합니다.\",\n",
    "    \"정말 감사합니다. 많은 도움이 되었어요!\"\n",
    "]\n",
    "\n",
    "# 대화 진행\n",
    "conversation_results = []\n",
    "for i, user_msg in enumerate(conversation_script, 1):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"턴 {i}: 사용자 메시지\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"👤 사용자: {user_msg}\")\n",
    "    \n",
    "    # 챗봇 응답 생성\n",
    "    result = chatbot.chat(session_id, user_msg)\n",
    "    \n",
    "    if 'error' not in result:\n",
    "        print(f\"\\n🤖 AI ({result['intent']}): {result['response'][:200]}...\")\n",
    "        \n",
    "        # 처리 통계\n",
    "        print(f\"\\n📊 처리 통계:\")\n",
    "        print(f\"  ⏱️  처리 시간: {result['processing_time']:.2f}초\")\n",
    "        print(f\"  🎯 토큰 사용: {result['tokens_used']}\")\n",
    "        print(f\"  💬 메시지 수: {result['session_stats']['message_count']}\")\n",
    "        print(f\"  🔄 최적화: {result['optimization']['optimization']}\")\n",
    "        \n",
    "        if result['optimization']['optimization'] != 'none':\n",
    "            print(f\"  📉 압축률: {result['optimization'].get('compression_ratio', 0):.1%}\")\n",
    "        \n",
    "        conversation_results.append(result)\n",
    "    else:\n",
    "        print(f\"❌ 오류: {result['error']}\")\n",
    "        break\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"🎉 대화 시나리오 테스트 완료\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# 최종 세션 통계\n",
    "if conversation_results:\n",
    "    final_stats = conversation_results[-1]['session_stats']\n",
    "    print(f\"\\n📈 최종 세션 통계:\")\n",
    "    print(f\"  📝 총 메시지 수: {final_stats['message_count']}\")\n",
    "    print(f\"  🎯 총 토큰 사용: {final_stats['total_tokens']}\")\n",
    "    print(f\"  ⏰ 세션 지속 시간: {final_stats['session_age']:.0f}초\")\n",
    "    print(f\"  💰 평균 응답 시간: {sum(r['processing_time'] for r in conversation_results) / len(conversation_results):.2f}초\")\n",
    "\n",
    "# 대화 히스토리 조회\n",
    "print(f\"\\n📚 대화 히스토리:\")\n",
    "history = chatbot.get_conversation_history(session_id)\n",
    "if 'error' not in history:\n",
    "    print(f\"  세션 ID: {history['session_id'][:8]}...\")\n",
    "    print(f\"  사용자 ID: {history['user_id']}\")\n",
    "    print(f\"  현재 상태: {history['current_state']}\")\n",
    "    print(f\"  메시지 수: {history['message_count']}\")\n",
    "else:\n",
    "    print(f\"  ❌ 히스토리 조회 실패: {history['error']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 성능 최적화 및 모니터링\n",
    "\n",
    "대화 시스템의 성능을 분석하고 최적화 포인트를 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "def analyze_conversation_performance(results: List[Dict]) -> Dict[str, Any]:\n",
    "    \"\"\"대화 성능 분석\"\"\"\n",
    "    if not results:\n",
    "        return {}\n",
    "    \n",
    "    # 데이터 추출\n",
    "    processing_times = [r['processing_time'] for r in results]\n",
    "    token_usage = [r['tokens_used'] for r in results]\n",
    "    message_counts = [r['session_stats']['message_count'] for r in results]\n",
    "    intents = [r['intent'] for r in results]\n",
    "    \n",
    "    # 통계 계산\n",
    "    analysis = {\n",
    "        'performance_stats': {\n",
    "            'avg_processing_time': sum(processing_times) / len(processing_times),\n",
    "            'max_processing_time': max(processing_times),\n",
    "            'min_processing_time': min(processing_times),\n",
    "            'total_tokens': sum(token_usage),\n",
    "            'avg_tokens_per_turn': sum(token_usage) / len(token_usage),\n",
    "            'max_tokens_per_turn': max(token_usage)\n",
    "        },\n",
    "        'optimization_stats': {\n",
    "            'optimizations_applied': sum(1 for r in results if r['optimization']['optimization'] != 'none'),\n",
    "            'avg_compression_ratio': sum(\n",
    "                r['optimization'].get('compression_ratio', 0) \n",
    "                for r in results if r['optimization']['optimization'] != 'none'\n",
    "            ) / max(1, sum(1 for r in results if r['optimization']['optimization'] != 'none'))\n",
    "        },\n",
    "        'intent_distribution': {}\n",
    "    }\n",
    "    \n",
    "    # 의도 분포 계산\n",
    "    from collections import Counter\n",
    "    intent_counts = Counter(intents)\n",
    "    analysis['intent_distribution'] = dict(intent_counts)\n",
    "    \n",
    "    return analysis\n",
    "\n",
    "def visualize_performance(results: List[Dict]):\n",
    "    \"\"\"성능 시각화\"\"\"\n",
    "    if not results:\n",
    "        print(\"시각화할 데이터가 없습니다.\")\n",
    "        return\n",
    "    \n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle('멀티턴 대화 성능 분석', fontsize=16)\n",
    "    \n",
    "    # 1. 처리 시간 추이\n",
    "    turns = range(1, len(results) + 1)\n",
    "    processing_times = [r['processing_time'] for r in results]\n",
    "    ax1.plot(turns, processing_times, 'b-o', linewidth=2, markersize=6)\n",
    "    ax1.set_title('턴별 처리 시간')\n",
    "    ax1.set_xlabel('대화 턴')\n",
    "    ax1.set_ylabel('처리 시간 (초)')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. 토큰 사용량 추이\n",
    "    token_usage = [r['tokens_used'] for r in results]\n",
    "    ax2.bar(turns, token_usage, color='green', alpha=0.7)\n",
    "    ax2.set_title('턴별 토큰 사용량')\n",
    "    ax2.set_xlabel('대화 턴')\n",
    "    ax2.set_ylabel('토큰 수')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. 누적 메시지 수\n",
    "    message_counts = [r['session_stats']['message_count'] for r in results]\n",
    "    ax3.plot(turns, message_counts, 'r-s', linewidth=2, markersize=6)\n",
    "    ax3.set_title('누적 메시지 수')\n",
    "    ax3.set_xlabel('대화 턴')\n",
    "    ax3.set_ylabel('메시지 수')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. 의도 분포\n",
    "    from collections import Counter\n",
    "    intents = [r['intent'] for r in results]\n",
    "    intent_counts = Counter(intents)\n",
    "    ax4.pie(intent_counts.values(), labels=intent_counts.keys(), autopct='%1.1f%%')\n",
    "    ax4.set_title('의도 분포')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 성능 분석 실행\n",
    "if 'conversation_results' in locals() and conversation_results:\n",
    "    print(\"📊 성능 분석 시작...\\n\")\n",
    "    \n",
    "    analysis = analyze_conversation_performance(conversation_results)\n",
    "    \n",
    "    print(\"🎯 성능 통계:\")\n",
    "    perf_stats = analysis['performance_stats']\n",
    "    print(f\"  평균 처리 시간: {perf_stats['avg_processing_time']:.2f}초\")\n",
    "    print(f\"  최대 처리 시간: {perf_stats['max_processing_time']:.2f}초\")\n",
    "    print(f\"  총 토큰 사용: {perf_stats['total_tokens']}\")\n",
    "    print(f\"  턴당 평균 토큰: {perf_stats['avg_tokens_per_turn']:.0f}\")\n",
    "    \n",
    "    print(\"\\n🔧 최적화 통계:\")\n",
    "    opt_stats = analysis['optimization_stats']\n",
    "    print(f\"  최적화 적용 횟수: {opt_stats['optimizations_applied']}\")\n",
    "    if opt_stats['avg_compression_ratio'] > 0:\n",
    "        print(f\"  평균 압축률: {opt_stats['avg_compression_ratio']:.1%}\")\n",
    "    \n",
    "    print(\"\\n🎭 의도 분포:\")\n",
    "    for intent, count in analysis['intent_distribution'].items():\n",
    "        print(f\"  {intent}: {count}회\")\n",
    "    \n",
    "    # 성능 시각화\n",
    "    print(\"\\n📈 성능 차트 생성 중...\")\n",
    "    try:\n",
    "        visualize_performance(conversation_results)\n",
    "    except Exception as e:\n",
    "        print(f\"차트 생성 실패: {e}\")\n",
    "        print(\"Matplotlib 설치가 필요할 수 있습니다: pip install matplotlib\")\n",
    "else:\n",
    "    print(\"분석할 대화 데이터가 없습니다. 먼저 대화 시나리오를 실행해주세요.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 멀티 사용자 동시성 테스트\n",
    "\n",
    "여러 사용자가 동시에 대화할 때의 시스템 안정성을 테스트합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import concurrent.futures\n",
    "import threading\n",
    "from threading import Thread\n",
    "import time\n",
    "\n",
    "def simulate_user_conversation(chatbot: MultiTurnChatbot, user_id: str, messages: List[str]) -> Dict[str, Any]:\n",
    "    \"\"\"사용자 대화 시뮬레이션\"\"\"\n",
    "    print(f\"👤 사용자 {user_id} 대화 시작\")\n",
    "    \n",
    "    try:\n",
    "        # 새 세션 시작\n",
    "        session_id = chatbot.start_conversation(user_id)\n",
    "        \n",
    "        results = []\n",
    "        total_time = 0\n",
    "        \n",
    "        for i, message in enumerate(messages):\n",
    "            print(f\"  {user_id}: {message[:30]}...\")\n",
    "            \n",
    "            result = chatbot.chat(session_id, message)\n",
    "            \n",
    "            if 'error' not in result:\n",
    "                results.append(result)\n",
    "                total_time += result['processing_time']\n",
    "                print(f\"  ✅ 응답 완료 ({result['processing_time']:.2f}초)\")\n",
    "            else:\n",
    "                print(f\"  ❌ 오류: {result['error']}\")\n",
    "                break\n",
    "            \n",
    "            # 사용자 간 메시지 간격 시뮬레이션\n",
    "            time.sleep(0.5)\n",
    "        \n",
    "        return {\n",
    "            'user_id': user_id,\n",
    "            'session_id': session_id,\n",
    "            'total_messages': len(results),\n",
    "            'total_time': total_time,\n",
    "            'avg_response_time': total_time / len(results) if results else 0,\n",
    "            'results': results\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"  ❌ 사용자 {user_id} 대화 실패: {e}\")\n",
    "        return {'user_id': user_id, 'error': str(e)}\n",
    "\n",
    "def run_concurrent_conversations():\n",
    "    \"\"\"동시 대화 테스트 실행\"\"\"\n",
    "    print(\"🔄 멀티 사용자 동시성 테스트 시작\\n\")\n",
    "    \n",
    "    # 사용자별 대화 시나리오\n",
    "    user_scenarios = {\n",
    "        'user_1': [\n",
    "            \"안녕하세요!\",\n",
    "            \"Python 기초를 배우고 싶어요.\",\n",
    "            \"변수와 함수에 대해 설명해주세요.\"\n",
    "        ],\n",
    "        'user_2': [\n",
    "            \"반갑습니다.\",\n",
    "            \"웹 개발을 시작하려면 어떻게 해야 하나요?\",\n",
    "            \"HTML과 CSS부터 배워야 할까요?\"\n",
    "        ],\n",
    "        'user_3': [\n",
    "            \"처음 사용해봅니다.\",\n",
    "            \"데이터 분석에 관심이 있어요.\",\n",
    "            \"pandas 라이브러리 사용법을 알려주세요.\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # 동시성 테스트를 위한 스레드 풀\n",
    "    start_time = time.time()\n",
    "    \n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:\n",
    "        # 각 사용자별로 병렬 대화 시작\n",
    "        future_to_user = {\n",
    "            executor.submit(\n",
    "                simulate_user_conversation, \n",
    "                chatbot, \n",
    "                user_id, \n",
    "                messages\n",
    "            ): user_id\n",
    "            for user_id, messages in user_scenarios.items()\n",
    "        }\n",
    "        \n",
    "        # 결과 수집\n",
    "        concurrent_results = []\n",
    "        for future in concurrent.futures.as_completed(future_to_user):\n",
    "            user_id = future_to_user[future]\n",
    "            try:\n",
    "                result = future.result()\n",
    "                concurrent_results.append(result)\n",
    "                print(f\"✅ {user_id} 완료\")\n",
    "            except Exception as exc:\n",
    "                print(f\"❌ {user_id} 실패: {exc}\")\n",
    "    \n",
    "    total_test_time = time.time() - start_time\n",
    "    \n",
    "    # 결과 분석\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(\"🎉 동시성 테스트 완료\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"📊 전체 테스트 시간: {total_test_time:.2f}초\")\n",
    "    print(f\"👥 동시 사용자 수: {len(user_scenarios)}\")\n",
    "    \n",
    "    successful_users = [r for r in concurrent_results if 'error' not in r]\n",
    "    \n",
    "    if successful_users:\n",
    "        print(f\"✅ 성공한 사용자: {len(successful_users)}/{len(user_scenarios)}\")\n",
    "        \n",
    "        avg_response_times = [r['avg_response_time'] for r in successful_users]\n",
    "        total_messages = sum(r['total_messages'] for r in successful_users)\n",
    "        \n",
    "        print(f\"\\n📈 성능 메트릭:\")\n",
    "        print(f\"  총 처리된 메시지: {total_messages}개\")\n",
    "        print(f\"  평균 응답 시간: {sum(avg_response_times) / len(avg_response_times):.2f}초\")\n",
    "        print(f\"  메시지 처리율: {total_messages / total_test_time:.1f} 메시지/초\")\n",
    "        \n",
    "        # 사용자별 상세 결과\n",
    "        print(f\"\\n👤 사용자별 결과:\")\n",
    "        for result in successful_users:\n",
    "            print(f\"  {result['user_id']}: {result['total_messages']}메시지, \"\n",
    "                  f\"평균 {result['avg_response_time']:.2f}초\")\n",
    "    else:\n",
    "        print(\"❌ 모든 사용자 대화가 실패했습니다.\")\n",
    "    \n",
    "    return concurrent_results\n",
    "\n",
    "# 동시성 테스트 실행\n",
    "try:\n",
    "    concurrent_test_results = run_concurrent_conversations()\n",
    "    \n",
    "    # Redis 연결 상태 확인\n",
    "    print(f\"\\n🔗 시스템 상태:\")\n",
    "    print(f\"  Redis 연결: {'활성' if chatbot.session_manager.client else '메모리 모드'}\")\n",
    "    print(f\"  세션 관리: {'분산 저장' if chatbot.session_manager.client else '로컬 메모리'}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ 동시성 테스트 실패: {e}\")\n",
    "    print(\"일부 환경에서는 멀티스레딩 제한이 있을 수 있습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 실습 정리 및 확장 아이디어\n",
    "\n",
    "4차시 실습의 핵심 내용을 정리하고 확장 가능한 아이디어를 제시합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_lesson4_summary():\n",
    "    \"\"\"4차시 실습 요약\"\"\"\n",
    "    print(\"\"\"\\n📚 4차시 실습 요약: 대화 상태 관리 & 멀티턴 최적화\n",
    "    \n",
    "🎯 달성한 학습 목표:\n",
    "✅ Redis 기반 세션 관리 시스템 구현\n",
    "✅ 컨텍스트 윈도우 최적화 (토큰 기반 압축)\n",
    "✅ 의도 분류 및 대화 상태 추적\n",
    "✅ 멀티 사용자 동시성 처리\n",
    "✅ 성능 모니터링 및 분석\n",
    "\n",
    "🔧 핵심 구현 사항:\n",
    "• SessionManager: Redis/메모리 하이브리드 세션 관리\n",
    "• ContextWindowOptimizer: 중요도 기반 메시지 필터링 & 요약\n",
    "• IntentClassifier: 키워드 + LLM 하이브리드 의도 분류\n",
    "• MultiTurnChatbot: 통합 대화 관리 시스템\n",
    "\n",
    "📊 성능 특징:\n",
    "• 세션 기반 상태 관리로 일관된 대화 유지\n",
    "• 토큰 최적화로 비용 효율성 확보\n",
    "• 동시 사용자 지원으로 확장성 보장\n",
    "• 실시간 성능 모니터링\n",
    "\n",
    "🚀 확장 아이디어:\n",
    "1. 고도화된 컨텍스트 관리\n",
    "   - 벡터 기반 의미론적 유사성 계산\n",
    "   - 장기/단기 메모리 분리\n",
    "   - 사용자별 개인화 컨텍스트\n",
    "\n",
    "2. 지능형 대화 흐름\n",
    "   - 감정 분석 기반 톤 조절\n",
    "   - 목표 지향적 대화 가이드\n",
    "   - 다단계 태스크 관리\n",
    "\n",
    "3. 고급 최적화\n",
    "   - 적응형 토큰 할당\n",
    "   - 예측적 컨텍스트 로딩\n",
    "   - 모델별 최적화 전략\n",
    "\n",
    "4. 운영 모니터링\n",
    "   - 실시간 대시보드\n",
    "   - 이상 상황 알림\n",
    "   - A/B 테스트 프레임워크\n",
    "\n",
    "5. 멀티모달 확장\n",
    "   - 음성 대화 상태 관리\n",
    "   - 이미지 기반 컨텍스트\n",
    "   - 크로스 모달리티 세션\"\"\")\n",
    "\n",
    "def suggest_next_steps():\n",
    "    \"\"\"다음 단계 제안\"\"\"\n",
    "    print(\"\"\"\\n🎓 다음 학습 단계 제안:\n",
    "\n",
    "📖 심화 학습:\n",
    "• LangChain Memory 모듈 활용\n",
    "• Semantic Kernel의 대화 관리\n",
    "• 분산 시스템에서의 세션 관리\n",
    "• 대화 품질 평가 메트릭\n",
    "\n",
    "🛠️ 실전 프로젝트:\n",
    "• 고객 서비스 챗봇 (장기 컨텍스트)\n",
    "• 교육용 튜터 시스템 (개인화 학습 추적)\n",
    "• 게임 NPC (상태 기반 대화)\n",
    "• 상담 봇 (감정 상태 관리)\n",
    "\n",
    "🔗 연관 기술:\n",
    "• Vector databases (Pinecone, Weaviate)\n",
    "• Stream processing (Kafka, Redis Streams)\n",
    "• Monitoring tools (Prometheus, Grafana)\n",
    "• A/B testing platforms\"\"\")\n",
    "\n",
    "# 실습 요약 출력\n",
    "print_lesson4_summary()\n",
    "suggest_next_steps()\n",
    "\n",
    "# 실습 완료 확인\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"🎉 4차시 실습이 성공적으로 완료되었습니다!\")\n",
    "print(\"📝 다음은 5차시: 외부 연동 & Tool Calling입니다.\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 실습 체크리스트\n",
    "checklist = [\n",
    "    \"✅ Redis 기반 세션 관리 구현\",\n",
    "    \"✅ 컨텍스트 윈도우 최적화 적용\", \n",
    "    \"✅ 의도 분류 시스템 동작\",\n",
    "    \"✅ 멀티턴 대화 시나리오 테스트\",\n",
    "    \"✅ 동시 사용자 처리 확인\",\n",
    "    \"✅ 성능 메트릭 수집 및 분석\"\n",
    "]\n",
    "\n",
    "print(\"\\n📋 실습 체크리스트:\")\n",
    "for item in checklist:\n",
    "    print(f\"  {item}\")\n",
    "\n",
    "print(\"\\n🔜 다음 실습 예고:\")\n",
    "print(\"  • OpenAI Function Calling\")\n",
    "print(\"  • 외부 API 연동 (날씨, 검색 등)\")\n",
    "print(\"  • 데이터베이스 연동\")\n",
    "print(\"  • Tool 기반 에이전트 구현\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}