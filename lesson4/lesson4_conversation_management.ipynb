{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4ì°¨ì‹œ: ëŒ€í™” ìƒíƒœ ê´€ë¦¬ & ë©€í‹°í„´ ìµœì í™”\n",
    "\n",
    "## í•™ìŠµ ëª©í‘œ\n",
    "- Redis ê¸°ë°˜ ì„¸ì…˜ ê´€ë¦¬ ì´í•´\n",
    "- ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš° ìµœì í™” êµ¬í˜„\n",
    "- ëŒ€í™” ìƒíƒœ ì¶”ì  ë° íë¦„ ì œì–´\n",
    "- ë©€í‹° ì‚¬ìš©ì í™˜ê²½ì—ì„œì˜ ë™ì‹œì„± ì²˜ë¦¬\n",
    "\n",
    "## ì£¼ìš” êµ¬í˜„ ë‚´ìš©\n",
    "1. **ì„¸ì…˜ ê´€ë¦¬ ì‹œìŠ¤í…œ**: Redis ê¸°ë°˜ ëŒ€í™” íˆìŠ¤í† ë¦¬ ì €ì¥\n",
    "2. **ì»¨í…ìŠ¤íŠ¸ ìµœì í™”**: í† í° ìˆ˜ ê¸°ë°˜ ë©”ì‹œì§€ ì••ì¶•\n",
    "3. **ëŒ€í™” íë¦„ ì œì–´**: ì˜ë„ ë¶„ë¥˜ ë° ìƒíƒœ ì „í™˜\n",
    "4. **ë©€í‹°í„´ ìµœì í™”**: ì¤‘ìš”ë„ ê¸°ë°˜ ë©”ì‹œì§€ ì„ ë³„"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. í™˜ê²½ ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import uuid\n",
    "import logging\n",
    "from typing import Dict, List, Any, Optional, Tuple\n",
    "from dataclasses import dataclass, asdict\n",
    "from datetime import datetime, timedelta\n",
    "from enum import Enum\n",
    "\n",
    "# ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "import redis\n",
    "from openai import OpenAI\n",
    "import tiktoken\n",
    "\n",
    "# ë¡œì»¬ ì„¤ì •\n",
    "sys.path.append('..')\n",
    "from config import get_config\n",
    "\n",
    "config = get_config()\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"âœ… í™˜ê²½ ì„¤ì • ì™„ë£Œ\")\n",
    "print(f\"ğŸ“Š ì„¤ì •ëœ ëª¨ë¸: {config.llm.openai_model}\")\n",
    "print(f\"ğŸ”§ ìµœëŒ€ í† í°: {config.llm.max_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ë°ì´í„° êµ¬ì¡° ì •ì˜\n",
    "\n",
    "ëŒ€í™” ê´€ë¦¬ë¥¼ ìœ„í•œ í•µì‹¬ ë°ì´í„° í´ë˜ìŠ¤ë“¤ì„ ì •ì˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConversationState(Enum):\n",
    "    \"\"\"ëŒ€í™” ìƒíƒœ ì •ì˜\"\"\"\n",
    "    GREETING = \"greeting\"\n",
    "    INFORMATION_SEEKING = \"information_seeking\"\n",
    "    TASK_EXECUTION = \"task_execution\"\n",
    "    PROBLEM_SOLVING = \"problem_solving\"\n",
    "    CASUAL_CHAT = \"casual_chat\"\n",
    "    ENDING = \"ending\"\n",
    "    UNKNOWN = \"unknown\"\n",
    "\n",
    "class MessageType(Enum):\n",
    "    \"\"\"ë©”ì‹œì§€ ìœ í˜•\"\"\"\n",
    "    USER = \"user\"\n",
    "    ASSISTANT = \"assistant\"\n",
    "    SYSTEM = \"system\"\n",
    "    FUNCTION = \"function\"\n",
    "\n",
    "@dataclass\n",
    "class ConversationMessage:\n",
    "    \"\"\"ëŒ€í™” ë©”ì‹œì§€ êµ¬ì¡°\"\"\"\n",
    "    id: str\n",
    "    role: MessageType\n",
    "    content: str\n",
    "    timestamp: datetime\n",
    "    metadata: Dict[str, Any]\n",
    "    tokens: int = 0\n",
    "    importance_score: float = 0.0\n",
    "    \n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        return {\n",
    "            'id': self.id,\n",
    "            'role': self.role.value,\n",
    "            'content': self.content,\n",
    "            'timestamp': self.timestamp.isoformat(),\n",
    "            'metadata': self.metadata,\n",
    "            'tokens': self.tokens,\n",
    "            'importance_score': self.importance_score\n",
    "        }\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸: ë©”ì‹œì§€ ê°ì²´ ìƒì„±\n",
    "test_message = ConversationMessage(\n",
    "    id=str(uuid.uuid4()),\n",
    "    role=MessageType.USER,\n",
    "    content=\"ì•ˆë…•í•˜ì„¸ìš”! AI ì±—ë´‡ì— ëŒ€í•´ ì•Œê³  ì‹¶ìŠµë‹ˆë‹¤.\",\n",
    "    timestamp=datetime.now(),\n",
    "    metadata={'source': 'test'}\n",
    ")\n",
    "\n",
    "print(\"âœ… ë°ì´í„° êµ¬ì¡° ì •ì˜ ì™„ë£Œ\")\n",
    "print(f\"ğŸ“ í…ŒìŠ¤íŠ¸ ë©”ì‹œì§€ ID: {test_message.id[:8]}...\")\n",
    "print(f\"ğŸ• ìƒì„± ì‹œê°„: {test_message.timestamp.strftime('%H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ì„¸ì…˜ ê´€ë¦¬ ì‹œìŠ¤í…œ êµ¬í˜„\n",
    "\n",
    "Redis ê¸°ë°˜ìœ¼ë¡œ ëŒ€í™” ì„¸ì…˜ì„ ê´€ë¦¬í•˜ëŠ” ì‹œìŠ¤í…œì„ êµ¬í˜„í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SessionManager:\n",
    "    \"\"\"Redis ê¸°ë°˜ ì„¸ì…˜ ê´€ë¦¬ì\"\"\"\n",
    "    \n",
    "    def __init__(self, redis_url: str = None, session_timeout: int = 3600):\n",
    "        self.redis_url = redis_url or config.get_redis_url()\n",
    "        self.session_timeout = session_timeout\n",
    "        self.client = None\n",
    "        self.fallback_sessions = {}  # Redis ì‹¤íŒ¨ ì‹œ ë©”ëª¨ë¦¬ ë°±ì—…\n",
    "        \n",
    "        self._init_redis()\n",
    "        logger.info(f\"ì„¸ì…˜ ë§¤ë‹ˆì € ì´ˆê¸°í™” ì™„ë£Œ - ë§Œë£Œì‹œê°„: {session_timeout}ì´ˆ\")\n",
    "    \n",
    "    def _init_redis(self):\n",
    "        \"\"\"Redis ì—°ê²° ì´ˆê¸°í™”\"\"\"\n",
    "        try:\n",
    "            self.client = redis.from_url(\n",
    "                self.redis_url,\n",
    "                decode_responses=True,\n",
    "                socket_connect_timeout=5\n",
    "            )\n",
    "            self.client.ping()\n",
    "            logger.info(\"Redis ì—°ê²° ì„±ê³µ\")\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Redis ì—°ê²° ì‹¤íŒ¨, ë©”ëª¨ë¦¬ ëª¨ë“œë¡œ ì „í™˜: {e}\")\n",
    "            self.client = None\n",
    "    \n",
    "    def create_session(self, user_id: str):\n",
    "        \"\"\"ìƒˆ ëŒ€í™” ì„¸ì…˜ ìƒì„±\"\"\"\n",
    "        session_id = str(uuid.uuid4())\n",
    "        now = datetime.now()\n",
    "        \n",
    "        session_data = {\n",
    "            'session_id': session_id,\n",
    "            'user_id': user_id,\n",
    "            'created_at': now.isoformat(),\n",
    "            'last_activity': now.isoformat(),\n",
    "            'messages': [],\n",
    "            'current_state': ConversationState.GREETING.value,\n",
    "            'total_tokens': 0,\n",
    "            'context_metadata': {\n",
    "                'topic_history': [],\n",
    "                'user_preferences': {}\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        self._save_session_data(session_id, session_data)\n",
    "        logger.info(f\"ìƒˆ ì„¸ì…˜ ìƒì„±: {session_id} (ì‚¬ìš©ì: {user_id})\")\n",
    "        \n",
    "        return session_id, session_data\n",
    "    \n",
    "    def get_session(self, session_id: str) -> Optional[Dict]:\n",
    "        \"\"\"ì„¸ì…˜ ì¡°íšŒ\"\"\"\n",
    "        try:\n",
    "            if self.client:\n",
    "                session_data = self.client.get(f\"session:{session_id}\")\n",
    "                if session_data:\n",
    "                    return json.loads(session_data)\n",
    "            else:\n",
    "                return self.fallback_sessions.get(session_id)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"ì„¸ì…˜ ì¡°íšŒ ì‹¤íŒ¨: {e}\")\n",
    "        return None\n",
    "    \n",
    "    def _save_session_data(self, session_id: str, data: Dict):\n",
    "        \"\"\"ì„¸ì…˜ ë°ì´í„° ì €ì¥\"\"\"\n",
    "        try:\n",
    "            session_json = json.dumps(data, ensure_ascii=False)\n",
    "            \n",
    "            if self.client:\n",
    "                self.client.setex(f\"session:{session_id}\", self.session_timeout, session_json)\n",
    "            else:\n",
    "                self.fallback_sessions[session_id] = data\n",
    "        except Exception as e:\n",
    "            logger.error(f\"ì„¸ì…˜ ì €ì¥ ì‹¤íŒ¨: {e}\")\n",
    "    \n",
    "    def _count_tokens(self, text: str) -> int:\n",
    "        \"\"\"í† í° ìˆ˜ ê³„ì‚°\"\"\"\n",
    "        try:\n",
    "            encoding = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "            return len(encoding.encode(text))\n",
    "        except:\n",
    "            # ëŒ€ëµì  ê³„ì‚°\n",
    "            return len(text) // 4\n",
    "\n",
    "# ì„¸ì…˜ ê´€ë¦¬ì í…ŒìŠ¤íŠ¸\n",
    "session_manager = SessionManager()\n",
    "test_session_id, test_session = session_manager.create_session(\"test_user\")\n",
    "\n",
    "print(\"âœ… ì„¸ì…˜ ê´€ë¦¬ ì‹œìŠ¤í…œ êµ¬í˜„ ì™„ë£Œ\")\n",
    "print(f\"ğŸ†” í…ŒìŠ¤íŠ¸ ì„¸ì…˜ ID: {test_session_id[:8]}...\")\n",
    "print(f\"ğŸ‘¤ ì‚¬ìš©ì ID: {test_session['user_id']}\")\n",
    "print(f\"ğŸ”„ í˜„ì¬ ìƒíƒœ: {test_session['current_state']}\")\n",
    "print(f\"ğŸ”— Redis ì—°ê²°: {'ì„±ê³µ' if session_manager.client else 'ë©”ëª¨ë¦¬ ëª¨ë“œ'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš° ìµœì í™”\n",
    "\n",
    "í† í° ì œí•œì„ ê³ ë ¤í•œ ì»¨í…ìŠ¤íŠ¸ ì••ì¶• ë° ìµœì í™”ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextWindowOptimizer:\n",
    "    \"\"\"ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš° ìµœì í™”\"\"\"\n",
    "    \n",
    "    def __init__(self, max_tokens: int = 4000, compression_ratio: float = 0.5):\n",
    "        self.max_tokens = max_tokens\n",
    "        self.compression_ratio = compression_ratio\n",
    "        self.client = OpenAI(api_key=config.llm.openai_api_key)\n",
    "        \n",
    "        print(f\"âœ… ì»¨í…ìŠ¤íŠ¸ ìµœì í™”ê¸° ì´ˆê¸°í™” - ìµœëŒ€ í† í°: {max_tokens}\")\n",
    "    \n",
    "    def optimize_messages(self, messages: List[Dict], current_tokens: int) -> Tuple[List[Dict], Dict]:\n",
    "        \"\"\"ë©”ì‹œì§€ ìµœì í™”\"\"\"\n",
    "        print(f\"ğŸ“Š ì»¨í…ìŠ¤íŠ¸ ìµœì í™” ì‹œì‘ - í˜„ì¬ í† í°: {current_tokens}\")\n",
    "        \n",
    "        if current_tokens <= self.max_tokens:\n",
    "            return messages, {'optimization': 'none', 'tokens': current_tokens}\n",
    "        \n",
    "        # ìµœê·¼ ë©”ì‹œì§€ ìš°ì„  ë³´ì¡´\n",
    "        target_tokens = int(self.max_tokens * self.compression_ratio)\n",
    "        optimized_messages = []\n",
    "        token_count = 0\n",
    "        \n",
    "        # ì‹œìŠ¤í…œ ë©”ì‹œì§€ëŠ” í•­ìƒ í¬í•¨\n",
    "        system_messages = [msg for msg in messages if msg.get('role') == 'system']\n",
    "        optimized_messages.extend(system_messages)\n",
    "        token_count += sum(self._estimate_tokens(msg['content']) for msg in system_messages)\n",
    "        \n",
    "        # ìµœê·¼ ë©”ì‹œì§€ë¶€í„° ì—­ìˆœìœ¼ë¡œ ì¶”ê°€\n",
    "        recent_messages = [msg for msg in messages if msg.get('role') != 'system']\n",
    "        for msg in reversed(recent_messages):\n",
    "            msg_tokens = self._estimate_tokens(msg['content'])\n",
    "            if token_count + msg_tokens <= target_tokens:\n",
    "                optimized_messages.insert(-len(system_messages) if system_messages else 0, msg)\n",
    "                token_count += msg_tokens\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        metadata = {\n",
    "            'optimization': 'token_filtering',\n",
    "            'original_count': len(messages),\n",
    "            'optimized_count': len(optimized_messages),\n",
    "            'original_tokens': current_tokens,\n",
    "            'optimized_tokens': token_count,\n",
    "            'compression_ratio': token_count / current_tokens if current_tokens > 0 else 0\n",
    "        }\n",
    "        \n",
    "        print(f\"ğŸ¯ ìµœì í™” ì™„ë£Œ: {len(messages)} -> {len(optimized_messages)} ë©”ì‹œì§€\")\n",
    "        print(f\"ğŸ“‰ í† í° ì••ì¶•: {current_tokens} -> {token_count} ({metadata['compression_ratio']:.1%})\")\n",
    "        \n",
    "        return optimized_messages, metadata\n",
    "    \n",
    "    def _estimate_tokens(self, text: str) -> int:\n",
    "        \"\"\"í† í° ìˆ˜ ì¶”ì •\"\"\"\n",
    "        try:\n",
    "            encoding = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "            return len(encoding.encode(text))\n",
    "        except:\n",
    "            return len(text) // 4\n",
    "\n",
    "    def create_conversation_summary(self, messages: List[Dict]) -> str:\n",
    "        \"\"\"ëŒ€í™” ìš”ì•½ ìƒì„±\"\"\"\n",
    "        try:\n",
    "            conversation_text = \"\\n\".join([\n",
    "                f\"{msg['role']}: {msg['content'][:200]}...\"\n",
    "                for msg in messages if msg['role'] in ['user', 'assistant']\n",
    "            ])\n",
    "            \n",
    "            summary_prompt = f\"\"\"ë‹¤ìŒ ëŒ€í™”ë¥¼ ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”:\n",
    "\n",
    "{conversation_text}\n",
    "\n",
    "ìš”ì•½:\"\"\"\n",
    "            \n",
    "            response = self.client.chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"ëŒ€í™” ë‚´ìš©ì„ ê°„ê²°í•˜ê²Œ ìš”ì•½í•˜ì„¸ìš”.\"},\n",
    "                    {\"role\": \"user\", \"content\": summary_prompt}\n",
    "                ],\n",
    "                max_tokens=300,\n",
    "                temperature=0.3\n",
    "            )\n",
    "            \n",
    "            return response.choices[0].message.content\n",
    "        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"ëŒ€í™” ìš”ì•½ ì‹¤íŒ¨: {e}\")\n",
    "            return \"ì´ì „ ëŒ€í™” ìš”ì•½ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "# ì»¨í…ìŠ¤íŠ¸ ìµœì í™” í…ŒìŠ¤íŠ¸\n",
    "optimizer = ContextWindowOptimizer(max_tokens=1000)\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë©”ì‹œì§€ ìƒì„±\n",
    "test_messages = [\n",
    "    {\"role\": \"system\", \"content\": \"ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\"},\n",
    "    {\"role\": \"user\", \"content\": \"ì•ˆë…•í•˜ì„¸ìš”! AIì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.\" * 50},  # ê¸´ ë©”ì‹œì§€\n",
    "    {\"role\": \"assistant\", \"content\": \"ì•ˆë…•í•˜ì„¸ìš”! AIëŠ” ì¸ê³µì§€ëŠ¥ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.\" * 30},\n",
    "    {\"role\": \"user\", \"content\": \"ë” ìì„¸íˆ ì•Œê³  ì‹¶ìŠµë‹ˆë‹¤.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"ë¬¼ë¡ ì…ë‹ˆë‹¤! ë” ìì„¸íˆ ì„¤ëª…í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\"},\n",
    "]\n",
    "\n",
    "total_tokens = sum(optimizer._estimate_tokens(msg['content']) for msg in test_messages)\n",
    "optimized_messages, opt_metadata = optimizer.optimize_messages(test_messages, total_tokens)\n",
    "\n",
    "print(\"\\nğŸ“‹ ìµœì í™” ê²°ê³¼:\")\n",
    "for key, value in opt_metadata.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ì˜ë„ ë¶„ë¥˜ ë° ëŒ€í™” ìƒíƒœ ê´€ë¦¬\n",
    "\n",
    "ì‚¬ìš©ì ì˜ë„ë¥¼ ë¶„ë¥˜í•˜ê³  ëŒ€í™” ìƒíƒœë¥¼ ì¶”ì í•˜ëŠ” ì‹œìŠ¤í…œì„ êµ¬í˜„í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntentClassifier:\n",
    "    \"\"\"ì˜ë„ ë¶„ë¥˜ê¸°\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.client = OpenAI(api_key=config.llm.openai_api_key)\n",
    "        \n",
    "        # ì˜ë„ë³„ í‚¤ì›Œë“œ ì •ì˜\n",
    "        self.intent_keywords = {\n",
    "            ConversationState.GREETING: ['ì•ˆë…•', 'ë°˜ê°‘', 'ì²˜ìŒ', 'hello', 'hi'],\n",
    "            ConversationState.INFORMATION_SEEKING: ['ì•Œë ¤', 'ì„¤ëª…', 'ë­ì•¼', 'ë¬´ì—‡', 'ì–´ë–»ê²Œ', 'ì™œ'],\n",
    "            ConversationState.TASK_EXECUTION: ['í•´ì¤˜', 'ë§Œë“¤ì–´', 'ìƒì„±', 'ì‘ì„±', 'ì‹¤í–‰'],\n",
    "            ConversationState.PROBLEM_SOLVING: ['ë¬¸ì œ', 'ì˜¤ë¥˜', 'ì—ëŸ¬', 'ì•ˆë¼', 'ë„ì›€'],\n",
    "            ConversationState.ENDING: ['ê³ ë§ˆì›Œ', 'ê°ì‚¬', 'ì˜ê°€', 'ì•ˆë…•íˆ', 'bye'],\n",
    "            ConversationState.CASUAL_CHAT: ['ì¬ë¯¸ìˆ', 'ì›ƒê¸´', 'ë†ë‹´', 'ì´ì•¼ê¸°']\n",
    "        }\n",
    "        \n",
    "        print(\"âœ… ì˜ë„ ë¶„ë¥˜ê¸° ì´ˆê¸°í™” ì™„ë£Œ\")\n",
    "    \n",
    "    def classify_intent(self, message: str) -> ConversationState:\n",
    "        \"\"\"ë©”ì‹œì§€ì˜ ì˜ë„ ë¶„ë¥˜\"\"\"\n",
    "        print(f\"ğŸ¯ ì˜ë„ ë¶„ë¥˜: {message[:30]}...\")\n",
    "        \n",
    "        # 1ë‹¨ê³„: í‚¤ì›Œë“œ ê¸°ë°˜ ë¹ ë¥¸ ë¶„ë¥˜\n",
    "        quick_intent = self._classify_by_keywords(message)\n",
    "        if quick_intent != ConversationState.UNKNOWN:\n",
    "            print(f\"  âš¡ í‚¤ì›Œë“œ ë§¤ì¹­: {quick_intent.value}\")\n",
    "            return quick_intent\n",
    "        \n",
    "        # 2ë‹¨ê³„: LLM ê¸°ë°˜ ì •í™•í•œ ë¶„ë¥˜\n",
    "        return self._classify_by_llm(message)\n",
    "    \n",
    "    def _classify_by_keywords(self, message: str) -> ConversationState:\n",
    "        \"\"\"í‚¤ì›Œë“œ ê¸°ë°˜ ë¹ ë¥¸ ì˜ë„ ë¶„ë¥˜\"\"\"\n",
    "        message_lower = message.lower()\n",
    "        \n",
    "        for intent, keywords in self.intent_keywords.items():\n",
    "            if any(keyword in message_lower for keyword in keywords):\n",
    "                return intent\n",
    "        \n",
    "        return ConversationState.UNKNOWN\n",
    "    \n",
    "    def _classify_by_llm(self, message: str) -> ConversationState:\n",
    "        \"\"\"LLM ê¸°ë°˜ ì •í™•í•œ ì˜ë„ ë¶„ë¥˜\"\"\"\n",
    "        try:\n",
    "            prompt = f\"\"\"ë‹¤ìŒ ë©”ì‹œì§€ì˜ ì˜ë„ë¥¼ ë¶„ë¥˜í•˜ì„¸ìš”.\n",
    "\n",
    "ê°€ëŠ¥í•œ ì˜ë„:\n",
    "- greeting: ì¸ì‚¬, ì²« ë§Œë‚¨\n",
    "- information_seeking: ì •ë³´ ìš”ì²­, ì§ˆë¬¸\n",
    "- task_execution: ì‘ì—… ìš”ì²­, ì‹¤í–‰ ëª…ë ¹\n",
    "- problem_solving: ë¬¸ì œ í•´ê²°, ë„ì›€ ìš”ì²­\n",
    "- casual_chat: ì¼ìƒ ëŒ€í™”, ì¡ë‹´\n",
    "- ending: ëŒ€í™” ì¢…ë£Œ, ì‘ë³„ì¸ì‚¬\n",
    "\n",
    "ë©”ì‹œì§€: {message}\n",
    "\n",
    "ì˜ë„ (ìœ„ ì¹´í…Œê³ ë¦¬ ì¤‘ í•˜ë‚˜ë§Œ):\"\"\"\n",
    "            \n",
    "            response = self.client.chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"ëŒ€í™” ì˜ë„ë¥¼ ì •í™•í•˜ê²Œ ë¶„ë¥˜í•˜ì„¸ìš”.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                max_tokens=20,\n",
    "                temperature=0.1\n",
    "            )\n",
    "            \n",
    "            result = response.choices[0].message.content.strip().lower()\n",
    "            \n",
    "            # ê²°ê³¼ë¥¼ ConversationStateë¡œ ë³€í™˜\n",
    "            intent_mapping = {\n",
    "                'greeting': ConversationState.GREETING,\n",
    "                'information_seeking': ConversationState.INFORMATION_SEEKING,\n",
    "                'task_execution': ConversationState.TASK_EXECUTION,\n",
    "                'problem_solving': ConversationState.PROBLEM_SOLVING,\n",
    "                'casual_chat': ConversationState.CASUAL_CHAT,\n",
    "                'ending': ConversationState.ENDING\n",
    "            }\n",
    "            \n",
    "            classified_intent = intent_mapping.get(result, ConversationState.UNKNOWN)\n",
    "            print(f\"  ğŸ¤– LLM ë¶„ë¥˜: {classified_intent.value}\")\n",
    "            \n",
    "            return classified_intent\n",
    "        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"LLM ì˜ë„ ë¶„ë¥˜ ì‹¤íŒ¨: {e}\")\n",
    "            return ConversationState.UNKNOWN\n",
    "\n",
    "# ì˜ë„ ë¶„ë¥˜ í…ŒìŠ¤íŠ¸\n",
    "classifier = IntentClassifier()\n",
    "\n",
    "test_messages = [\n",
    "    \"ì•ˆë…•í•˜ì„¸ìš”! ì²˜ìŒ ëµ™ê² ìŠµë‹ˆë‹¤.\",\n",
    "    \"Pythonìœ¼ë¡œ ì›¹ í¬ë¡¤ë§í•˜ëŠ” ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”.\",\n",
    "    \"ì½”ë“œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.\",\n",
    "    \"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆëŠ”ë° ë„ì›€ì´ í•„ìš”í•©ë‹ˆë‹¤.\",\n",
    "    \"ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì¢‹ë„¤ìš”.\",\n",
    "    \"ê°ì‚¬í•©ë‹ˆë‹¤. ì•ˆë…•íˆ ê³„ì„¸ìš”.\"\n",
    "]\n",
    "\n",
    "print(\"\\nğŸ§ª ì˜ë„ ë¶„ë¥˜ í…ŒìŠ¤íŠ¸:\")\n",
    "for i, msg in enumerate(test_messages, 1):\n",
    "    intent = classifier.classify_intent(msg)\n",
    "    print(f\"{i}. '{msg[:30]}...' -> {intent.value}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. í†µí•© ë©€í‹°í„´ ì±—ë´‡ êµ¬í˜„\n",
    "\n",
    "ëª¨ë“  ì»´í¬ë„ŒíŠ¸ë¥¼ í†µí•©í•œ ì™„ì „í•œ ë©€í‹°í„´ ëŒ€í™” ì‹œìŠ¤í…œì„ êµ¬í˜„í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTurnChatbot:\n",
    "    \"\"\"í†µí•© ë©€í‹°í„´ ëŒ€í™” ì±—ë´‡\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.session_manager = SessionManager()\n",
    "        self.context_optimizer = ContextWindowOptimizer()\n",
    "        self.intent_classifier = IntentClassifier()\n",
    "        self.client = OpenAI(api_key=config.llm.openai_api_key)\n",
    "        \n",
    "        print(\"âœ… ë©€í‹°í„´ ì±—ë´‡ ì´ˆê¸°í™” ì™„ë£Œ\")\n",
    "    \n",
    "    def start_conversation(self, user_id: str) -> str:\n",
    "        \"\"\"ìƒˆ ëŒ€í™” ì‹œì‘\"\"\"\n",
    "        session_id, session_data = self.session_manager.create_session(user_id)\n",
    "        print(f\"ğŸ†• ìƒˆ ëŒ€í™” ì‹œì‘: {session_id[:8]}... (ì‚¬ìš©ì: {user_id})\")\n",
    "        return session_id\n",
    "    \n",
    "    def chat(self, session_id: str, user_message: str) -> Dict[str, Any]:\n",
    "        \"\"\"ëŒ€í™” ì²˜ë¦¬\"\"\"\n",
    "        start_time = time.time()\n",
    "        print(f\"\\nğŸ’¬ ëŒ€í™” ì²˜ë¦¬ ì‹œì‘: {user_message[:50]}...\")\n",
    "        \n",
    "        try:\n",
    "            # 1. ì„¸ì…˜ ì¡°íšŒ\n",
    "            session_data = self.session_manager.get_session(session_id)\n",
    "            if not session_data:\n",
    "                return {'error': 'ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤'}\n",
    "            \n",
    "            # 2. ì˜ë„ ë¶„ë¥˜\n",
    "            intent = self.intent_classifier.classify_intent(user_message)\n",
    "            \n",
    "            # 3. ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€\n",
    "            user_msg = {\n",
    "                'id': str(uuid.uuid4()),\n",
    "                'role': 'user',\n",
    "                'content': user_message,\n",
    "                'timestamp': datetime.now().isoformat(),\n",
    "                'metadata': {'intent': intent.value}\n",
    "            }\n",
    "            \n",
    "            session_data['messages'].append(user_msg)\n",
    "            session_data['current_state'] = intent.value\n",
    "            session_data['last_activity'] = datetime.now().isoformat()\n",
    "            \n",
    "            # 4. ì»¨í…ìŠ¤íŠ¸ ìµœì í™”\n",
    "            messages_for_api = [{'role': msg['role'], 'content': msg['content']} \n",
    "                               for msg in session_data['messages']]\n",
    "            \n",
    "            total_tokens = sum(self.context_optimizer._estimate_tokens(msg['content']) \n",
    "                             for msg in messages_for_api)\n",
    "            \n",
    "            optimized_messages, opt_metadata = self.context_optimizer.optimize_messages(\n",
    "                messages_for_api, total_tokens\n",
    "            )\n",
    "            \n",
    "            # 5. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì¶”ê°€\n",
    "            system_prompt = self._generate_system_prompt(intent)\n",
    "            final_messages = [{'role': 'system', 'content': system_prompt}] + optimized_messages\n",
    "            \n",
    "            # 6. AI ì‘ë‹µ ìƒì„±\n",
    "            print(f\"ğŸ¤– AI ì‘ë‹µ ìƒì„± ì¤‘... (ë©”ì‹œì§€ ìˆ˜: {len(final_messages)})\")\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=config.llm.openai_model,\n",
    "                messages=final_messages,\n",
    "                temperature=config.llm.temperature,\n",
    "                max_tokens=config.llm.max_tokens\n",
    "            )\n",
    "            \n",
    "            ai_response = response.choices[0].message.content\n",
    "            tokens_used = response.usage.total_tokens\n",
    "            \n",
    "            # 7. AI ì‘ë‹µ ì €ì¥\n",
    "            ai_msg = {\n",
    "                'id': str(uuid.uuid4()),\n",
    "                'role': 'assistant',\n",
    "                'content': ai_response,\n",
    "                'timestamp': datetime.now().isoformat(),\n",
    "                'metadata': {\n",
    "                    'model': config.llm.openai_model,\n",
    "                    'tokens': tokens_used,\n",
    "                    'state': intent.value\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            session_data['messages'].append(ai_msg)\n",
    "            session_data['total_tokens'] += tokens_used\n",
    "            \n",
    "            # 8. ì„¸ì…˜ ì—…ë°ì´íŠ¸\n",
    "            self.session_manager._save_session_data(session_id, session_data)\n",
    "            \n",
    "            processing_time = time.time() - start_time\n",
    "            \n",
    "            # ê²°ê³¼ ë°˜í™˜\n",
    "            result = {\n",
    "                'session_id': session_id,\n",
    "                'response': ai_response,\n",
    "                'intent': intent.value,\n",
    "                'conversation_state': session_data['current_state'],\n",
    "                'processing_time': processing_time,\n",
    "                'tokens_used': tokens_used,\n",
    "                'optimization': opt_metadata,\n",
    "                'session_stats': {\n",
    "                    'message_count': len(session_data['messages']),\n",
    "                    'total_tokens': session_data['total_tokens'],\n",
    "                    'session_age': (datetime.now() - datetime.fromisoformat(\n",
    "                        session_data['created_at'])).total_seconds()\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            print(f\"âœ… ëŒ€í™” ì²˜ë¦¬ ì™„ë£Œ - ì‹œê°„: {processing_time:.2f}ì´ˆ, í† í°: {tokens_used}\")\n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"ëŒ€í™” ì²˜ë¦¬ ì‹¤íŒ¨: {e}\")\n",
    "            return {'error': f'ëŒ€í™” ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}'}\n",
    "    \n",
    "    def _generate_system_prompt(self, intent: ConversationState) -> str:\n",
    "        \"\"\"ìƒíƒœë³„ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±\"\"\"\n",
    "        base_prompt = \"ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\"\n",
    "        \n",
    "        state_prompts = {\n",
    "            ConversationState.GREETING: f\"{base_prompt} ì‚¬ìš©ìì™€ ì²« ë§Œë‚¨ì´ë¯€ë¡œ ì¹œê·¼í•˜ê²Œ ì¸ì‚¬í•˜ì„¸ìš”.\",\n",
    "            ConversationState.INFORMATION_SEEKING: f\"{base_prompt} ì •í™•í•œ ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”.\",\n",
    "            ConversationState.TASK_EXECUTION: f\"{base_prompt} ë‹¨ê³„ë³„ë¡œ ëª…í™•í•œ ì•ˆë‚´ë¥¼ ì œê³µí•˜ì„¸ìš”.\",\n",
    "            ConversationState.PROBLEM_SOLVING: f\"{base_prompt} ë¬¸ì œë¥¼ ì²´ê³„ì ìœ¼ë¡œ í•´ê²°í•´ì£¼ì„¸ìš”.\",\n",
    "            ConversationState.CASUAL_CHAT: f\"{base_prompt} ìì—°ìŠ¤ëŸ½ê³  ì¹œê·¼í•œ ëŒ€í™”ë¥¼ í•˜ì„¸ìš”.\",\n",
    "            ConversationState.ENDING: f\"{base_prompt} ë”°ëœ»í•œ ì‘ë³„ì¸ì‚¬ë¥¼ í•´ì£¼ì„¸ìš”.\"\n",
    "        }\n",
    "        \n",
    "        return state_prompts.get(intent, base_prompt)\n",
    "    \n",
    "    def get_conversation_history(self, session_id: str) -> Dict[str, Any]:\n",
    "        \"\"\"ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¡°íšŒ\"\"\"\n",
    "        session_data = self.session_manager.get_session(session_id)\n",
    "        if not session_data:\n",
    "            return {'error': 'ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤'}\n",
    "        \n",
    "        return {\n",
    "            'session_id': session_id,\n",
    "            'user_id': session_data['user_id'],\n",
    "            'created_at': session_data['created_at'],\n",
    "            'current_state': session_data['current_state'],\n",
    "            'message_count': len(session_data['messages']),\n",
    "            'total_tokens': session_data['total_tokens'],\n",
    "            'messages': session_data['messages'][-10:],  # ìµœê·¼ 10ê°œ ë©”ì‹œì§€ë§Œ\n",
    "        }\n",
    "\n",
    "print(\"âœ… ë©€í‹°í„´ ì±—ë´‡ í´ë˜ìŠ¤ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ë©€í‹°í„´ ëŒ€í™” ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸\n",
    "\n",
    "ì‹¤ì œ ëŒ€í™” ì‹œë‚˜ë¦¬ì˜¤ë¡œ ì‹œìŠ¤í…œì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë©€í‹°í„´ ì±—ë´‡ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "chatbot = MultiTurnChatbot()\n",
    "\n",
    "# ëŒ€í™” ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸\n",
    "print(\"ğŸ¬ ë©€í‹°í„´ ëŒ€í™” ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸ ì‹œì‘\\n\")\n",
    "\n",
    "# ìƒˆ ëŒ€í™” ì‹œì‘\n",
    "session_id = chatbot.start_conversation(\"demo_user\")\n",
    "\n",
    "# ëŒ€í™” ì‹œë‚˜ë¦¬ì˜¤\n",
    "conversation_script = [\n",
    "    \"ì•ˆë…•í•˜ì„¸ìš”! ì²˜ìŒ ì‚¬ìš©í•´ë´…ë‹ˆë‹¤.\",\n",
    "    \"Pythonìœ¼ë¡œ ì›¹ í¬ë¡¤ë§ì„ ë°°ìš°ê³  ì‹¶ì€ë°, ì–´ë””ì„œ ì‹œì‘í•´ì•¼ í• ê¹Œìš”?\",\n",
    "    \"requestsì™€ BeautifulSoupì„ ì‚¬ìš©í•œ ì˜ˆì œ ì½”ë“œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.\",\n",
    "    \"ì½”ë“œì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”. ë„ì›€ì´ í•„ìš”í•©ë‹ˆë‹¤.\",\n",
    "    \"ì •ë§ ê°ì‚¬í•©ë‹ˆë‹¤. ë§ì€ ë„ì›€ì´ ë˜ì—ˆì–´ìš”!\"\n",
    "]\n",
    "\n",
    "# ëŒ€í™” ì§„í–‰\n",
    "conversation_results = []\n",
    "for i, user_msg in enumerate(conversation_script, 1):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"í„´ {i}: ì‚¬ìš©ì ë©”ì‹œì§€\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"ğŸ‘¤ ì‚¬ìš©ì: {user_msg}\")\n",
    "    \n",
    "    # ì±—ë´‡ ì‘ë‹µ ìƒì„±\n",
    "    result = chatbot.chat(session_id, user_msg)\n",
    "    \n",
    "    if 'error' not in result:\n",
    "        print(f\"\\nğŸ¤– AI ({result['intent']}): {result['response'][:200]}...\")\n",
    "        \n",
    "        # ì²˜ë¦¬ í†µê³„\n",
    "        print(f\"\\nğŸ“Š ì²˜ë¦¬ í†µê³„:\")\n",
    "        print(f\"  â±ï¸  ì²˜ë¦¬ ì‹œê°„: {result['processing_time']:.2f}ì´ˆ\")\n",
    "        print(f\"  ğŸ¯ í† í° ì‚¬ìš©: {result['tokens_used']}\")\n",
    "        print(f\"  ğŸ’¬ ë©”ì‹œì§€ ìˆ˜: {result['session_stats']['message_count']}\")\n",
    "        print(f\"  ğŸ”„ ìµœì í™”: {result['optimization']['optimization']}\")\n",
    "        \n",
    "        if result['optimization']['optimization'] != 'none':\n",
    "            print(f\"  ğŸ“‰ ì••ì¶•ë¥ : {result['optimization'].get('compression_ratio', 0):.1%}\")\n",
    "        \n",
    "        conversation_results.append(result)\n",
    "    else:\n",
    "        print(f\"âŒ ì˜¤ë¥˜: {result['error']}\")\n",
    "        break\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"ğŸ‰ ëŒ€í™” ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸ ì™„ë£Œ\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# ìµœì¢… ì„¸ì…˜ í†µê³„\n",
    "if conversation_results:\n",
    "    final_stats = conversation_results[-1]['session_stats']\n",
    "    print(f\"\\nğŸ“ˆ ìµœì¢… ì„¸ì…˜ í†µê³„:\")\n",
    "    print(f\"  ğŸ“ ì´ ë©”ì‹œì§€ ìˆ˜: {final_stats['message_count']}\")\n",
    "    print(f\"  ğŸ¯ ì´ í† í° ì‚¬ìš©: {final_stats['total_tokens']}\")\n",
    "    print(f\"  â° ì„¸ì…˜ ì§€ì† ì‹œê°„: {final_stats['session_age']:.0f}ì´ˆ\")\n",
    "    print(f\"  ğŸ’° í‰ê·  ì‘ë‹µ ì‹œê°„: {sum(r['processing_time'] for r in conversation_results) / len(conversation_results):.2f}ì´ˆ\")\n",
    "\n",
    "# ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¡°íšŒ\n",
    "print(f\"\\nğŸ“š ëŒ€í™” íˆìŠ¤í† ë¦¬:\")\n",
    "history = chatbot.get_conversation_history(session_id)\n",
    "if 'error' not in history:\n",
    "    print(f\"  ì„¸ì…˜ ID: {history['session_id'][:8]}...\")\n",
    "    print(f\"  ì‚¬ìš©ì ID: {history['user_id']}\")\n",
    "    print(f\"  í˜„ì¬ ìƒíƒœ: {history['current_state']}\")\n",
    "    print(f\"  ë©”ì‹œì§€ ìˆ˜: {history['message_count']}\")\n",
    "else:\n",
    "    print(f\"  âŒ íˆìŠ¤í† ë¦¬ ì¡°íšŒ ì‹¤íŒ¨: {history['error']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. ì„±ëŠ¥ ìµœì í™” ë° ëª¨ë‹ˆí„°ë§\n",
    "\n",
    "ëŒ€í™” ì‹œìŠ¤í…œì˜ ì„±ëŠ¥ì„ ë¶„ì„í•˜ê³  ìµœì í™” í¬ì¸íŠ¸ë¥¼ í™•ì¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "def analyze_conversation_performance(results: List[Dict]) -> Dict[str, Any]:\n",
    "    \"\"\"ëŒ€í™” ì„±ëŠ¥ ë¶„ì„\"\"\"\n",
    "    if not results:\n",
    "        return {}\n",
    "    \n",
    "    # ë°ì´í„° ì¶”ì¶œ\n",
    "    processing_times = [r['processing_time'] for r in results]\n",
    "    token_usage = [r['tokens_used'] for r in results]\n",
    "    message_counts = [r['session_stats']['message_count'] for r in results]\n",
    "    intents = [r['intent'] for r in results]\n",
    "    \n",
    "    # í†µê³„ ê³„ì‚°\n",
    "    analysis = {\n",
    "        'performance_stats': {\n",
    "            'avg_processing_time': sum(processing_times) / len(processing_times),\n",
    "            'max_processing_time': max(processing_times),\n",
    "            'min_processing_time': min(processing_times),\n",
    "            'total_tokens': sum(token_usage),\n",
    "            'avg_tokens_per_turn': sum(token_usage) / len(token_usage),\n",
    "            'max_tokens_per_turn': max(token_usage)\n",
    "        },\n",
    "        'optimization_stats': {\n",
    "            'optimizations_applied': sum(1 for r in results if r['optimization']['optimization'] != 'none'),\n",
    "            'avg_compression_ratio': sum(\n",
    "                r['optimization'].get('compression_ratio', 0) \n",
    "                for r in results if r['optimization']['optimization'] != 'none'\n",
    "            ) / max(1, sum(1 for r in results if r['optimization']['optimization'] != 'none'))\n",
    "        },\n",
    "        'intent_distribution': {}\n",
    "    }\n",
    "    \n",
    "    # ì˜ë„ ë¶„í¬ ê³„ì‚°\n",
    "    from collections import Counter\n",
    "    intent_counts = Counter(intents)\n",
    "    analysis['intent_distribution'] = dict(intent_counts)\n",
    "    \n",
    "    return analysis\n",
    "\n",
    "def visualize_performance(results: List[Dict]):\n",
    "    \"\"\"ì„±ëŠ¥ ì‹œê°í™”\"\"\"\n",
    "    if not results:\n",
    "        print(\"ì‹œê°í™”í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "    \n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle('ë©€í‹°í„´ ëŒ€í™” ì„±ëŠ¥ ë¶„ì„', fontsize=16)\n",
    "    \n",
    "    # 1. ì²˜ë¦¬ ì‹œê°„ ì¶”ì´\n",
    "    turns = range(1, len(results) + 1)\n",
    "    processing_times = [r['processing_time'] for r in results]\n",
    "    ax1.plot(turns, processing_times, 'b-o', linewidth=2, markersize=6)\n",
    "    ax1.set_title('í„´ë³„ ì²˜ë¦¬ ì‹œê°„')\n",
    "    ax1.set_xlabel('ëŒ€í™” í„´')\n",
    "    ax1.set_ylabel('ì²˜ë¦¬ ì‹œê°„ (ì´ˆ)')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. í† í° ì‚¬ìš©ëŸ‰ ì¶”ì´\n",
    "    token_usage = [r['tokens_used'] for r in results]\n",
    "    ax2.bar(turns, token_usage, color='green', alpha=0.7)\n",
    "    ax2.set_title('í„´ë³„ í† í° ì‚¬ìš©ëŸ‰')\n",
    "    ax2.set_xlabel('ëŒ€í™” í„´')\n",
    "    ax2.set_ylabel('í† í° ìˆ˜')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. ëˆ„ì  ë©”ì‹œì§€ ìˆ˜\n",
    "    message_counts = [r['session_stats']['message_count'] for r in results]\n",
    "    ax3.plot(turns, message_counts, 'r-s', linewidth=2, markersize=6)\n",
    "    ax3.set_title('ëˆ„ì  ë©”ì‹œì§€ ìˆ˜')\n",
    "    ax3.set_xlabel('ëŒ€í™” í„´')\n",
    "    ax3.set_ylabel('ë©”ì‹œì§€ ìˆ˜')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. ì˜ë„ ë¶„í¬\n",
    "    from collections import Counter\n",
    "    intents = [r['intent'] for r in results]\n",
    "    intent_counts = Counter(intents)\n",
    "    ax4.pie(intent_counts.values(), labels=intent_counts.keys(), autopct='%1.1f%%')\n",
    "    ax4.set_title('ì˜ë„ ë¶„í¬')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ì„±ëŠ¥ ë¶„ì„ ì‹¤í–‰\n",
    "if 'conversation_results' in locals() and conversation_results:\n",
    "    print(\"ğŸ“Š ì„±ëŠ¥ ë¶„ì„ ì‹œì‘...\\n\")\n",
    "    \n",
    "    analysis = analyze_conversation_performance(conversation_results)\n",
    "    \n",
    "    print(\"ğŸ¯ ì„±ëŠ¥ í†µê³„:\")\n",
    "    perf_stats = analysis['performance_stats']\n",
    "    print(f\"  í‰ê·  ì²˜ë¦¬ ì‹œê°„: {perf_stats['avg_processing_time']:.2f}ì´ˆ\")\n",
    "    print(f\"  ìµœëŒ€ ì²˜ë¦¬ ì‹œê°„: {perf_stats['max_processing_time']:.2f}ì´ˆ\")\n",
    "    print(f\"  ì´ í† í° ì‚¬ìš©: {perf_stats['total_tokens']}\")\n",
    "    print(f\"  í„´ë‹¹ í‰ê·  í† í°: {perf_stats['avg_tokens_per_turn']:.0f}\")\n",
    "    \n",
    "    print(\"\\nğŸ”§ ìµœì í™” í†µê³„:\")\n",
    "    opt_stats = analysis['optimization_stats']\n",
    "    print(f\"  ìµœì í™” ì ìš© íšŸìˆ˜: {opt_stats['optimizations_applied']}\")\n",
    "    if opt_stats['avg_compression_ratio'] > 0:\n",
    "        print(f\"  í‰ê·  ì••ì¶•ë¥ : {opt_stats['avg_compression_ratio']:.1%}\")\n",
    "    \n",
    "    print(\"\\nğŸ­ ì˜ë„ ë¶„í¬:\")\n",
    "    for intent, count in analysis['intent_distribution'].items():\n",
    "        print(f\"  {intent}: {count}íšŒ\")\n",
    "    \n",
    "    # ì„±ëŠ¥ ì‹œê°í™”\n",
    "    print(\"\\nğŸ“ˆ ì„±ëŠ¥ ì°¨íŠ¸ ìƒì„± ì¤‘...\")\n",
    "    try:\n",
    "        visualize_performance(conversation_results)\n",
    "    except Exception as e:\n",
    "        print(f\"ì°¨íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}\")\n",
    "        print(\"Matplotlib ì„¤ì¹˜ê°€ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤: pip install matplotlib\")\n",
    "else:\n",
    "    print(\"ë¶„ì„í•  ëŒ€í™” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ëŒ€í™” ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. ë©€í‹° ì‚¬ìš©ì ë™ì‹œì„± í…ŒìŠ¤íŠ¸\n",
    "\n",
    "ì—¬ëŸ¬ ì‚¬ìš©ìê°€ ë™ì‹œì— ëŒ€í™”í•  ë•Œì˜ ì‹œìŠ¤í…œ ì•ˆì •ì„±ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import concurrent.futures\n",
    "import threading\n",
    "from threading import Thread\n",
    "import time\n",
    "\n",
    "def simulate_user_conversation(chatbot: MultiTurnChatbot, user_id: str, messages: List[str]) -> Dict[str, Any]:\n",
    "    \"\"\"ì‚¬ìš©ì ëŒ€í™” ì‹œë®¬ë ˆì´ì…˜\"\"\"\n",
    "    print(f\"ğŸ‘¤ ì‚¬ìš©ì {user_id} ëŒ€í™” ì‹œì‘\")\n",
    "    \n",
    "    try:\n",
    "        # ìƒˆ ì„¸ì…˜ ì‹œì‘\n",
    "        session_id = chatbot.start_conversation(user_id)\n",
    "        \n",
    "        results = []\n",
    "        total_time = 0\n",
    "        \n",
    "        for i, message in enumerate(messages):\n",
    "            print(f\"  {user_id}: {message[:30]}...\")\n",
    "            \n",
    "            result = chatbot.chat(session_id, message)\n",
    "            \n",
    "            if 'error' not in result:\n",
    "                results.append(result)\n",
    "                total_time += result['processing_time']\n",
    "                print(f\"  âœ… ì‘ë‹µ ì™„ë£Œ ({result['processing_time']:.2f}ì´ˆ)\")\n",
    "            else:\n",
    "                print(f\"  âŒ ì˜¤ë¥˜: {result['error']}\")\n",
    "                break\n",
    "            \n",
    "            # ì‚¬ìš©ì ê°„ ë©”ì‹œì§€ ê°„ê²© ì‹œë®¬ë ˆì´ì…˜\n",
    "            time.sleep(0.5)\n",
    "        \n",
    "        return {\n",
    "            'user_id': user_id,\n",
    "            'session_id': session_id,\n",
    "            'total_messages': len(results),\n",
    "            'total_time': total_time,\n",
    "            'avg_response_time': total_time / len(results) if results else 0,\n",
    "            'results': results\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"  âŒ ì‚¬ìš©ì {user_id} ëŒ€í™” ì‹¤íŒ¨: {e}\")\n",
    "        return {'user_id': user_id, 'error': str(e)}\n",
    "\n",
    "def run_concurrent_conversations():\n",
    "    \"\"\"ë™ì‹œ ëŒ€í™” í…ŒìŠ¤íŠ¸ ì‹¤í–‰\"\"\"\n",
    "    print(\"ğŸ”„ ë©€í‹° ì‚¬ìš©ì ë™ì‹œì„± í…ŒìŠ¤íŠ¸ ì‹œì‘\\n\")\n",
    "    \n",
    "    # ì‚¬ìš©ìë³„ ëŒ€í™” ì‹œë‚˜ë¦¬ì˜¤\n",
    "    user_scenarios = {\n",
    "        'user_1': [\n",
    "            \"ì•ˆë…•í•˜ì„¸ìš”!\",\n",
    "            \"Python ê¸°ì´ˆë¥¼ ë°°ìš°ê³  ì‹¶ì–´ìš”.\",\n",
    "            \"ë³€ìˆ˜ì™€ í•¨ìˆ˜ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.\"\n",
    "        ],\n",
    "        'user_2': [\n",
    "            \"ë°˜ê°‘ìŠµë‹ˆë‹¤.\",\n",
    "            \"ì›¹ ê°œë°œì„ ì‹œì‘í•˜ë ¤ë©´ ì–´ë–»ê²Œ í•´ì•¼ í•˜ë‚˜ìš”?\",\n",
    "            \"HTMLê³¼ CSSë¶€í„° ë°°ì›Œì•¼ í• ê¹Œìš”?\"\n",
    "        ],\n",
    "        'user_3': [\n",
    "            \"ì²˜ìŒ ì‚¬ìš©í•´ë´…ë‹ˆë‹¤.\",\n",
    "            \"ë°ì´í„° ë¶„ì„ì— ê´€ì‹¬ì´ ìˆì–´ìš”.\",\n",
    "            \"pandas ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”.\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # ë™ì‹œì„± í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ìŠ¤ë ˆë“œ í’€\n",
    "    start_time = time.time()\n",
    "    \n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:\n",
    "        # ê° ì‚¬ìš©ìë³„ë¡œ ë³‘ë ¬ ëŒ€í™” ì‹œì‘\n",
    "        future_to_user = {\n",
    "            executor.submit(\n",
    "                simulate_user_conversation, \n",
    "                chatbot, \n",
    "                user_id, \n",
    "                messages\n",
    "            ): user_id\n",
    "            for user_id, messages in user_scenarios.items()\n",
    "        }\n",
    "        \n",
    "        # ê²°ê³¼ ìˆ˜ì§‘\n",
    "        concurrent_results = []\n",
    "        for future in concurrent.futures.as_completed(future_to_user):\n",
    "            user_id = future_to_user[future]\n",
    "            try:\n",
    "                result = future.result()\n",
    "                concurrent_results.append(result)\n",
    "                print(f\"âœ… {user_id} ì™„ë£Œ\")\n",
    "            except Exception as exc:\n",
    "                print(f\"âŒ {user_id} ì‹¤íŒ¨: {exc}\")\n",
    "    \n",
    "    total_test_time = time.time() - start_time\n",
    "    \n",
    "    # ê²°ê³¼ ë¶„ì„\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(\"ğŸ‰ ë™ì‹œì„± í…ŒìŠ¤íŠ¸ ì™„ë£Œ\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"ğŸ“Š ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹œê°„: {total_test_time:.2f}ì´ˆ\")\n",
    "    print(f\"ğŸ‘¥ ë™ì‹œ ì‚¬ìš©ì ìˆ˜: {len(user_scenarios)}\")\n",
    "    \n",
    "    successful_users = [r for r in concurrent_results if 'error' not in r]\n",
    "    \n",
    "    if successful_users:\n",
    "        print(f\"âœ… ì„±ê³µí•œ ì‚¬ìš©ì: {len(successful_users)}/{len(user_scenarios)}\")\n",
    "        \n",
    "        avg_response_times = [r['avg_response_time'] for r in successful_users]\n",
    "        total_messages = sum(r['total_messages'] for r in successful_users)\n",
    "        \n",
    "        print(f\"\\nğŸ“ˆ ì„±ëŠ¥ ë©”íŠ¸ë¦­:\")\n",
    "        print(f\"  ì´ ì²˜ë¦¬ëœ ë©”ì‹œì§€: {total_messages}ê°œ\")\n",
    "        print(f\"  í‰ê·  ì‘ë‹µ ì‹œê°„: {sum(avg_response_times) / len(avg_response_times):.2f}ì´ˆ\")\n",
    "        print(f\"  ë©”ì‹œì§€ ì²˜ë¦¬ìœ¨: {total_messages / total_test_time:.1f} ë©”ì‹œì§€/ì´ˆ\")\n",
    "        \n",
    "        # ì‚¬ìš©ìë³„ ìƒì„¸ ê²°ê³¼\n",
    "        print(f\"\\nğŸ‘¤ ì‚¬ìš©ìë³„ ê²°ê³¼:\")\n",
    "        for result in successful_users:\n",
    "            print(f\"  {result['user_id']}: {result['total_messages']}ë©”ì‹œì§€, \"\n",
    "                  f\"í‰ê·  {result['avg_response_time']:.2f}ì´ˆ\")\n",
    "    else:\n",
    "        print(\"âŒ ëª¨ë“  ì‚¬ìš©ì ëŒ€í™”ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\")\n",
    "    \n",
    "    return concurrent_results\n",
    "\n",
    "# ë™ì‹œì„± í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "try:\n",
    "    concurrent_test_results = run_concurrent_conversations()\n",
    "    \n",
    "    # Redis ì—°ê²° ìƒíƒœ í™•ì¸\n",
    "    print(f\"\\nğŸ”— ì‹œìŠ¤í…œ ìƒíƒœ:\")\n",
    "    print(f\"  Redis ì—°ê²°: {'í™œì„±' if chatbot.session_manager.client else 'ë©”ëª¨ë¦¬ ëª¨ë“œ'}\")\n",
    "    print(f\"  ì„¸ì…˜ ê´€ë¦¬: {'ë¶„ì‚° ì €ì¥' if chatbot.session_manager.client else 'ë¡œì»¬ ë©”ëª¨ë¦¬'}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ ë™ì‹œì„± í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}\")\n",
    "    print(\"ì¼ë¶€ í™˜ê²½ì—ì„œëŠ” ë©€í‹°ìŠ¤ë ˆë”© ì œí•œì´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. ì‹¤ìŠµ ì •ë¦¬ ë° í™•ì¥ ì•„ì´ë””ì–´\n",
    "\n",
    "4ì°¨ì‹œ ì‹¤ìŠµì˜ í•µì‹¬ ë‚´ìš©ì„ ì •ë¦¬í•˜ê³  í™•ì¥ ê°€ëŠ¥í•œ ì•„ì´ë””ì–´ë¥¼ ì œì‹œí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_lesson4_summary():\n",
    "    \"\"\"4ì°¨ì‹œ ì‹¤ìŠµ ìš”ì•½\"\"\"\n",
    "    print(\"\"\"\\nğŸ“š 4ì°¨ì‹œ ì‹¤ìŠµ ìš”ì•½: ëŒ€í™” ìƒíƒœ ê´€ë¦¬ & ë©€í‹°í„´ ìµœì í™”\n",
    "    \n",
    "ğŸ¯ ë‹¬ì„±í•œ í•™ìŠµ ëª©í‘œ:\n",
    "âœ… Redis ê¸°ë°˜ ì„¸ì…˜ ê´€ë¦¬ ì‹œìŠ¤í…œ êµ¬í˜„\n",
    "âœ… ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš° ìµœì í™” (í† í° ê¸°ë°˜ ì••ì¶•)\n",
    "âœ… ì˜ë„ ë¶„ë¥˜ ë° ëŒ€í™” ìƒíƒœ ì¶”ì \n",
    "âœ… ë©€í‹° ì‚¬ìš©ì ë™ì‹œì„± ì²˜ë¦¬\n",
    "âœ… ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë° ë¶„ì„\n",
    "\n",
    "ğŸ”§ í•µì‹¬ êµ¬í˜„ ì‚¬í•­:\n",
    "â€¢ SessionManager: Redis/ë©”ëª¨ë¦¬ í•˜ì´ë¸Œë¦¬ë“œ ì„¸ì…˜ ê´€ë¦¬\n",
    "â€¢ ContextWindowOptimizer: ì¤‘ìš”ë„ ê¸°ë°˜ ë©”ì‹œì§€ í•„í„°ë§ & ìš”ì•½\n",
    "â€¢ IntentClassifier: í‚¤ì›Œë“œ + LLM í•˜ì´ë¸Œë¦¬ë“œ ì˜ë„ ë¶„ë¥˜\n",
    "â€¢ MultiTurnChatbot: í†µí•© ëŒ€í™” ê´€ë¦¬ ì‹œìŠ¤í…œ\n",
    "\n",
    "ğŸ“Š ì„±ëŠ¥ íŠ¹ì§•:\n",
    "â€¢ ì„¸ì…˜ ê¸°ë°˜ ìƒíƒœ ê´€ë¦¬ë¡œ ì¼ê´€ëœ ëŒ€í™” ìœ ì§€\n",
    "â€¢ í† í° ìµœì í™”ë¡œ ë¹„ìš© íš¨ìœ¨ì„± í™•ë³´\n",
    "â€¢ ë™ì‹œ ì‚¬ìš©ì ì§€ì›ìœ¼ë¡œ í™•ì¥ì„± ë³´ì¥\n",
    "â€¢ ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§\n",
    "\n",
    "ğŸš€ í™•ì¥ ì•„ì´ë””ì–´:\n",
    "1. ê³ ë„í™”ëœ ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬\n",
    "   - ë²¡í„° ê¸°ë°˜ ì˜ë¯¸ë¡ ì  ìœ ì‚¬ì„± ê³„ì‚°\n",
    "   - ì¥ê¸°/ë‹¨ê¸° ë©”ëª¨ë¦¬ ë¶„ë¦¬\n",
    "   - ì‚¬ìš©ìë³„ ê°œì¸í™” ì»¨í…ìŠ¤íŠ¸\n",
    "\n",
    "2. ì§€ëŠ¥í˜• ëŒ€í™” íë¦„\n",
    "   - ê°ì • ë¶„ì„ ê¸°ë°˜ í†¤ ì¡°ì ˆ\n",
    "   - ëª©í‘œ ì§€í–¥ì  ëŒ€í™” ê°€ì´ë“œ\n",
    "   - ë‹¤ë‹¨ê³„ íƒœìŠ¤í¬ ê´€ë¦¬\n",
    "\n",
    "3. ê³ ê¸‰ ìµœì í™”\n",
    "   - ì ì‘í˜• í† í° í• ë‹¹\n",
    "   - ì˜ˆì¸¡ì  ì»¨í…ìŠ¤íŠ¸ ë¡œë”©\n",
    "   - ëª¨ë¸ë³„ ìµœì í™” ì „ëµ\n",
    "\n",
    "4. ìš´ì˜ ëª¨ë‹ˆí„°ë§\n",
    "   - ì‹¤ì‹œê°„ ëŒ€ì‹œë³´ë“œ\n",
    "   - ì´ìƒ ìƒí™© ì•Œë¦¼\n",
    "   - A/B í…ŒìŠ¤íŠ¸ í”„ë ˆì„ì›Œí¬\n",
    "\n",
    "5. ë©€í‹°ëª¨ë‹¬ í™•ì¥\n",
    "   - ìŒì„± ëŒ€í™” ìƒíƒœ ê´€ë¦¬\n",
    "   - ì´ë¯¸ì§€ ê¸°ë°˜ ì»¨í…ìŠ¤íŠ¸\n",
    "   - í¬ë¡œìŠ¤ ëª¨ë‹¬ë¦¬í‹° ì„¸ì…˜\"\"\")\n",
    "\n",
    "def suggest_next_steps():\n",
    "    \"\"\"ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ\"\"\"\n",
    "    print(\"\"\"\\nğŸ“ ë‹¤ìŒ í•™ìŠµ ë‹¨ê³„ ì œì•ˆ:\n",
    "\n",
    "ğŸ“– ì‹¬í™” í•™ìŠµ:\n",
    "â€¢ LangChain Memory ëª¨ë“ˆ í™œìš©\n",
    "â€¢ Semantic Kernelì˜ ëŒ€í™” ê´€ë¦¬\n",
    "â€¢ ë¶„ì‚° ì‹œìŠ¤í…œì—ì„œì˜ ì„¸ì…˜ ê´€ë¦¬\n",
    "â€¢ ëŒ€í™” í’ˆì§ˆ í‰ê°€ ë©”íŠ¸ë¦­\n",
    "\n",
    "ğŸ› ï¸ ì‹¤ì „ í”„ë¡œì íŠ¸:\n",
    "â€¢ ê³ ê° ì„œë¹„ìŠ¤ ì±—ë´‡ (ì¥ê¸° ì»¨í…ìŠ¤íŠ¸)\n",
    "â€¢ êµìœ¡ìš© íŠœí„° ì‹œìŠ¤í…œ (ê°œì¸í™” í•™ìŠµ ì¶”ì )\n",
    "â€¢ ê²Œì„ NPC (ìƒíƒœ ê¸°ë°˜ ëŒ€í™”)\n",
    "â€¢ ìƒë‹´ ë´‡ (ê°ì • ìƒíƒœ ê´€ë¦¬)\n",
    "\n",
    "ğŸ”— ì—°ê´€ ê¸°ìˆ :\n",
    "â€¢ Vector databases (Pinecone, Weaviate)\n",
    "â€¢ Stream processing (Kafka, Redis Streams)\n",
    "â€¢ Monitoring tools (Prometheus, Grafana)\n",
    "â€¢ A/B testing platforms\"\"\")\n",
    "\n",
    "# ì‹¤ìŠµ ìš”ì•½ ì¶œë ¥\n",
    "print_lesson4_summary()\n",
    "suggest_next_steps()\n",
    "\n",
    "# ì‹¤ìŠµ ì™„ë£Œ í™•ì¸\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ‰ 4ì°¨ì‹œ ì‹¤ìŠµì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "print(\"ğŸ“ ë‹¤ìŒì€ 5ì°¨ì‹œ: ì™¸ë¶€ ì—°ë™ & Tool Callingì…ë‹ˆë‹¤.\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ì‹¤ìŠµ ì²´í¬ë¦¬ìŠ¤íŠ¸\n",
    "checklist = [\n",
    "    \"âœ… Redis ê¸°ë°˜ ì„¸ì…˜ ê´€ë¦¬ êµ¬í˜„\",\n",
    "    \"âœ… ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš° ìµœì í™” ì ìš©\", \n",
    "    \"âœ… ì˜ë„ ë¶„ë¥˜ ì‹œìŠ¤í…œ ë™ì‘\",\n",
    "    \"âœ… ë©€í‹°í„´ ëŒ€í™” ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸\",\n",
    "    \"âœ… ë™ì‹œ ì‚¬ìš©ì ì²˜ë¦¬ í™•ì¸\",\n",
    "    \"âœ… ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ë° ë¶„ì„\"\n",
    "]\n",
    "\n",
    "print(\"\\nğŸ“‹ ì‹¤ìŠµ ì²´í¬ë¦¬ìŠ¤íŠ¸:\")\n",
    "for item in checklist:\n",
    "    print(f\"  {item}\")\n",
    "\n",
    "print(\"\\nğŸ”œ ë‹¤ìŒ ì‹¤ìŠµ ì˜ˆê³ :\")\n",
    "print(\"  â€¢ OpenAI Function Calling\")\n",
    "print(\"  â€¢ ì™¸ë¶€ API ì—°ë™ (ë‚ ì”¨, ê²€ìƒ‰ ë“±)\")\n",
    "print(\"  â€¢ ë°ì´í„°ë² ì´ìŠ¤ ì—°ë™\")\n",
    "print(\"  â€¢ Tool ê¸°ë°˜ ì—ì´ì „íŠ¸ êµ¬í˜„\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}