{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "lesson7-title",
   "metadata": {},
   "source": [
    "# 7ì°¨ì‹œ: ë°°í¬ ë° í†µí•©\n",
    "\n",
    "## í•™ìŠµ ëª©í‘œ\n",
    "- FastAPI ê¸°ë°˜ REST API ì„œë²„ êµ¬ì¶•\n",
    "- Docker ì»¨í…Œì´ë„ˆí™” ë° ë°°í¬ í™˜ê²½ êµ¬ì„±\n",
    "- CI/CD íŒŒì´í”„ë¼ì¸ êµ¬ì¶•\n",
    "- ëª¨ë‹ˆí„°ë§ ë° ìš´ì˜ ë„êµ¬ êµ¬ì„±\n",
    "- í”„ë¡œë•ì…˜ í™˜ê²½ ë°°í¬ ì „ëµ\n",
    "\n",
    "## ëª©ì°¨\n",
    "1. [í™˜ê²½ ì„¤ì •](#í™˜ê²½-ì„¤ì •)\n",
    "2. [FastAPI ì„œë²„ êµ¬ì¶•](#fastapi-ì„œë²„-êµ¬ì¶•)\n",
    "3. [Docker ì»¨í…Œì´ë„ˆí™”](#docker-ì»¨í…Œì´ë„ˆí™”)\n",
    "4. [CI/CD íŒŒì´í”„ë¼ì¸](#cicd-íŒŒì´í”„ë¼ì¸)\n",
    "5. [ëª¨ë‹ˆí„°ë§ ì„¤ì •](#ëª¨ë‹ˆí„°ë§-ì„¤ì •)\n",
    "6. [ë°°í¬ í…ŒìŠ¤íŠ¸](#ë°°í¬-í…ŒìŠ¤íŠ¸)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup",
   "metadata": {},
   "source": [
    "## í™˜ê²½ ì„¤ì •\n",
    "\n",
    "í”„ë¡œë•ì…˜ ë°°í¬ì— í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•˜ê³  ì„¤ì •í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install-requirements",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ (ì£¼ì„ í•´ì œí•˜ì—¬ ì‹¤í–‰)\n",
    "# !pip install fastapi uvicorn docker prometheus-client structlog opentelemetry-api\n",
    "\n",
    "print(\"ë°°í¬ ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "7ì°¨ì‹œ: ë°°í¬ ë° í†µí•©\n",
    "Author: AI Chatbot Workshop\n",
    "Date: 2024-08-30\n",
    "Description: FastAPI REST API, Docker ë°°í¬, CI/CD íŒŒì´í”„ë¼ì¸, í”„ë¡œë•ì…˜ í™˜ê²½ êµ¬ì„±\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import uuid\n",
    "import logging\n",
    "import asyncio\n",
    "from typing import Dict, List, Any, Optional\n",
    "from dataclasses import dataclass, asdict\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "\n",
    "# FastAPI ë° ì›¹ ì„œë²„\n",
    "from fastapi import FastAPI, HTTPException, Depends, BackgroundTasks, Request, Response\n",
    "from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from fastapi.responses import JSONResponse, StreamingResponse\n",
    "from pydantic import BaseModel, Field\n",
    "import uvicorn\n",
    "\n",
    "# ëª¨ë‹ˆí„°ë§ ë° ë¡œê¹…\n",
    "from prometheus_client import Counter, Histogram, Gauge, generate_latest, CONTENT_TYPE_LATEST\n",
    "import structlog\n",
    "\n",
    "# Docker\n",
    "import docker\n",
    "\n",
    "# ë¡œì»¬ ëª¨ë“ˆ\n",
    "sys.path.append('..')\n",
    "from config import get_config\n",
    "\n",
    "# ì„¤ì •\n",
    "config = get_config()\n",
    "logger = structlog.get_logger(__name__)\n",
    "\n",
    "print(\"ë°°í¬ ê´€ë ¨ ëª¨ë“ˆ ì„í¬íŠ¸ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fastapi-setup",
   "metadata": {},
   "source": [
    "## 1. FastAPI ì„œë²„ êµ¬ì¶•\n",
    "\n",
    "### 1.1 ê¸°ë³¸ API ëª¨ë¸ ì •ì˜\n",
    "API ìš”ì²­/ì‘ë‹µì„ ìœ„í•œ ë°ì´í„° ëª¨ë¸ì„ ì •ì˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "api-models",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prometheus ë©”íŠ¸ë¦­ ì •ì˜\n",
    "API_REQUESTS_TOTAL = Counter('api_requests_total', 'Total API requests', ['method', 'endpoint', 'status'])\n",
    "API_REQUEST_DURATION = Histogram('api_request_duration_seconds', 'API request duration')\n",
    "ACTIVE_CONNECTIONS = Gauge('api_active_connections', 'Active API connections')\n",
    "\n",
    "# API ë°ì´í„° ëª¨ë¸\n",
    "class ChatRequest(BaseModel):\n",
    "    \"\"\"ì±„íŒ… ìš”ì²­ ëª¨ë¸\"\"\"\n",
    "    message: str = Field(..., description=\"ì‚¬ìš©ì ë©”ì‹œì§€\")\n",
    "    conversation_id: Optional[str] = Field(None, description=\"ëŒ€í™” ID\")\n",
    "    model: str = Field(\"gpt-3.5-turbo\", description=\"ì‚¬ìš©í•  ëª¨ë¸\")\n",
    "    temperature: float = Field(0.7, description=\"ì‘ë‹µ ì°½ì˜ì„±\")\n",
    "    max_tokens: Optional[int] = Field(None, description=\"ìµœëŒ€ í† í° ìˆ˜\")\n",
    "    stream: bool = Field(False, description=\"ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì—¬ë¶€\")\n",
    "    use_cache: bool = Field(True, description=\"ìºì‹œ ì‚¬ìš© ì—¬ë¶€\")\n",
    "\n",
    "class ChatResponse(BaseModel):\n",
    "    \"\"\"ì±„íŒ… ì‘ë‹µ ëª¨ë¸\"\"\"\n",
    "    response: str\n",
    "    conversation_id: str\n",
    "    model: str\n",
    "    usage: Dict[str, int]\n",
    "    response_time: float\n",
    "    cached: bool\n",
    "    timestamp: str\n",
    "\n",
    "class HealthResponse(BaseModel):\n",
    "    \"\"\"í—¬ìŠ¤ ì²´í¬ ì‘ë‹µ\"\"\"\n",
    "    status: str\n",
    "    timestamp: str\n",
    "    version: str\n",
    "    uptime: float\n",
    "    services: Dict[str, str]\n",
    "\n",
    "# ë³´ì•ˆ\n",
    "security = HTTPBearer(auto_error=False)\n",
    "\n",
    "print(\"API ëª¨ë¸ ì •ì˜ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fastapi-app",
   "metadata": {},
   "source": [
    "### 1.2 FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜ êµ¬ì„±\n",
    "ë¯¸ë“¤ì›¨ì–´ì™€ ë¼ìš°í„°ë¥¼ í¬í•¨í•œ ì™„ì „í•œ API ì„œë²„ë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fastapi-application",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductionChatbotAPI:\n",
    "    \"\"\"í”„ë¡œë•ì…˜ìš© ì±—ë´‡ API ì„œë²„\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"API ì„œë²„ ì´ˆê¸°í™”\"\"\"\n",
    "        self.app = FastAPI(\n",
    "            title=\"AI Chatbot API\",\n",
    "            description=\"Production-ready AI Chatbot API\",\n",
    "            version=\"1.0.0\",\n",
    "            docs_url=\"/docs\",\n",
    "            redoc_url=\"/redoc\"\n",
    "        )\n",
    "        \n",
    "        # ì‹œì‘ ì‹œê°„\n",
    "        self.start_time = time.time()\n",
    "        \n",
    "        # ë¯¸ë“¤ì›¨ì–´ ì„¤ì •\n",
    "        self._setup_middleware()\n",
    "        \n",
    "        # ë¼ìš°í„° ì„¤ì •\n",
    "        self._setup_routes()\n",
    "    \n",
    "    def _setup_middleware(self):\n",
    "        \"\"\"ë¯¸ë“¤ì›¨ì–´ ì„¤ì •\"\"\"\n",
    "        # CORS ì„¤ì •\n",
    "        self.app.add_middleware(\n",
    "            CORSMiddleware,\n",
    "            allow_origins=[\"http://localhost:3000\", \"http://localhost:8080\"],\n",
    "            allow_credentials=True,\n",
    "            allow_methods=[\"GET\", \"POST\"],\n",
    "            allow_headers=[\"*\"],\n",
    "        )\n",
    "        \n",
    "        # ì»¤ìŠ¤í…€ ëª¨ë‹ˆí„°ë§ ë¯¸ë“¤ì›¨ì–´\n",
    "        @self.app.middleware(\"http\")\n",
    "        async def monitoring_middleware(request: Request, call_next):\n",
    "            \"\"\"ìš”ì²­ ëª¨ë‹ˆí„°ë§ ë¯¸ë“¤ì›¨ì–´\"\"\"\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # í™œì„± ì—°ê²° ìˆ˜ ì¦ê°€\n",
    "            ACTIVE_CONNECTIONS.inc()\n",
    "            \n",
    "            try:\n",
    "                response = await call_next(request)\n",
    "                \n",
    "                # ë©”íŠ¸ë¦­ ê¸°ë¡\n",
    "                duration = time.time() - start_time\n",
    "                API_REQUEST_DURATION.observe(duration)\n",
    "                API_REQUESTS_TOTAL.labels(\n",
    "                    method=request.method,\n",
    "                    endpoint=request.url.path,\n",
    "                    status=response.status_code\n",
    "                ).inc()\n",
    "                \n",
    "                # ì‘ë‹µ í—¤ë”ì— ì¶”ê°€ ì •ë³´\n",
    "                response.headers[\"X-Response-Time\"] = str(duration)\n",
    "                response.headers[\"X-Request-ID\"] = str(uuid.uuid4())\n",
    "                \n",
    "                return response\n",
    "                \n",
    "            except Exception as e:\n",
    "                # ì—ëŸ¬ ë©”íŠ¸ë¦­\n",
    "                API_REQUESTS_TOTAL.labels(\n",
    "                    method=request.method,\n",
    "                    endpoint=request.url.path,\n",
    "                    status=500\n",
    "                ).inc()\n",
    "                \n",
    "                logger.error(f\"ìš”ì²­ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "                raise\n",
    "            \n",
    "            finally:\n",
    "                # í™œì„± ì—°ê²° ìˆ˜ ê°ì†Œ\n",
    "                ACTIVE_CONNECTIONS.dec()\n",
    "    \n",
    "    def _setup_routes(self):\n",
    "        \"\"\"API ë¼ìš°í„° ì„¤ì •\"\"\"\n",
    "        \n",
    "        @self.app.get(\"/health\", response_model=HealthResponse)\n",
    "        async def health_check():\n",
    "            \"\"\"í—¬ìŠ¤ ì²´í¬\"\"\"\n",
    "            uptime = time.time() - self.start_time\n",
    "            \n",
    "            # ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸\n",
    "            services = {\n",
    "                \"api\": \"healthy\",\n",
    "                \"database\": \"healthy\",  # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” DB ì—°ê²° í™•ì¸\n",
    "                \"redis\": \"healthy\",     # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” Redis ì—°ê²° í™•ì¸\n",
    "                \"openai\": \"healthy\"     # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” API í‚¤ ê²€ì¦\n",
    "            }\n",
    "            \n",
    "            status = \"healthy\" if all(s == \"healthy\" for s in services.values()) else \"degraded\"\n",
    "            \n",
    "            return HealthResponse(\n",
    "                status=status,\n",
    "                timestamp=datetime.now().isoformat(),\n",
    "                version=\"1.0.0\",\n",
    "                uptime=uptime,\n",
    "                services=services\n",
    "            )\n",
    "        \n",
    "        @self.app.get(\"/metrics\")\n",
    "        async def metrics():\n",
    "            \"\"\"Prometheus ë©”íŠ¸ë¦­ ì—”ë“œí¬ì¸íŠ¸\"\"\"\n",
    "            return Response(generate_latest(), media_type=CONTENT_TYPE_LATEST)\n",
    "        \n",
    "        @self.app.post(\"/chat\", response_model=ChatResponse)\n",
    "        async def chat_completion(\n",
    "            request: ChatRequest,\n",
    "            background_tasks: BackgroundTasks,\n",
    "            auth: Optional[HTTPAuthorizationCredentials] = Depends(security)\n",
    "        ):\n",
    "            \"\"\"ì±„íŒ… ì™„ì„± API\"\"\"\n",
    "            start_time = time.time()\n",
    "            \n",
    "            try:\n",
    "                # ëŒ€í™” ID ìƒì„±\n",
    "                conversation_id = request.conversation_id or str(uuid.uuid4())\n",
    "                \n",
    "                # ì‹œë®¬ë ˆì´ì…˜ëœ ì‘ë‹µ (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ì´ì „ ì°¨ì‹œ ì½”ë“œ í™œìš©)\n",
    "                await asyncio.sleep(0.1)  # API í˜¸ì¶œ ì‹œë®¬ë ˆì´ì…˜\n",
    "                \n",
    "                response_text = f\"ì•ˆë…•í•˜ì„¸ìš”! '{request.message}'ì— ëŒ€í•œ ë‹µë³€ì…ë‹ˆë‹¤. ì´ê²ƒì€ í…ŒìŠ¤íŠ¸ ì‘ë‹µì…ë‹ˆë‹¤.\"\n",
    "                \n",
    "                # ì‘ë‹µ êµ¬ì„±\n",
    "                response = ChatResponse(\n",
    "                    response=response_text,\n",
    "                    conversation_id=conversation_id,\n",
    "                    model=request.model,\n",
    "                    usage={\n",
    "                        \"prompt_tokens\": len(request.message.split()) * 2,\n",
    "                        \"completion_tokens\": len(response_text.split()) * 2,\n",
    "                        \"total_tokens\": (len(request.message) + len(response_text)) * 2\n",
    "                    },\n",
    "                    response_time=time.time() - start_time,\n",
    "                    cached=False,\n",
    "                    timestamp=datetime.now().isoformat()\n",
    "                )\n",
    "                \n",
    "                return response\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"ì±„íŒ… ì™„ì„± ì˜¤ë¥˜: {e}\")\n",
    "                raise HTTPException(status_code=500, detail=f\"ë‚´ë¶€ ì„œë²„ ì˜¤ë¥˜: {str(e)}\")\n",
    "        \n",
    "        @self.app.get(\"/\")\n",
    "        async def root():\n",
    "            \"\"\"ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸\"\"\"\n",
    "            return {\n",
    "                \"message\": \"AI Chatbot API\",\n",
    "                \"version\": \"1.0.0\",\n",
    "                \"docs_url\": \"/docs\",\n",
    "                \"health_url\": \"/health\"\n",
    "            }\n",
    "\n",
    "# API ì„œë²„ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "api_server = ProductionChatbotAPI()\n",
    "app = api_server.app\n",
    "\n",
    "print(\"FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜ êµ¬ì„± ì™„ë£Œ!\")\n",
    "print(\"ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì„œë²„ë¥¼ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\")\n",
    "print(\"uvicorn lesson7_deployment_integration:app --host 0.0.0.0 --port 8000 --reload\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "docker-setup",
   "metadata": {},
   "source": [
    "## 2. Docker ì»¨í…Œì´ë„ˆí™”\n",
    "\n",
    "### 2.1 Docker íŒŒì¼ ìƒì„±\n",
    "ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì»¨í…Œì´ë„ˆí™”í•˜ê¸° ìœ„í•œ Dockerfileì„ ìƒì„±í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "docker-manager",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DockerManager:\n",
    "    \"\"\"Docker ë°°í¬ ê´€ë¦¬ì\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Docker ë§¤ë‹ˆì € ì´ˆê¸°í™”\"\"\"\n",
    "        try:\n",
    "            self.client = docker.from_env()\n",
    "            self.logger = structlog.get_logger(__name__)\n",
    "            self.logger.info(\"Docker í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ\")\n",
    "        except Exception as e:\n",
    "            print(f\"Docker í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}\")\n",
    "            print(\"Dockerê°€ ì„¤ì¹˜ë˜ì–´ ìˆê³  ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.\")\n",
    "            self.client = None\n",
    "            self.logger = None\n",
    "    \n",
    "    def generate_dockerfile(self, output_path: str = \"Dockerfile\"):\n",
    "        \"\"\"Dockerfile ìƒì„±\"\"\"\n",
    "        dockerfile_content = '''# ë©€í‹°ìŠ¤í…Œì´ì§€ ë¹Œë“œ\n",
    "FROM python:3.9-slim as builder\n",
    "\n",
    "# ì‹œìŠ¤í…œ ì˜ì¡´ì„± ì„¤ì¹˜\n",
    "RUN apt-get update && apt-get install -y \\\\\n",
    "    build-essential \\\\\n",
    "    curl \\\\\n",
    "    && rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "# Python ì˜ì¡´ì„± ì„¤ì¹˜\n",
    "COPY requirements.txt .\n",
    "RUN pip install --no-cache-dir --user -r requirements.txt\n",
    "\n",
    "# í”„ë¡œë•ì…˜ ìŠ¤í…Œì´ì§€\n",
    "FROM python:3.9-slim\n",
    "\n",
    "# ì‹œìŠ¤í…œ ì‚¬ìš©ì ìƒì„±\n",
    "RUN groupadd -r appuser && useradd -r -g appuser appuser\n",
    "\n",
    "# í•„ìš”í•œ ì‹œìŠ¤í…œ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "RUN apt-get update && apt-get install -y \\\\\n",
    "    curl \\\\\n",
    "    && rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "# Python íŒ¨í‚¤ì§€ ë³µì‚¬\n",
    "COPY --from=builder /root/.local /home/appuser/.local\n",
    "\n",
    "# ì• í”Œë¦¬ì¼€ì´ì…˜ ë””ë ‰í† ë¦¬ ìƒì„±\n",
    "WORKDIR /app\n",
    "\n",
    "# ì†ŒìŠ¤ ì½”ë“œ ë³µì‚¬\n",
    "COPY --chown=appuser:appuser . .\n",
    "\n",
    "# í¬íŠ¸ ë…¸ì¶œ\n",
    "EXPOSE 8000\n",
    "\n",
    "# í—¬ìŠ¤ ì²´í¬\n",
    "HEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \\\\\n",
    "    CMD curl -f http://localhost:8000/health || exit 1\n",
    "\n",
    "# ì‚¬ìš©ì ë³€ê²½\n",
    "USER appuser\n",
    "\n",
    "# í™˜ê²½ ë³€ìˆ˜\n",
    "ENV PATH=/home/appuser/.local/bin:$PATH\n",
    "ENV PYTHONPATH=/app\n",
    "\n",
    "# ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰\n",
    "CMD [\"uvicorn\", \"lesson7.lesson7_deployment_integration:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n",
    "'''\n",
    "        \n",
    "        with open(output_path, 'w') as f:\n",
    "            f.write(dockerfile_content)\n",
    "        \n",
    "        print(f\"Dockerfile ìƒì„± ì™„ë£Œ: {output_path}\")\n",
    "        return output_path\n",
    "    \n",
    "    def generate_docker_compose(self, output_path: str = \"docker-compose.yml\"):\n",
    "        \"\"\"docker-compose.yml ìƒì„±\"\"\"\n",
    "        compose_content = '''version: '3.8'\n",
    "\n",
    "services:\n",
    "  chatbot-api:\n",
    "    build:\n",
    "      context: .\n",
    "      dockerfile: Dockerfile\n",
    "    container_name: chatbot-api\n",
    "    ports:\n",
    "      - \"8000:8000\"\n",
    "    environment:\n",
    "      - REDIS_HOST=redis\n",
    "      - REDIS_PORT=6379\n",
    "      - ENVIRONMENT=production\n",
    "    volumes:\n",
    "      - ./logs:/app/logs\n",
    "      - ./data:/app/data\n",
    "    depends_on:\n",
    "      - redis\n",
    "      - prometheus\n",
    "    restart: unless-stopped\n",
    "    networks:\n",
    "      - chatbot-network\n",
    "\n",
    "  redis:\n",
    "    image: redis:7-alpine\n",
    "    container_name: chatbot-redis\n",
    "    ports:\n",
    "      - \"6379:6379\"\n",
    "    volumes:\n",
    "      - redis_data:/data\n",
    "    restart: unless-stopped\n",
    "    networks:\n",
    "      - chatbot-network\n",
    "\n",
    "  prometheus:\n",
    "    image: prom/prometheus:latest\n",
    "    container_name: chatbot-prometheus\n",
    "    ports:\n",
    "      - \"9090:9090\"\n",
    "    volumes:\n",
    "      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml\n",
    "      - prometheus_data:/prometheus\n",
    "    restart: unless-stopped\n",
    "    networks:\n",
    "      - chatbot-network\n",
    "\n",
    "  grafana:\n",
    "    image: grafana/grafana:latest\n",
    "    container_name: chatbot-grafana\n",
    "    ports:\n",
    "      - \"3000:3000\"\n",
    "    volumes:\n",
    "      - grafana_data:/var/lib/grafana\n",
    "    environment:\n",
    "      - GF_SECURITY_ADMIN_PASSWORD=admin\n",
    "    restart: unless-stopped\n",
    "    networks:\n",
    "      - chatbot-network\n",
    "\n",
    "volumes:\n",
    "  redis_data:\n",
    "  prometheus_data:\n",
    "  grafana_data:\n",
    "\n",
    "networks:\n",
    "  chatbot-network:\n",
    "    driver: bridge\n",
    "'''\n",
    "        \n",
    "        with open(output_path, 'w') as f:\n",
    "            f.write(compose_content)\n",
    "        \n",
    "        print(f\"docker-compose.yml ìƒì„± ì™„ë£Œ: {output_path}\")\n",
    "        return output_path\n",
    "    \n",
    "    def create_deployment_script(self, output_path: str = \"deploy.sh\"):\n",
    "        \"\"\"ë°°í¬ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±\"\"\"\n",
    "        deploy_script = '''#!/bin/bash\n",
    "set -e\n",
    "\n",
    "echo \"=== AI ì±—ë´‡ API ë°°í¬ ì‹œì‘ ===\"\n",
    "\n",
    "# í™˜ê²½ ë³€ìˆ˜ í™•ì¸\n",
    "if [ -z \"$OPENAI_API_KEY\" ]; then\n",
    "    echo \"OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\"\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "# Docker ì´ë¯¸ì§€ ë¹Œë“œ\n",
    "echo \"Docker ì´ë¯¸ì§€ ë¹Œë“œ ì¤‘...\"\n",
    "docker-compose build --no-cache\n",
    "\n",
    "# ê¸°ì¡´ ì»¨í…Œì´ë„ˆ ì¤‘ì§€\n",
    "echo \"ê¸°ì¡´ ì„œë¹„ìŠ¤ ì¤‘ì§€ ì¤‘...\"\n",
    "docker-compose down\n",
    "\n",
    "# ìƒˆ ì»¨í…Œì´ë„ˆ ì‹œì‘\n",
    "echo \"ìƒˆ ì„œë¹„ìŠ¤ ì‹œì‘ ì¤‘...\"\n",
    "docker-compose up -d\n",
    "\n",
    "# í—¬ìŠ¤ ì²´í¬\n",
    "echo \"í—¬ìŠ¤ ì²´í¬ ì¤‘...\"\n",
    "sleep 30\n",
    "curl -f http://localhost:8000/health || exit 1\n",
    "\n",
    "echo \"=== ë°°í¬ ì™„ë£Œ ===\"\n",
    "echo \"API ë¬¸ì„œ: http://localhost:8000/docs\"\n",
    "echo \"Grafana: http://localhost:3000 (admin/admin)\"\n",
    "echo \"Prometheus: http://localhost:9090\"\n",
    "'''\n",
    "        \n",
    "        with open(output_path, 'w') as f:\n",
    "            f.write(deploy_script)\n",
    "        \n",
    "        # ì‹¤í–‰ ê¶Œí•œ ë¶€ì—¬\n",
    "        os.chmod(output_path, 0o755)\n",
    "        \n",
    "        print(f\"ë°°í¬ ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì™„ë£Œ: {output_path}\")\n",
    "        return output_path\n",
    "\n",
    "# Docker ê´€ë¦¬ì í…ŒìŠ¤íŠ¸\n",
    "docker_manager = DockerManager()\n",
    "\n",
    "if docker_manager.client:\n",
    "    # Docker íŒŒì¼ë“¤ ìƒì„±\n",
    "    dockerfile_path = docker_manager.generate_dockerfile()\n",
    "    compose_path = docker_manager.generate_docker_compose()\n",
    "    deploy_script_path = docker_manager.create_deployment_script()\n",
    "    \n",
    "    print(\"\\nğŸ³ Docker ì„¤ì • íŒŒì¼ë“¤ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤:\")\n",
    "    print(f\"  - {dockerfile_path}\")\n",
    "    print(f\"  - {compose_path}\")\n",
    "    print(f\"  - {deploy_script_path}\")\n",
    "    \n",
    "    print(\"\\në‹¤ìŒ ëª…ë ¹ì–´ë¡œ ë°°í¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\")\n",
    "    print(f\"  chmod +x {deploy_script_path}\")\n",
    "    print(f\"  ./{deploy_script_path}\")\nelse:\n",
    "    print(\"âš ï¸ Dockerê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. ìˆ˜ë™ìœ¼ë¡œ íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤.\")\n",
    "    \n",
    "    # Docker íŒŒì¼ë“¤ ìˆ˜ë™ ìƒì„±\n",
    "    docker_manager.generate_dockerfile()\n",
    "    docker_manager.generate_docker_compose()\n",
    "    docker_manager.create_deployment_script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}