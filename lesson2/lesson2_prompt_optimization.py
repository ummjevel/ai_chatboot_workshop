#!/usr/bin/env python3
"""
2ì°¨ì‹œ: í”„ë¡¬í”„íŠ¸ ì‹¤ë¬´ ìµœì í™”
Author: AI Chatbot Workshop
Date: 2024-08-30
Description: Jinja2 ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì‹œìŠ¤í…œ, í˜ë¥´ì†Œë‚˜ ì ìš©, íŠ¸ëŸ¬ë¸”ìŠˆíŒ… í•´ê²°
"""

import os
import json
import time
import logging
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime
from dataclasses import dataclass, asdict
from abc import ABC, abstractmethod
import hashlib
import random
from jinja2 import Template, Environment, FileSystemLoader
from openai import OpenAI
import streamlit as st

# ë¡œì»¬ ëª¨ë“ˆ
import sys
sys.path.append('..')
from config import get_config

config = get_config()
logger = logging.getLogger(__name__)

@dataclass
class PromptTemplate:
    """í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ êµ¬ì¡°"""
    name: str
    category: str
    template: str
    variables: List[str]
    description: str
    author: str
    version: str = "1.0"
    created_at: datetime = None
    
    def __post_init__(self):
        if self.created_at is None:
            self.created_at = datetime.now()

@dataclass
class PersonaConfig:
    """í˜ë¥´ì†Œë‚˜ ì„¤ì •"""
    name: str
    role: str
    tone: str
    expertise: List[str]
    constraints: List[str]
    examples: List[Dict[str, str]]
    brand_guidelines: Optional[Dict[str, Any]] = None

@dataclass
class PromptTestResult:
    """í”„ë¡¬í”„íŠ¸ í…ŒìŠ¤íŠ¸ ê²°ê³¼"""
    template_name: str
    test_input: Dict[str, Any]
    generated_prompt: str
    response: str
    tokens_used: int
    processing_time: float
    quality_score: float
    timestamp: datetime

class PromptTemplateEngine:
    """Jinja2 ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì—”ì§„"""
    
    def __init__(self, template_dir: str = "templates"):
        """
        Args:
            template_dir: í…œí”Œë¦¿ íŒŒì¼ì´ ì €ì¥ëœ ë””ë ‰í† ë¦¬
        """
        self.template_dir = template_dir
        self.env = Environment(
            loader=FileSystemLoader(template_dir) if os.path.exists(template_dir) else None,
            trim_blocks=True,
            lstrip_blocks=True
        )
        self.templates: Dict[str, PromptTemplate] = {}
        self._load_default_templates()
        logger.info(f"í”„ë¡¬í”„íŠ¸ ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ - í…œí”Œë¦¿ ìˆ˜: {len(self.templates)}")
    
    def _load_default_templates(self):
        """ê¸°ë³¸ í…œí”Œë¦¿ ë¡œë“œ"""
        default_templates = {
            "general_assistant": PromptTemplate(
                name="general_assistant",
                category="ê¸°ë³¸",
                template="""ë‹¹ì‹ ì€ {{persona.role}}ì…ë‹ˆë‹¤. {{persona.tone}} í†¤ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.

ì „ë¬¸ë¶„ì•¼: {{persona.expertise|join(', ')}}

ì œì•½ì‚¬í•­:
{% for constraint in persona.constraints %}
- {{constraint}}
{% endfor %}

ì‚¬ìš©ì ì§ˆë¬¸: {{user_question}}

ë‹µë³€ í˜•ì‹: {{response_format}}
ë‹µë³€ ê¸¸ì´: {{length_limit}}ì ì´ë‚´""",
                variables=["persona", "user_question", "response_format", "length_limit"],
                description="ì¼ë°˜ì ì¸ ì–´ì‹œìŠ¤í„´íŠ¸ ì—­í• ì„ ìœ„í•œ ê¸°ë³¸ í…œí”Œë¦¿",
                author="AI Workshop"
            ),
            
            "code_reviewer": PromptTemplate(
                name="code_reviewer",
                category="ê°œë°œ",
                template="""ë‹¹ì‹ ì€ {{years_experience}}ë…„ ê²½ë ¥ì˜ {{programming_language}} ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ë‹¤ìŒ ì½”ë“œë¥¼ ë¦¬ë·°í•´ì£¼ì„¸ìš”:

```{{programming_language}}
{{code_snippet}}
```

ë¦¬ë·° ê´€ì :
{% for aspect in review_aspects %}
- {{aspect}}
{% endfor %}

ì¶œë ¥ í˜•ì‹:
1. ì½”ë“œ í’ˆì§ˆ ì ìˆ˜ (1-10)
2. ì£¼ìš” ê°œì„ ì‚¬í•­
3. ë³´ì•ˆ ì´ìŠˆ
4. ì„±ëŠ¥ ìµœì í™” ì œì•ˆ
5. ê°œì„ ëœ ì½”ë“œ ì˜ˆì‹œ""",
                variables=["years_experience", "programming_language", "code_snippet", "review_aspects"],
                description="ì½”ë“œ ë¦¬ë·°ë¥¼ ìœ„í•œ ì „ë¬¸ í…œí”Œë¦¿",
                author="AI Workshop"
            ),
            
            "customer_support": PromptTemplate(
                name="customer_support",
                category="ê³ ê°ì§€ì›",
                template="""ì•ˆë…•í•˜ì„¸ìš”! {{company_name}} ê³ ê°ì§€ì›íŒ€ì˜ {{agent_name}}ì…ë‹ˆë‹¤.

ë¸Œëœë“œ ê°€ì´ë“œë¼ì¸:
- í†¤: {{brand_tone}}
- í•µì‹¬ê°€ì¹˜: {{brand_values|join(', ')}}
- ê¸ˆì§€ì–´: {{forbidden_words|join(', ')}}

ê³ ê° ë¬¸ì˜:
ë¶„ë¥˜: {{inquiry_category}}
ë‚´ìš©: {{customer_message}}
ìš°ì„ ìˆœìœ„: {{priority_level}}

{% if previous_interactions %}
ì´ì „ ìƒë‹´ ë‚´ì—­:
{% for interaction in previous_interactions %}
- {{interaction.date}}: {{interaction.summary}}
{% endfor %}
{% endif %}

ì‘ë‹µ ê°€ì´ë“œë¼ì¸:
1. ê³µê°ì  ì¸ì‚¬
2. ë¬¸ì œ íŒŒì•… í™•ì¸
3. êµ¬ì²´ì  í•´ê²°ë°©ì•ˆ ì œì‹œ
4. ì¶”ê°€ ë„ì›€ ì œì•ˆ

ìµœëŒ€ {{max_length}}ìë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.""",
                variables=["company_name", "agent_name", "brand_tone", "brand_values", 
                          "forbidden_words", "inquiry_category", "customer_message", 
                          "priority_level", "previous_interactions", "max_length"],
                description="ê³ ê°ì§€ì›ì„ ìœ„í•œ ë¸Œëœë“œ ê°€ì´ë“œë¼ì¸ ì ìš© í…œí”Œë¦¿",
                author="AI Workshop"
            ),
            
            "content_creator": PromptTemplate(
                name="content_creator",
                category="ë§ˆì¼€íŒ…",
                template="""ë‹¹ì‹ ì€ {{platform}} ì „ë¬¸ ì½˜í…ì¸  í¬ë¦¬ì—ì´í„°ì…ë‹ˆë‹¤.

ì½˜í…ì¸  ìš”êµ¬ì‚¬í•­:
- ì£¼ì œ: {{topic}}
- íƒ€ê²Ÿ ì˜¤ë””ì–¸ìŠ¤: {{target_audience}}
- ì½˜í…ì¸  ìœ í˜•: {{content_type}}
- ëª©í‘œ: {{marketing_goal}}
- í‚¤ì›Œë“œ: {{keywords|join(', ')}}

ë¸Œëœë“œ í†¤ì•¤ë§¤ë„ˆ:
- ìŠ¤íƒ€ì¼: {{brand_style}}
- ê°€ì¹˜ê´€: {{brand_values|join(', ')}}

{% if competitor_analysis %}
ê²½ìŸì‚¬ ë¶„ì„:
{% for competitor in competitor_analysis %}
- {{competitor.name}}: {{competitor.strategy}}
{% endfor %}
{% endif %}

ì½˜í…ì¸  êµ¬ì¡°:
1. í›„í¬ (ì²« ì¤„)
2. ë³¸ë¬¸ ({{content_length}} ë‹¨ì–´)
3. ì½œíˆ¬ì•¡ì…˜
4. í•´ì‹œíƒœê·¸ (ìµœëŒ€ {{max_hashtags}}ê°œ)

SEOë¥¼ ê³ ë ¤í•˜ì—¬ ì‘ì„±í•˜ë˜, ìì—°ìŠ¤ëŸ¬ìš´ íë¦„ì„ ìœ ì§€í•˜ì„¸ìš”.""",
                variables=["platform", "topic", "target_audience", "content_type", 
                          "marketing_goal", "keywords", "brand_style", "brand_values",
                          "competitor_analysis", "content_length", "max_hashtags"],
                description="ì†Œì…œë¯¸ë””ì–´ ë§ˆì¼€íŒ… ì½˜í…ì¸  ìƒì„± í…œí”Œë¦¿",
                author="AI Workshop"
            )
        }
        
        self.templates.update(default_templates)
    
    def add_template(self, template: PromptTemplate):
        """ìƒˆ í…œí”Œë¦¿ ì¶”ê°€"""
        self.templates[template.name] = template
        logger.info(f"í…œí”Œë¦¿ ì¶”ê°€: {template.name}")
    
    def get_template(self, name: str) -> Optional[PromptTemplate]:
        """í…œí”Œë¦¿ ì¡°íšŒ"""
        return self.templates.get(name)
    
    def list_templates(self, category: Optional[str] = None) -> List[PromptTemplate]:
        """í…œí”Œë¦¿ ëª©ë¡ ì¡°íšŒ"""
        if category:
            return [t for t in self.templates.values() if t.category == category]
        return list(self.templates.values())
    
    def render_prompt(self, template_name: str, variables: Dict[str, Any]) -> str:
        """
        í”„ë¡¬í”„íŠ¸ ë Œë”ë§
        
        Args:
            template_name: í…œí”Œë¦¿ ì´ë¦„
            variables: í…œí”Œë¦¿ ë³€ìˆ˜
            
        Returns:
            str: ë Œë”ë§ëœ í”„ë¡¬í”„íŠ¸
            
        Raises:
            ValueError: í…œí”Œë¦¿ì´ ì¡´ì¬í•˜ì§€ ì•Šê±°ë‚˜ í•„ìˆ˜ ë³€ìˆ˜ê°€ ëˆ„ë½ëœ ê²½ìš°
        """
        template_obj = self.get_template(template_name)
        if not template_obj:
            raise ValueError(f"í…œí”Œë¦¿ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {template_name}")
        
        # í•„ìˆ˜ ë³€ìˆ˜ í™•ì¸
        missing_vars = set(template_obj.variables) - set(variables.keys())
        if missing_vars:
            logger.warning(f"ëˆ„ë½ëœ ë³€ìˆ˜: {missing_vars}")
        
        try:
            jinja_template = Template(template_obj.template)
            rendered = jinja_template.render(**variables)
            
            logger.debug(f"í”„ë¡¬í”„íŠ¸ ë Œë”ë§ ì™„ë£Œ - í…œí”Œë¦¿: {template_name}, ê¸¸ì´: {len(rendered)}")
            return rendered
        
        except Exception as e:
            logger.error(f"í”„ë¡¬í”„íŠ¸ ë Œë”ë§ ì‹¤íŒ¨: {e}")
            raise

class PersonaManager:
    """í˜ë¥´ì†Œë‚˜ ê´€ë¦¬ì"""
    
    def __init__(self):
        self.personas: Dict[str, PersonaConfig] = {}
        self._load_default_personas()
        logger.info(f"í˜ë¥´ì†Œë‚˜ ê´€ë¦¬ì ì´ˆê¸°í™” - í˜ë¥´ì†Œë‚˜ ìˆ˜: {len(self.personas)}")
    
    def _load_default_personas(self):
        """ê¸°ë³¸ í˜ë¥´ì†Œë‚˜ ë¡œë“œ"""
        default_personas = {
            "friendly_assistant": PersonaConfig(
                name="ì¹œê·¼í•œ ë„ìš°ë¯¸",
                role="ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸",
                tone="ì¹œê·¼í•˜ê³  ë”°ëœ»í•œ",
                expertise=["ì¼ë°˜ ìƒì‹", "ë¬¸ì œ í•´ê²°", "ì •ë³´ ì œê³µ"],
                constraints=[
                    "í•­ìƒ ì •ì¤‘í•˜ê³  ì˜ˆì˜ë°”ë¥´ê²Œ ëŒ€ë‹µ",
                    "í™•ì‹¤í•˜ì§€ ì•Šì€ ì •ë³´ëŠ” ì¶”ì¸¡í•˜ì§€ ì•ŠìŒ",
                    "ê°œì¸ì •ë³´ëŠ” ì ˆëŒ€ ìš”ì²­í•˜ì§€ ì•ŠìŒ"
                ],
                examples=[
                    {
                        "input": "ì•ˆë…•í•˜ì„¸ìš”",
                        "output": "ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”? ê¶ê¸ˆí•œ ê²ƒì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ë§ì”€í•´ì£¼ì„¸ìš”."
                    }
                ]
            ),
            
            "technical_expert": PersonaConfig(
                name="ê¸°ìˆ  ì „ë¬¸ê°€",
                role="10ë…„ ê²½ë ¥ì˜ ì†Œí”„íŠ¸ì›¨ì–´ ì—”ì§€ë‹ˆì–´",
                tone="ì „ë¬¸ì ì´ë©´ì„œë„ ì´í•´í•˜ê¸° ì‰¬ìš´",
                expertise=["Python", "ì›¹ê°œë°œ", "AI/ML", "ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜", "ë°ì´í„°ë² ì´ìŠ¤"],
                constraints=[
                    "ì •í™•í•œ ê¸°ìˆ  ì •ë³´ë§Œ ì œê³µ",
                    "ì˜ˆì‹œ ì½”ë“œëŠ” ì‹¤í–‰ ê°€ëŠ¥í•´ì•¼ í•¨",
                    "ìµœì‹  ê¸°ìˆ  ë™í–¥ ë°˜ì˜",
                    "ì´ˆë³´ìë„ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì„¤ëª…"
                ],
                examples=[
                    {
                        "input": "Pythonìœ¼ë¡œ APIë¥¼ ì–´ë–»ê²Œ ë§Œë“¤ì–´ìš”?",
                        "output": "FastAPIë‚˜ Flaskë¥¼ ì‚¬ìš©í•˜ë©´ ì‰½ê²Œ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ FastAPIë¡œ ê°„ë‹¨í•œ APIë¥¼ ë§Œë“¤ì–´ë³´ê² ìŠµë‹ˆë‹¤..."
                    }
                ]
            ),
            
            "brand_ambassador": PersonaConfig(
                name="ë¸Œëœë“œ ì•°ë°°ì„œë”",
                role="ê¸°ì—… ë¸Œëœë“œ ëŒ€ë³€ì¸",
                tone="ì „ë¬¸ì ì´ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ”",
                expertise=["ë¸Œëœë“œ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜", "ê³ ê° ì„œë¹„ìŠ¤", "ë§ˆì¼€íŒ…"],
                constraints=[
                    "ë¸Œëœë“œ ê°€ì¹˜ì™€ ì¼ì¹˜í•˜ëŠ” ë©”ì‹œì§€",
                    "ê²½ìŸì‚¬ ì–¸ê¸‰ ê¸ˆì§€",
                    "ë¶€ì •ì  í‘œí˜„ ìµœì†Œí™”",
                    "í•­ìƒ ì†”ë£¨ì…˜ ì¤‘ì‹¬ì  ì ‘ê·¼"
                ],
                examples=[
                    {
                        "input": "ì œí’ˆì— ë¬¸ì œê°€ ìˆì–´ìš”",
                        "output": "ë¶ˆí¸ì„ ë¼ì³ë“œë ¤ ì£„ì†¡í•©ë‹ˆë‹¤. ë¹ ë¥¸ í•´ê²°ì„ ìœ„í•´ êµ¬ì²´ì ì¸ ìƒí™©ì„ ì•Œë ¤ì£¼ì‹œê² ì–´ìš”? ìµœì„ ì„ ë‹¤í•´ ë„ì›€ë“œë¦¬ê² ìŠµë‹ˆë‹¤."
                    }
                ],
                brand_guidelines={
                    "tone": "professional_friendly",
                    "values": ["ê³ ê°ì¤‘ì‹¬", "í˜ì‹ ", "ì‹ ë¢°", "í’ˆì§ˆ"],
                    "forbidden_words": ["ë¬¸ì œ", "ë¶ˆê°€ëŠ¥", "ì•ˆë¨", "ëª¨ë¦„"],
                    "preferred_words": ["í•´ê²°", "ê°€ëŠ¥", "ë„ì›€", "ì§€ì›"]
                }
            )
        }
        
        self.personas.update(default_personas)
    
    def add_persona(self, persona: PersonaConfig):
        """ìƒˆ í˜ë¥´ì†Œë‚˜ ì¶”ê°€"""
        self.personas[persona.name] = persona
        logger.info(f"í˜ë¥´ì†Œë‚˜ ì¶”ê°€: {persona.name}")
    
    def get_persona(self, name: str) -> Optional[PersonaConfig]:
        """í˜ë¥´ì†Œë‚˜ ì¡°íšŒ"""
        return self.personas.get(name)
    
    def list_personas(self) -> List[PersonaConfig]:
        """í˜ë¥´ì†Œë‚˜ ëª©ë¡"""
        return list(self.personas.values())

class PromptOptimizer:
    """í”„ë¡¬í”„íŠ¸ ìµœì í™” ë° A/B í…ŒìŠ¤íŠ¸"""
    
    def __init__(self, openai_client: OpenAI, template_engine: PromptTemplateEngine):
        self.client = openai_client
        self.template_engine = template_engine
        self.test_results: List[PromptTestResult] = []
        logger.info("í”„ë¡¬í”„íŠ¸ ìµœì í™” ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def generate_prompt_variations(self, base_template: str, 
                                 variations_config: Dict[str, List[str]]) -> List[str]:
        """
        í”„ë¡¬í”„íŠ¸ ë³€í˜• ìƒì„±
        
        Args:
            base_template: ê¸°ë³¸ í…œí”Œë¦¿
            variations_config: ë³€í˜• ì„¤ì • {'temperature': [0.1, 0.7, 0.9], ...}
            
        Returns:
            List[str]: ë³€í˜•ëœ í”„ë¡¬í”„íŠ¸ë“¤
        """
        variations = []
        
        # ì˜¨ë„ ë³€í˜•
        if 'temperature_hints' in variations_config:
            for temp_hint in variations_config['temperature_hints']:
                variation = f"{base_template}\n\n{temp_hint}"
                variations.append(variation)
        
        # í†¤ ë³€í˜•
        if 'tone_variations' in variations_config:
            for tone in variations_config['tone_variations']:
                variation = base_template.replace("ë‹µë³€í•´ì£¼ì„¸ìš”", f"{tone} í†¤ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”")
                variations.append(variation)
        
        # ê¸¸ì´ ì œí•œ ë³€í˜•
        if 'length_limits' in variations_config:
            for length in variations_config['length_limits']:
                variation = f"{base_template}\n\në‹µë³€ì€ {length}ì ì´ë‚´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”."
                variations.append(variation)
        
        logger.info(f"í”„ë¡¬í”„íŠ¸ ë³€í˜• {len(variations)}ê°œ ìƒì„±")
        return variations
    
    def test_prompt_quality(self, prompt: str, test_inputs: List[str]) -> float:
        """
        í”„ë¡¬í”„íŠ¸ í’ˆì§ˆ í‰ê°€
        
        Args:
            prompt: í…ŒìŠ¤íŠ¸í•  í”„ë¡¬í”„íŠ¸
            test_inputs: í…ŒìŠ¤íŠ¸ ì…ë ¥ë“¤
            
        Returns:
            float: í’ˆì§ˆ ì ìˆ˜ (0-100)
        """
        scores = []
        
        for test_input in test_inputs:
            try:
                # API í˜¸ì¶œ
                messages = [
                    {"role": "system", "content": prompt},
                    {"role": "user", "content": test_input}
                ]
                
                response = self.client.chat.completions.create(
                    model=config.llm.openai_model,
                    messages=messages,
                    max_tokens=200,
                    temperature=0.1  # ì¼ê´€ì„±ì„ ìœ„í•´ ë‚®ì€ temperature ì‚¬ìš©
                )
                
                answer = response.choices[0].message.content
                
                # í’ˆì§ˆ í‰ê°€ (ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±)
                score = self._calculate_quality_score(test_input, answer, prompt)
                scores.append(score)
                
            except Exception as e:
                logger.error(f"í’ˆì§ˆ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
                scores.append(0)
        
        avg_score = sum(scores) / len(scores) if scores else 0
        logger.info(f"í‰ê·  í’ˆì§ˆ ì ìˆ˜: {avg_score:.1f}")
        return avg_score
    
    def _calculate_quality_score(self, input_text: str, output_text: str, prompt: str) -> float:
        """í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° (íœ´ë¦¬ìŠ¤í‹±)"""
        score = 50  # ê¸°ë³¸ ì ìˆ˜
        
        # ê¸¸ì´ ì ì ˆì„± (ë„ˆë¬´ ì§§ê±°ë‚˜ ê¸¸ì§€ ì•ŠìŒ)
        if 50 <= len(output_text) <= 500:
            score += 20
        
        # ê´€ë ¨ì„± (ì…ë ¥ê³¼ ì¶œë ¥ì˜ í‚¤ì›Œë“œ ë§¤ì¹­)
        input_words = set(input_text.lower().split())
        output_words = set(output_text.lower().split())
        relevance = len(input_words & output_words) / len(input_words) if input_words else 0
        score += relevance * 20
        
        # êµ¬ì¡°í™” (ë¬¸ì¥ êµ¬ì¡°)
        if '. ' in output_text or '\n' in output_text:
            score += 10
        
        return min(100, max(0, score))
    
    def run_ab_test(self, prompt_a: str, prompt_b: str, 
                   test_inputs: List[str], test_name: str = "A/B Test") -> Dict[str, Any]:
        """
        A/B í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        
        Args:
            prompt_a: í”„ë¡¬í”„íŠ¸ A
            prompt_b: í”„ë¡¬í”„íŠ¸ B  
            test_inputs: í…ŒìŠ¤íŠ¸ ì…ë ¥ë“¤
            test_name: í…ŒìŠ¤íŠ¸ ì´ë¦„
            
        Returns:
            Dict: í…ŒìŠ¤íŠ¸ ê²°ê³¼
        """
        logger.info(f"A/B í…ŒìŠ¤íŠ¸ ì‹œì‘: {test_name}")
        start_time = time.time()
        
        results_a = []
        results_b = []
        
        for i, test_input in enumerate(test_inputs):
            # í”„ë¡¬í”„íŠ¸ A í…ŒìŠ¤íŠ¸
            result_a = self._test_single_prompt(f"A_{i}", prompt_a, test_input)
            results_a.append(result_a)
            
            # í”„ë¡¬í”„íŠ¸ B í…ŒìŠ¤íŠ¸
            result_b = self._test_single_prompt(f"B_{i}", prompt_b, test_input)
            results_b.append(result_b)
            
            # ì €ì¥
            self.test_results.extend([result_a, result_b])
        
        # ê²°ê³¼ ë¶„ì„
        avg_score_a = sum(r.quality_score for r in results_a) / len(results_a)
        avg_score_b = sum(r.quality_score for r in results_b) / len(results_b)
        avg_time_a = sum(r.processing_time for r in results_a) / len(results_a)
        avg_time_b = sum(r.processing_time for r in results_b) / len(results_b)
        avg_tokens_a = sum(r.tokens_used for r in results_a) / len(results_a)
        avg_tokens_b = sum(r.tokens_used for r in results_b) / len(results_b)
        
        total_time = time.time() - start_time
        
        # ìŠ¹ì ê²°ì •
        winner = "A" if avg_score_a > avg_score_b else "B"
        score_diff = abs(avg_score_a - avg_score_b)
        
        result = {
            "test_name": test_name,
            "winner": winner,
            "score_difference": score_diff,
            "results": {
                "prompt_a": {
                    "avg_quality_score": avg_score_a,
                    "avg_processing_time": avg_time_a,
                    "avg_tokens": avg_tokens_a,
                    "results": results_a
                },
                "prompt_b": {
                    "avg_quality_score": avg_score_b,
                    "avg_processing_time": avg_time_b,
                    "avg_tokens": avg_tokens_b,
                    "results": results_b
                }
            },
            "test_duration": total_time,
            "total_tests": len(test_inputs) * 2,
            "timestamp": datetime.now()
        }
        
        logger.info(f"A/B í…ŒìŠ¤íŠ¸ ì™„ë£Œ - ìŠ¹ì: {winner}, ì ìˆ˜ì°¨: {score_diff:.1f}")
        return result
    
    def _test_single_prompt(self, test_id: str, prompt: str, test_input: str) -> PromptTestResult:
        """ë‹¨ì¼ í”„ë¡¬í”„íŠ¸ í…ŒìŠ¤íŠ¸"""
        start_time = time.time()
        
        try:
            messages = [
                {"role": "system", "content": prompt},
                {"role": "user", "content": test_input}
            ]
            
            response = self.client.chat.completions.create(
                model=config.llm.openai_model,
                messages=messages,
                max_tokens=300,
                temperature=0.7,
                seed=42  # ì¼ê´€ì„±ì„ ìœ„í•œ seed ê³ ì •
            )
            
            processing_time = time.time() - start_time
            answer = response.choices[0].message.content
            tokens = response.usage.total_tokens
            quality = self._calculate_quality_score(test_input, answer, prompt)
            
            return PromptTestResult(
                template_name=test_id,
                test_input={"user_input": test_input},
                generated_prompt=prompt,
                response=answer,
                tokens_used=tokens,
                processing_time=processing_time,
                quality_score=quality,
                timestamp=datetime.now()
            )
            
        except Exception as e:
            logger.error(f"í”„ë¡¬í”„íŠ¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            return PromptTestResult(
                template_name=test_id,
                test_input={"user_input": test_input},
                generated_prompt=prompt,
                response=f"ì˜¤ë¥˜: {str(e)}",
                tokens_used=0,
                processing_time=time.time() - start_time,
                quality_score=0,
                timestamp=datetime.now()
            )

class TroubleshootingSolver:
    """í”„ë¡¬í”„íŠ¸ íŠ¸ëŸ¬ë¸”ìŠˆíŒ… í•´ê²°ì‚¬"""
    
    @staticmethod
    def ensure_consistency(base_prompt: str) -> str:
        """ì¼ê´€ì„± í™•ë³´ë¥¼ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ê°œì„ """
        consistency_suffix = """

[ì¤‘ìš”í•œ ì§€ì¹¨]
- temperature=0ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ì¼ê´€ëœ ì‘ë‹µì„ ìƒì„±í•˜ì„¸ìš”
- ë™ì¼í•œ ì§ˆë¬¸ì—ëŠ” í•­ìƒ ë™ì¼í•œ êµ¬ì¡°ë¡œ ë‹µë³€í•˜ì„¸ìš”
- ì˜ˆì¸¡ ê°€ëŠ¥í•˜ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì‘ë‹µì„ ì œê³µí•˜ì„¸ìš”"""
        
        return base_prompt + consistency_suffix
    
    @staticmethod
    def compress_prompt(long_prompt: str, max_length: int = 1000) -> str:
        """í”„ë¡¬í”„íŠ¸ ì••ì¶• (í† í° ìˆ˜ ìµœì í™”)"""
        if len(long_prompt) <= max_length:
            return long_prompt
        
        # ì••ì¶• ì „ëµ
        compressed = long_prompt
        
        # 1. ì¤‘ë³µ ê³µë°± ì œê±°
        import re
        compressed = re.sub(r'\s+', ' ', compressed)
        
        # 2. ë¶ˆí•„ìš”í•œ êµ¬ë¬¸ ì œê±°
        unnecessary_phrases = [
            "please", "kindly", "I would like you to",
            "Could you", "Would you mind", "It would be great if"
        ]
        
        for phrase in unnecessary_phrases:
            compressed = compressed.replace(phrase, "")
        
        # 3. í•µì‹¬ ë‚´ìš©ë§Œ ìœ ì§€
        if len(compressed) > max_length:
            # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ìë¥´ê¸°
            sentences = compressed.split('. ')
            compressed = '. '.join(sentences[:max_length//50])  # ëŒ€ëµ ì¶”ì •
        
        logger.info(f"í”„ë¡¬í”„íŠ¸ ì••ì¶•: {len(long_prompt)} -> {len(compressed)} ë¬¸ì")
        return compressed.strip()
    
    @staticmethod
    def fix_response_format(prompt: str, desired_format: str) -> str:
        """ì‘ë‹µ í˜•ì‹ ì œì–´ ê°œì„ """
        format_instructions = {
            "json": "\n\nì‘ë‹µì„ ë°˜ë“œì‹œ ìœ íš¨í•œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì œê³µí•˜ì„¸ìš”. ë‹¤ë¥¸ ì„¤ëª…ì€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.",
            "markdown": "\n\nì‘ë‹µì„ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”. í—¤ë”, ë¦¬ìŠ¤íŠ¸, ì½”ë“œ ë¸”ë¡ì„ í™œìš©í•˜ì„¸ìš”.",
            "bullet_points": "\n\nì‘ë‹µì„ ë¶ˆë¦¿ í¬ì¸íŠ¸ í˜•íƒœë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”:\n- ì²« ë²ˆì§¸ ìš”ì \n- ë‘ ë²ˆì§¸ ìš”ì \n- ...",
            "numbered_list": "\n\nì‘ë‹µì„ ë²ˆí˜¸ ë§¤ê¸´ ëª©ë¡ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”:\n1. ì²« ë²ˆì§¸ í•­ëª©\n2. ë‘ ë²ˆì§¸ í•­ëª©\n...",
            "paragraph": "\n\nì‘ë‹µì„ ì˜ êµ¬ì¡°í™”ëœ ë¬¸ë‹¨ í˜•íƒœë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”. ê° ë¬¸ë‹¨ì€ í•˜ë‚˜ì˜ ì£¼ìš” ì•„ì´ë””ì–´ë¥¼ ë‹¤ë£¨ì„¸ìš”."
        }
        
        format_instruction = format_instructions.get(desired_format, "")
        return prompt + format_instruction

def create_streamlit_ui():
    """Streamlit UI ìƒì„±"""
    st.set_page_config(
        page_title="AI ì±—ë´‡ ë©˜í† ë§ - 2ì°¨ì‹œ",
        page_icon="ğŸ¯",
        layout="wide"
    )
    
    st.title("ğŸ¯ AI ì±—ë´‡ ë©˜í† ë§ - 2ì°¨ì‹œ: í”„ë¡¬í”„íŠ¸ ìµœì í™”")
    st.caption("Jinja2 í…œí”Œë¦¿, í˜ë¥´ì†Œë‚˜ ì ìš©, A/B í…ŒìŠ¤íŠ¸")
    
    # ì´ˆê¸°í™”
    if 'template_engine' not in st.session_state:
        st.session_state.template_engine = PromptTemplateEngine()
        st.session_state.persona_manager = PersonaManager()
        st.session_state.optimizer = PromptOptimizer(
            OpenAI(api_key=config.llm.openai_api_key),
            st.session_state.template_engine
        )
    
    # ì‚¬ì´ë“œë°”
    with st.sidebar:
        st.header("âš™ï¸ ì„¤ì •")
        
        # í…œí”Œë¦¿ ì„ íƒ
        template_names = list(st.session_state.template_engine.templates.keys())
        selected_template = st.selectbox("í…œí”Œë¦¿ ì„ íƒ", template_names, index=0)
        
        # í˜ë¥´ì†Œë‚˜ ì„ íƒ
        persona_names = list(st.session_state.persona_manager.personas.keys())
        selected_persona = st.selectbox("í˜ë¥´ì†Œë‚˜ ì„ íƒ", persona_names, index=0)
        
        st.divider()
        
        # í…ŒìŠ¤íŠ¸ ëª¨ë“œ
        test_mode = st.radio(
            "í…ŒìŠ¤íŠ¸ ëª¨ë“œ",
            ["ë‹¨ì¼ í…ŒìŠ¤íŠ¸", "A/B í…ŒìŠ¤íŠ¸", "í’ˆì§ˆ ë¶„ì„"]
        )
    
    # ë©”ì¸ ì½˜í…ì¸ 
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.header("ğŸ“ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿")
        
        # ì„ íƒëœ í…œí”Œë¦¿ ì •ë³´
        template = st.session_state.template_engine.get_template(selected_template)
        if template:
            st.subheader(f"ğŸ“‹ {template.name}")
            st.write(f"**ì¹´í…Œê³ ë¦¬**: {template.category}")
            st.write(f"**ì„¤ëª…**: {template.description}")
            st.write(f"**ì‘ì„±ì**: {template.author}")
            
            # í…œí”Œë¦¿ ë‚´ìš©
            st.text_area("í…œí”Œë¦¿ ë‚´ìš©", template.template, height=200, disabled=True)
            
            # í•„ìˆ˜ ë³€ìˆ˜
            st.write("**í•„ìˆ˜ ë³€ìˆ˜**:")
            for var in template.variables:
                st.write(f"- `{var}`")
    
    with col2:
        st.header("ğŸ­ í˜ë¥´ì†Œë‚˜ ì„¤ì •")
        
        # ì„ íƒëœ í˜ë¥´ì†Œë‚˜ ì •ë³´
        persona = st.session_state.persona_manager.get_persona(selected_persona)
        if persona:
            st.subheader(f"ğŸ‘¤ {persona.name}")
            st.write(f"**ì—­í• **: {persona.role}")
            st.write(f"**í†¤**: {persona.tone}")
            
            # ì „ë¬¸ë¶„ì•¼
            st.write("**ì „ë¬¸ë¶„ì•¼**:")
            for expertise in persona.expertise:
                st.write(f"- {expertise}")
            
            # ì œì•½ì‚¬í•­
            st.write("**ì œì•½ì‚¬í•­**:")
            for constraint in persona.constraints:
                st.write(f"- {constraint}")
    
    st.divider()
    
    # í…ŒìŠ¤íŠ¸ ì„¹ì…˜
    if test_mode == "ë‹¨ì¼ í…ŒìŠ¤íŠ¸":
        st.header("ğŸ§ª ë‹¨ì¼ í”„ë¡¬í”„íŠ¸ í…ŒìŠ¤íŠ¸")
        
        col1, col2 = st.columns([1, 1])
        
        with col1:
            # ë³€ìˆ˜ ì…ë ¥
            st.subheader("ë³€ìˆ˜ ì…ë ¥")
            variables = {}
            
            if template:
                for var in template.variables:
                    if var == "persona":
                        variables[var] = persona
                    elif var in ["user_question", "customer_message", "topic"]:
                        variables[var] = st.text_area(f"{var}:", height=100)
                    elif var in ["response_format", "content_type", "brand_tone"]:
                        variables[var] = st.text_input(f"{var}:")
                    elif var in ["length_limit", "max_length", "years_experience"]:
                        variables[var] = st.number_input(f"{var}:", min_value=1, value=200)
                    elif var in ["keywords", "brand_values", "expertise"]:
                        text_input = st.text_input(f"{var} (ì‰¼í‘œ êµ¬ë¶„):")
                        variables[var] = [x.strip() for x in text_input.split(',') if x.strip()]
                    else:
                        variables[var] = st.text_input(f"{var}:")
            
            if st.button("í”„ë¡¬í”„íŠ¸ ìƒì„±"):
                try:
                    rendered_prompt = st.session_state.template_engine.render_prompt(
                        selected_template, variables
                    )
                    st.session_state.generated_prompt = rendered_prompt
                except Exception as e:
                    st.error(f"í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
        
        with col2:
            # ìƒì„±ëœ í”„ë¡¬í”„íŠ¸
            st.subheader("ìƒì„±ëœ í”„ë¡¬í”„íŠ¸")
            if hasattr(st.session_state, 'generated_prompt'):
                st.text_area("", st.session_state.generated_prompt, height=300)
                
                # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
                test_input = st.text_input("í…ŒìŠ¤íŠ¸ ì…ë ¥:")
                if st.button("ì‘ë‹µ ìƒì„±"):
                    with st.spinner("AI ì‘ë‹µ ìƒì„± ì¤‘..."):
                        try:
                            client = OpenAI(api_key=config.llm.openai_api_key)
                            messages = [
                                {"role": "system", "content": st.session_state.generated_prompt},
                                {"role": "user", "content": test_input}
                            ]
                            
                            response = client.chat.completions.create(
                                model=config.llm.openai_model,
                                messages=messages,
                                max_tokens=500,
                                temperature=0.7
                            )
                            
                            st.subheader("AI ì‘ë‹µ")
                            st.write(response.choices[0].message.content)
                            
                            # ë©”íƒ€ë°ì´í„°
                            st.caption(f"í† í° ì‚¬ìš©: {response.usage.total_tokens}")
                            
                        except Exception as e:
                            st.error(f"ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")
    
    elif test_mode == "A/B í…ŒìŠ¤íŠ¸":
        st.header("âš–ï¸ A/B í…ŒìŠ¤íŠ¸")
        
        col1, col2 = st.columns([1, 1])
        
        with col1:
            st.subheader("í”„ë¡¬í”„íŠ¸ A")
            prompt_a = st.text_area("í”„ë¡¬í”„íŠ¸ A:", height=150)
        
        with col2:
            st.subheader("í”„ë¡¬í”„íŠ¸ B")
            prompt_b = st.text_area("í”„ë¡¬í”„íŠ¸ B:", height=150)
        
        # í…ŒìŠ¤íŠ¸ ì…ë ¥
        st.subheader("í…ŒìŠ¤íŠ¸ ì…ë ¥ (ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„)")
        test_inputs_text = st.text_area("", height=100)
        test_inputs = [x.strip() for x in test_inputs_text.split('\n') if x.strip()]
        
        if st.button("A/B í…ŒìŠ¤íŠ¸ ì‹¤í–‰") and prompt_a and prompt_b and test_inputs:
            with st.spinner("A/B í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘..."):
                try:
                    result = st.session_state.optimizer.run_ab_test(
                        prompt_a, prompt_b, test_inputs, "Manual A/B Test"
                    )
                    
                    # ê²°ê³¼ í‘œì‹œ
                    st.subheader("ğŸ† í…ŒìŠ¤íŠ¸ ê²°ê³¼")
                    
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("ìŠ¹ì", result["winner"])
                    with col2:
                        st.metric("ì ìˆ˜ì°¨", f"{result['score_difference']:.1f}")
                    with col3:
                        st.metric("ì´ í…ŒìŠ¤íŠ¸", result["total_tests"])
                    
                    # ìƒì„¸ ê²°ê³¼
                    results_a = result["results"]["prompt_a"]
                    results_b = result["results"]["prompt_b"]
                    
                    col1, col2 = st.columns(2)
                    with col1:
                        st.subheader("ğŸ“Š í”„ë¡¬í”„íŠ¸ A")
                        st.metric("í‰ê·  í’ˆì§ˆ ì ìˆ˜", f"{results_a['avg_quality_score']:.1f}")
                        st.metric("í‰ê·  ì²˜ë¦¬ ì‹œê°„", f"{results_a['avg_processing_time']:.2f}ì´ˆ")
                        st.metric("í‰ê·  í† í° ìˆ˜", f"{results_a['avg_tokens']:.0f}")
                    
                    with col2:
                        st.subheader("ğŸ“Š í”„ë¡¬í”„íŠ¸ B")
                        st.metric("í‰ê·  í’ˆì§ˆ ì ìˆ˜", f"{results_b['avg_quality_score']:.1f}")
                        st.metric("í‰ê·  ì²˜ë¦¬ ì‹œê°„", f"{results_b['avg_processing_time']:.2f}ì´ˆ")
                        st.metric("í‰ê·  í† í° ìˆ˜", f"{results_b['avg_tokens']:.0f}")
                    
                except Exception as e:
                    st.error(f"A/B í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
    
    elif test_mode == "í’ˆì§ˆ ë¶„ì„":
        st.header("ğŸ“ˆ í”„ë¡¬í”„íŠ¸ í’ˆì§ˆ ë¶„ì„")
        
        # ë¶„ì„í•  í”„ë¡¬í”„íŠ¸
        analysis_prompt = st.text_area("ë¶„ì„í•  í”„ë¡¬í”„íŠ¸:", height=200)
        
        # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤
        st.subheader("í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤")
        test_cases = st.text_area("í…ŒìŠ¤íŠ¸ ì…ë ¥ë“¤ (ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„):", height=100)
        test_list = [x.strip() for x in test_cases.split('\n') if x.strip()]
        
        if st.button("í’ˆì§ˆ ë¶„ì„ ì‹œì‘") and analysis_prompt and test_list:
            with st.spinner("í’ˆì§ˆ ë¶„ì„ ì¤‘..."):
                try:
                    quality_score = st.session_state.optimizer.test_prompt_quality(
                        analysis_prompt, test_list
                    )
                    
                    # ê²°ê³¼ í‘œì‹œ
                    st.subheader("ğŸ“Š í’ˆì§ˆ ë¶„ì„ ê²°ê³¼")
                    
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("ì „ì²´ í’ˆì§ˆ ì ìˆ˜", f"{quality_score:.1f}/100")
                    with col2:
                        grade = "A" if quality_score >= 80 else "B" if quality_score >= 60 else "C"
                        st.metric("ë“±ê¸‰", grade)
                    with col3:
                        st.metric("í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ìˆ˜", len(test_list))
                    
                    # ê°œì„  ì œì•ˆ
                    st.subheader("ğŸ’¡ ê°œì„  ì œì•ˆ")
                    if quality_score < 70:
                        st.warning("í’ˆì§ˆ ì ìˆ˜ê°€ ë‚®ìŠµë‹ˆë‹¤. ë‹¤ìŒì„ ê³ ë ¤í•´ë³´ì„¸ìš”:")
                        st.write("- ë” êµ¬ì²´ì ì¸ ì§€ì‹œì‚¬í•­ ì¶”ê°€")
                        st.write("- ì˜ˆì‹œ í¬í•¨")
                        st.write("- ì‘ë‹µ í˜•ì‹ ëª…ì‹œ")
                        st.write("- ì œì•½ì‚¬í•­ ëª…í™•í™”")
                    else:
                        st.success("ì¢‹ì€ í’ˆì§ˆì˜ í”„ë¡¬í”„íŠ¸ì…ë‹ˆë‹¤!")
                    
                    # ìµœì í™”ëœ ë²„ì „ ì œì•ˆ
                    st.subheader("ğŸ”§ ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸ ì œì•ˆ")
                    
                    # ì¼ê´€ì„± ê°œì„ 
                    consistent_prompt = TroubleshootingSolver.ensure_consistency(analysis_prompt)
                    st.text_area("ì¼ê´€ì„± ê°œì„  ë²„ì „:", consistent_prompt, height=200)
                    
                    # ì••ì¶• ë²„ì „
                    compressed_prompt = TroubleshootingSolver.compress_prompt(analysis_prompt)
                    st.text_area("ì••ì¶• ë²„ì „ (í† í° ìµœì í™”):", compressed_prompt, height=150)
                    
                except Exception as e:
                    st.error(f"í’ˆì§ˆ ë¶„ì„ ì‹¤íŒ¨: {e}")
    
    # í…œí”Œë¦¿ ë° í˜ë¥´ì†Œë‚˜ ê´€ë¦¬
    st.divider()
    with st.expander("ğŸ› ï¸ í…œí”Œë¦¿ & í˜ë¥´ì†Œë‚˜ ê´€ë¦¬"):
        tab1, tab2 = st.tabs(["ìƒˆ í…œí”Œë¦¿ ì¶”ê°€", "ìƒˆ í˜ë¥´ì†Œë‚˜ ì¶”ê°€"])
        
        with tab1:
            st.subheader("ìƒˆ í…œí”Œë¦¿ ì¶”ê°€")
            new_template_name = st.text_input("í…œí”Œë¦¿ ì´ë¦„:")
            new_template_category = st.text_input("ì¹´í…Œê³ ë¦¬:")
            new_template_content = st.text_area("í…œí”Œë¦¿ ë‚´ìš©:", height=200)
            new_template_vars = st.text_input("ë³€ìˆ˜ ëª©ë¡ (ì‰¼í‘œ êµ¬ë¶„):")
            new_template_desc = st.text_input("ì„¤ëª…:")
            
            if st.button("í…œí”Œë¦¿ ì¶”ê°€"):
                if all([new_template_name, new_template_category, new_template_content]):
                    variables = [v.strip() for v in new_template_vars.split(',') if v.strip()]
                    new_template = PromptTemplate(
                        name=new_template_name,
                        category=new_template_category,
                        template=new_template_content,
                        variables=variables,
                        description=new_template_desc,
                        author="User"
                    )
                    st.session_state.template_engine.add_template(new_template)
                    st.success(f"í…œí”Œë¦¿ '{new_template_name}' ì¶”ê°€ ì™„ë£Œ!")
                    st.rerun()
        
        with tab2:
            st.subheader("ìƒˆ í˜ë¥´ì†Œë‚˜ ì¶”ê°€")
            new_persona_name = st.text_input("í˜ë¥´ì†Œë‚˜ ì´ë¦„:")
            new_persona_role = st.text_input("ì—­í• :")
            new_persona_tone = st.text_input("í†¤:")
            new_persona_expertise = st.text_input("ì „ë¬¸ë¶„ì•¼ (ì‰¼í‘œ êµ¬ë¶„):")
            new_persona_constraints = st.text_input("ì œì•½ì‚¬í•­ (ì‰¼í‘œ êµ¬ë¶„):")
            
            if st.button("í˜ë¥´ì†Œë‚˜ ì¶”ê°€"):
                if all([new_persona_name, new_persona_role, new_persona_tone]):
                    expertise = [e.strip() for e in new_persona_expertise.split(',') if e.strip()]
                    constraints = [c.strip() for c in new_persona_constraints.split(',') if c.strip()]
                    
                    new_persona = PersonaConfig(
                        name=new_persona_name,
                        role=new_persona_role,
                        tone=new_persona_tone,
                        expertise=expertise,
                        constraints=constraints,
                        examples=[]
                    )
                    st.session_state.persona_manager.add_persona(new_persona)
                    st.success(f"í˜ë¥´ì†Œë‚˜ '{new_persona_name}' ì¶”ê°€ ì™„ë£Œ!")
                    st.rerun()

def run_cli_demo():
    """CLI ë°ëª¨"""
    print("=== AI ì±—ë´‡ ë©˜í† ë§ 2ì°¨ì‹œ: í”„ë¡¬í”„íŠ¸ ìµœì í™” ===")
    
    # ì´ˆê¸°í™”
    template_engine = PromptTemplateEngine()
    persona_manager = PersonaManager()
    
    print(f"ë¡œë“œëœ í…œí”Œë¦¿: {len(template_engine.templates)}ê°œ")
    print(f"ë¡œë“œëœ í˜ë¥´ì†Œë‚˜: {len(persona_manager.personas)}ê°œ")
    
    # í…œí”Œë¦¿ ëª©ë¡ í‘œì‹œ
    print("\nğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ í…œí”Œë¦¿:")
    for i, template in enumerate(template_engine.list_templates(), 1):
        print(f"{i}. {template.name} ({template.category})")
    
    # ì‚¬ìš©ì ì„ íƒ
    while True:
        try:
            choice = input("\ní…œí”Œë¦¿ ë²ˆí˜¸ë¥¼ ì„ íƒí•˜ì„¸ìš” (0: ì¢…ë£Œ): ")
            if choice == '0':
                break
            
            template_idx = int(choice) - 1
            templates_list = template_engine.list_templates()
            
            if 0 <= template_idx < len(templates_list):
                selected_template = templates_list[template_idx]
                print(f"\nì„ íƒëœ í…œí”Œë¦¿: {selected_template.name}")
                print(f"ì„¤ëª…: {selected_template.description}")
                print(f"í•„ìˆ˜ ë³€ìˆ˜: {', '.join(selected_template.variables)}")
                
                # ë³€ìˆ˜ ì…ë ¥
                variables = {}
                for var in selected_template.variables:
                    if var == "persona":
                        print("\ní˜ë¥´ì†Œë‚˜ ëª©ë¡:")
                        personas = persona_manager.list_personas()
                        for i, p in enumerate(personas):
                            print(f"{i+1}. {p.name}")
                        
                        persona_choice = int(input("í˜ë¥´ì†Œë‚˜ ì„ íƒ: ")) - 1
                        if 0 <= persona_choice < len(personas):
                            variables[var] = personas[persona_choice]
                    else:
                        value = input(f"{var}: ")
                        # íƒ€ì… ì¶”ì •
                        if var.endswith('_limit') or var.startswith('max_') or 'years' in var:
                            try:
                                variables[var] = int(value)
                            except:
                                variables[var] = value
                        elif ',' in value:
                            variables[var] = [x.strip() for x in value.split(',')]
                        else:
                            variables[var] = value
                
                # í”„ë¡¬í”„íŠ¸ ë Œë”ë§
                try:
                    rendered = template_engine.render_prompt(selected_template.name, variables)
                    print(f"\nğŸ¯ ìƒì„±ëœ í”„ë¡¬í”„íŠ¸:")
                    print("=" * 50)
                    print(rendered)
                    print("=" * 50)
                    
                    # í…ŒìŠ¤íŠ¸ ì—¬ë¶€
                    if input("\nAI ì‘ë‹µì„ í…ŒìŠ¤íŠ¸í•´ë³´ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").lower() == 'y':
                        test_input = input("í…ŒìŠ¤íŠ¸ ì…ë ¥: ")
                        
                        client = OpenAI(api_key=config.llm.openai_api_key)
                        messages = [
                            {"role": "system", "content": rendered},
                            {"role": "user", "content": test_input}
                        ]
                        
                        print("\nğŸ¤– AI ì‘ë‹µ:")
                        response = client.chat.completions.create(
                            model=config.llm.openai_model,
                            messages=messages,
                            max_tokens=500,
                            temperature=0.7
                        )
                        
                        print(response.choices[0].message.content)
                        print(f"\nì‚¬ìš©ëœ í† í°: {response.usage.total_tokens}")
                
                except Exception as e:
                    print(f"ì˜¤ë¥˜: {e}")
            else:
                print("ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤.")
        
        except (ValueError, KeyboardInterrupt):
            print("í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break

if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == "cli":
        run_cli_demo()
    else:
        create_streamlit_ui()