{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ¯ AI ì±—ë´‡ ë©˜í† ë§ - 2ì°¨ì‹œ: í”„ë¡¬í”„íŠ¸ ìµœì í™”\n",
    "\n",
    "## ğŸ¯ í•™ìŠµ ëª©í‘œ\n",
    "- Jinja2 ê¸°ë°˜ ë™ì  í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì‹œìŠ¤í…œ êµ¬ì¶•\n",
    "- í˜ë¥´ì†Œë‚˜ ë° ë¸Œëœë“œ í†¤ì•¤ë§¤ë„ˆ ì ìš©\n",
    "- A/B í…ŒìŠ¤íŠ¸ë¥¼ í†µí•œ í”„ë¡¬í”„íŠ¸ ìµœì í™”\n",
    "- í”„ë¡¬í”„íŠ¸ íŠ¸ëŸ¬ë¸”ìŠˆíŒ… ë° ì¼ê´€ì„± í™•ë³´\n",
    "- ë‹µë³€ í’ˆì§ˆ ì¸¡ì • ë° ê°œì„  ë°©ë²•\n",
    "\n",
    "## ğŸ“‹ ì‚¬ì „ ì¤€ë¹„ì‚¬í•­\n",
    "1. 1ì°¨ì‹œ ì™„ë£Œ ë° í™˜ê²½ ì„¤ì •\n",
    "2. Jinja2 í…œí”Œë¦¿ ì—”ì§„ ì´í•´\n",
    "3. OpenAI API í‚¤ ì„¤ì •\n",
    "4. í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ê¸°ë³¸ ì§€ì‹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£ í™˜ê²½ ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import logging\n",
    "from typing import Dict, List, Any, Optional, Tuple\n",
    "from datetime import datetime\n",
    "from dataclasses import dataclass, asdict\n",
    "import hashlib\n",
    "import random\n",
    "from jinja2 import Template, Environment, FileSystemLoader\n",
    "from openai import OpenAI\n",
    "\n",
    "# ë¡œì»¬ ëª¨ë“ˆ (ìƒìœ„ ë””ë ‰í† ë¦¬)\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from config import get_config\n",
    "\n",
    "# ì„¤ì • ë¡œë“œ\n",
    "config = get_config()\n",
    "\n",
    "# ë¡œê¹… ì„¤ì •\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ\")\n",
    "print(f\"ğŸ”‘ API í‚¤ ì„¤ì • ìƒíƒœ: {'âœ… ì„¤ì •ë¨' if config.llm.openai_api_key else 'âŒ ë¯¸ì„¤ì •'}\")\n",
    "print(f\"ğŸ¤– ì‚¬ìš© ëª¨ë¸: {config.llm.openai_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ ë°ì´í„° êµ¬ì¡° ì •ì˜\n",
    "\n",
    "í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ê³¼ í˜ë¥´ì†Œë‚˜ë¥¼ ì²´ê³„ì ìœ¼ë¡œ ê´€ë¦¬í•˜ê¸° ìœ„í•œ ë°ì´í„° í´ë˜ìŠ¤ë¥¼ ì •ì˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class PromptTemplate:\n",
    "    \"\"\"í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ êµ¬ì¡°\"\"\"\n",
    "    name: str\n",
    "    category: str\n",
    "    template: str\n",
    "    variables: List[str]\n",
    "    description: str\n",
    "    author: str\n",
    "    version: str = \"1.0\"\n",
    "    created_at: datetime = None\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        if self.created_at is None:\n",
    "            self.created_at = datetime.now()\n",
    "\n",
    "@dataclass\n",
    "class PersonaConfig:\n",
    "    \"\"\"í˜ë¥´ì†Œë‚˜ ì„¤ì •\"\"\"\n",
    "    name: str\n",
    "    role: str\n",
    "    tone: str\n",
    "    expertise: List[str]\n",
    "    constraints: List[str]\n",
    "    examples: List[Dict[str, str]]\n",
    "    brand_guidelines: Optional[Dict[str, Any]] = None\n",
    "\n",
    "@dataclass\n",
    "class PromptTestResult:\n",
    "    \"\"\"í”„ë¡¬í”„íŠ¸ í…ŒìŠ¤íŠ¸ ê²°ê³¼\"\"\"\n",
    "    template_name: str\n",
    "    test_input: Dict[str, Any]\n",
    "    generated_prompt: str\n",
    "    response: str\n",
    "    tokens_used: int\n",
    "    processing_time: float\n",
    "    quality_score: float\n",
    "    timestamp: datetime\n",
    "\n",
    "print(\"âœ… ë°ì´í„° êµ¬ì¡° ì •ì˜ ì™„ë£Œ\")\n",
    "print(\"ğŸ“‹ ì •ì˜ëœ í´ë˜ìŠ¤:\")\n",
    "print(\"  - PromptTemplate: í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ê´€ë¦¬\")\n",
    "print(\"  - PersonaConfig: í˜ë¥´ì†Œë‚˜ ì„¤ì •\")\n",
    "print(\"  - PromptTestResult: í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ Jinja2 í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì—”ì§„ êµ¬í˜„\n",
    "\n",
    "ë™ì ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ìˆëŠ” í…œí”Œë¦¿ ì—”ì§„ì„ êµ¬í˜„í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PromptTemplateEngine:\n",
    "    \"\"\"Jinja2 ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì—”ì§„\"\"\"\n",
    "    \n",
    "    def __init__(self, template_dir: str = \"templates\"):\n",
    "        self.template_dir = template_dir\n",
    "        self.env = Environment(\n",
    "            loader=FileSystemLoader(template_dir) if os.path.exists(template_dir) else None,\n",
    "            trim_blocks=True,\n",
    "            lstrip_blocks=True\n",
    "        )\n",
    "        self.templates: Dict[str, PromptTemplate] = {}\n",
    "        self._load_default_templates()\n",
    "        logger.info(f\"í”„ë¡¬í”„íŠ¸ ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ - í…œí”Œë¦¿ ìˆ˜: {len(self.templates)}\")\n",
    "    \n",
    "    def _load_default_templates(self):\n",
    "        \"\"\"ê¸°ë³¸ í…œí”Œë¦¿ ë¡œë“œ\"\"\"\n",
    "        # ì¼ë°˜ ì–´ì‹œìŠ¤í„´íŠ¸ í…œí”Œë¦¿\n",
    "        general_template = PromptTemplate(\n",
    "            name=\"general_assistant\",\n",
    "            category=\"ê¸°ë³¸\",\n",
    "            template=\"\"\"ë‹¹ì‹ ì€ {{persona.role}}ì…ë‹ˆë‹¤. {{persona.tone}} í†¤ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "ì „ë¬¸ë¶„ì•¼: {{persona.expertise|join(', ')}}\n",
    "\n",
    "ì œì•½ì‚¬í•­:\n",
    "{% for constraint in persona.constraints %}\n",
    "- {{constraint}}\n",
    "{% endfor %}\n",
    "\n",
    "ì‚¬ìš©ì ì§ˆë¬¸: {{user_question}}\n",
    "\n",
    "ë‹µë³€ í˜•ì‹: {{response_format}}\n",
    "ë‹µë³€ ê¸¸ì´: {{length_limit}}ì ì´ë‚´\"\"\",\n",
    "            variables=[\"persona\", \"user_question\", \"response_format\", \"length_limit\"],\n",
    "            description=\"ì¼ë°˜ì ì¸ ì–´ì‹œìŠ¤í„´íŠ¸ ì—­í• ì„ ìœ„í•œ ê¸°ë³¸ í…œí”Œë¦¿\",\n",
    "            author=\"AI Workshop\"\n",
    "        )\n",
    "        \n",
    "        # ì½”ë“œ ë¦¬ë·° í…œí”Œë¦¿\n",
    "        code_review_template = PromptTemplate(\n",
    "            name=\"code_reviewer\",\n",
    "            category=\"ê°œë°œ\",\n",
    "            template=\"\"\"ë‹¹ì‹ ì€ {{years_experience}}ë…„ ê²½ë ¥ì˜ {{programming_language}} ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
    "\n",
    "ë‹¤ìŒ ì½”ë“œë¥¼ ë¦¬ë·°í•´ì£¼ì„¸ìš”:\n",
    "\n",
    "```{{programming_language}}\n",
    "{{code_snippet}}\n",
    "```\n",
    "\n",
    "ë¦¬ë·° ê´€ì :\n",
    "{% for aspect in review_aspects %}\n",
    "- {{aspect}}\n",
    "{% endfor %}\n",
    "\n",
    "ì¶œë ¥ í˜•ì‹:\n",
    "1. ì½”ë“œ í’ˆì§ˆ ì ìˆ˜ (1-10)\n",
    "2. ì£¼ìš” ê°œì„ ì‚¬í•­\n",
    "3. ë³´ì•ˆ ì´ìŠˆ\n",
    "4. ì„±ëŠ¥ ìµœì í™” ì œì•ˆ\n",
    "5. ê°œì„ ëœ ì½”ë“œ ì˜ˆì‹œ\"\"\",\n",
    "            variables=[\"years_experience\", \"programming_language\", \"code_snippet\", \"review_aspects\"],\n",
    "            description=\"ì½”ë“œ ë¦¬ë·°ë¥¼ ìœ„í•œ ì „ë¬¸ í…œí”Œë¦¿\",\n",
    "            author=\"AI Workshop\"\n",
    "        )\n",
    "        \n",
    "        # ê³ ê°ì§€ì› í…œí”Œë¦¿\n",
    "        customer_support_template = PromptTemplate(\n",
    "            name=\"customer_support\",\n",
    "            category=\"ê³ ê°ì§€ì›\",\n",
    "            template=\"\"\"ì•ˆë…•í•˜ì„¸ìš”! {{company_name}} ê³ ê°ì§€ì›íŒ€ì˜ {{agent_name}}ì…ë‹ˆë‹¤.\n",
    "\n",
    "ë¸Œëœë“œ ê°€ì´ë“œë¼ì¸:\n",
    "- í†¤: {{brand_tone}}\n",
    "- í•µì‹¬ê°€ì¹˜: {{brand_values|join(', ')}}\n",
    "- ê¸ˆì§€ì–´: {{forbidden_words|join(', ')}}\n",
    "\n",
    "ê³ ê° ë¬¸ì˜:\n",
    "ë¶„ë¥˜: {{inquiry_category}}\n",
    "ë‚´ìš©: {{customer_message}}\n",
    "ìš°ì„ ìˆœìœ„: {{priority_level}}\n",
    "\n",
    "ì‘ë‹µ ê°€ì´ë“œë¼ì¸:\n",
    "1. ê³µê°ì  ì¸ì‚¬\n",
    "2. ë¬¸ì œ íŒŒì•… í™•ì¸\n",
    "3. êµ¬ì²´ì  í•´ê²°ë°©ì•ˆ ì œì‹œ\n",
    "4. ì¶”ê°€ ë„ì›€ ì œì•ˆ\n",
    "\n",
    "ìµœëŒ€ {{max_length}}ìë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.\"\"\",\n",
    "            variables=[\"company_name\", \"agent_name\", \"brand_tone\", \"brand_values\", \n",
    "                      \"forbidden_words\", \"inquiry_category\", \"customer_message\", \n",
    "                      \"priority_level\", \"max_length\"],\n",
    "            description=\"ê³ ê°ì§€ì›ì„ ìœ„í•œ ë¸Œëœë“œ ê°€ì´ë“œë¼ì¸ ì ìš© í…œí”Œë¦¿\",\n",
    "            author=\"AI Workshop\"\n",
    "        )\n",
    "        \n",
    "        self.templates[\"general_assistant\"] = general_template\n",
    "        self.templates[\"code_reviewer\"] = code_review_template\n",
    "        self.templates[\"customer_support\"] = customer_support_template\n",
    "    \n",
    "    def add_template(self, template: PromptTemplate):\n",
    "        \"\"\"ìƒˆ í…œí”Œë¦¿ ì¶”ê°€\"\"\"\n",
    "        self.templates[template.name] = template\n",
    "        logger.info(f\"í…œí”Œë¦¿ ì¶”ê°€: {template.name}\")\n",
    "    \n",
    "    def get_template(self, name: str) -> Optional[PromptTemplate]:\n",
    "        \"\"\"í…œí”Œë¦¿ ì¡°íšŒ\"\"\"\n",
    "        return self.templates.get(name)\n",
    "    \n",
    "    def list_templates(self, category: Optional[str] = None) -> List[PromptTemplate]:\n",
    "        \"\"\"í…œí”Œë¦¿ ëª©ë¡ ì¡°íšŒ\"\"\"\n",
    "        if category:\n",
    "            return [t for t in self.templates.values() if t.category == category]\n",
    "        return list(self.templates.values())\n",
    "    \n",
    "    def render_prompt(self, template_name: str, variables: Dict[str, Any]) -> str:\n",
    "        \"\"\"í”„ë¡¬í”„íŠ¸ ë Œë”ë§\"\"\"\n",
    "        template_obj = self.get_template(template_name)\n",
    "        if not template_obj:\n",
    "            raise ValueError(f\"í…œí”Œë¦¿ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {template_name}\")\n",
    "        \n",
    "        try:\n",
    "            jinja_template = Template(template_obj.template)\n",
    "            rendered = jinja_template.render(**variables)\n",
    "            logger.debug(f\"í”„ë¡¬í”„íŠ¸ ë Œë”ë§ ì™„ë£Œ - í…œí”Œë¦¿: {template_name}\")\n",
    "            return rendered\n",
    "        except Exception as e:\n",
    "            logger.error(f\"í”„ë¡¬í”„íŠ¸ ë Œë”ë§ ì‹¤íŒ¨: {e}\")\n",
    "            raise\n",
    "\n",
    "# í…œí”Œë¦¿ ì—”ì§„ ìƒì„± ë° í…ŒìŠ¤íŠ¸\n",
    "template_engine = PromptTemplateEngine()\n",
    "\n",
    "print(f\"âœ… í…œí”Œë¦¿ ì—”ì§„ ìƒì„± ì™„ë£Œ\")\n",
    "print(f\"ğŸ“ ë¡œë“œëœ í…œí”Œë¦¿: {len(template_engine.templates)}ê°œ\")\n",
    "\n",
    "for template_name, template in template_engine.templates.items():\n",
    "    print(f\"  - {template_name} ({template.category}): {template.description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4ï¸âƒ£ í˜ë¥´ì†Œë‚˜ ê´€ë¦¬ ì‹œìŠ¤í…œ\n",
    "\n",
    "ë‹¤ì–‘í•œ í˜ë¥´ì†Œë‚˜ë¥¼ ì •ì˜í•˜ê³  ê´€ë¦¬í•˜ëŠ” ì‹œìŠ¤í…œì„ êµ¬ì¶•í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PersonaManager:\n",
    "    \"\"\"í˜ë¥´ì†Œë‚˜ ê´€ë¦¬ì\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.personas: Dict[str, PersonaConfig] = {}\n",
    "        self._load_default_personas()\n",
    "        logger.info(f\"í˜ë¥´ì†Œë‚˜ ê´€ë¦¬ì ì´ˆê¸°í™” - í˜ë¥´ì†Œë‚˜ ìˆ˜: {len(self.personas)}\")\n",
    "    \n",
    "    def _load_default_personas(self):\n",
    "        \"\"\"ê¸°ë³¸ í˜ë¥´ì†Œë‚˜ ë¡œë“œ\"\"\"\n",
    "        \n",
    "        # ì¹œê·¼í•œ ì–´ì‹œìŠ¤í„´íŠ¸\n",
    "        friendly_assistant = PersonaConfig(\n",
    "            name=\"friendly_assistant\",\n",
    "            role=\"ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸\",\n",
    "            tone=\"ì¹œê·¼í•˜ê³  ë”°ëœ»í•œ\",\n",
    "            expertise=[\"ì¼ë°˜ ìƒì‹\", \"ë¬¸ì œ í•´ê²°\", \"ì •ë³´ ì œê³µ\"],\n",
    "            constraints=[\n",
    "                \"í•­ìƒ ì •ì¤‘í•˜ê³  ì˜ˆì˜ë°”ë¥´ê²Œ ëŒ€ë‹µ\",\n",
    "                \"í™•ì‹¤í•˜ì§€ ì•Šì€ ì •ë³´ëŠ” ì¶”ì¸¡í•˜ì§€ ì•ŠìŒ\",\n",
    "                \"ê°œì¸ì •ë³´ëŠ” ì ˆëŒ€ ìš”ì²­í•˜ì§€ ì•ŠìŒ\"\n",
    "            ],\n",
    "            examples=[\n",
    "                {\n",
    "                    \"input\": \"ì•ˆë…•í•˜ì„¸ìš”\",\n",
    "                    \"output\": \"ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”? ê¶ê¸ˆí•œ ê²ƒì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ë§ì”€í•´ì£¼ì„¸ìš”.\"\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # ê¸°ìˆ  ì „ë¬¸ê°€\n",
    "        technical_expert = PersonaConfig(\n",
    "            name=\"technical_expert\",\n",
    "            role=\"10ë…„ ê²½ë ¥ì˜ ì†Œí”„íŠ¸ì›¨ì–´ ì—”ì§€ë‹ˆì–´\",\n",
    "            tone=\"ì „ë¬¸ì ì´ë©´ì„œë„ ì´í•´í•˜ê¸° ì‰¬ìš´\",\n",
    "            expertise=[\"Python\", \"ì›¹ê°œë°œ\", \"AI/ML\", \"ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜\", \"ë°ì´í„°ë² ì´ìŠ¤\"],\n",
    "            constraints=[\n",
    "                \"ì •í™•í•œ ê¸°ìˆ  ì •ë³´ë§Œ ì œê³µ\",\n",
    "                \"ì˜ˆì‹œ ì½”ë“œëŠ” ì‹¤í–‰ ê°€ëŠ¥í•´ì•¼ í•¨\",\n",
    "                \"ìµœì‹  ê¸°ìˆ  ë™í–¥ ë°˜ì˜\",\n",
    "                \"ì´ˆë³´ìë„ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì„¤ëª…\"\n",
    "            ],\n",
    "            examples=[\n",
    "                {\n",
    "                    \"input\": \"Pythonìœ¼ë¡œ APIë¥¼ ì–´ë–»ê²Œ ë§Œë“¤ì–´ìš”?\",\n",
    "                    \"output\": \"FastAPIë‚˜ Flaskë¥¼ ì‚¬ìš©í•˜ë©´ ì‰½ê²Œ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ FastAPIë¡œ ê°„ë‹¨í•œ APIë¥¼ ë§Œë“¤ì–´ë³´ê² ìŠµë‹ˆë‹¤...\"\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # ë¸Œëœë“œ ì•°ë°°ì„œë”\n",
    "        brand_ambassador = PersonaConfig(\n",
    "            name=\"brand_ambassador\",\n",
    "            role=\"ê¸°ì—… ë¸Œëœë“œ ëŒ€ë³€ì¸\",\n",
    "            tone=\"ì „ë¬¸ì ì´ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ”\",\n",
    "            expertise=[\"ë¸Œëœë“œ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜\", \"ê³ ê° ì„œë¹„ìŠ¤\", \"ë§ˆì¼€íŒ…\"],\n",
    "            constraints=[\n",
    "                \"ë¸Œëœë“œ ê°€ì¹˜ì™€ ì¼ì¹˜í•˜ëŠ” ë©”ì‹œì§€\",\n",
    "                \"ê²½ìŸì‚¬ ì–¸ê¸‰ ê¸ˆì§€\",\n",
    "                \"ë¶€ì •ì  í‘œí˜„ ìµœì†Œí™”\",\n",
    "                \"í•­ìƒ ì†”ë£¨ì…˜ ì¤‘ì‹¬ì  ì ‘ê·¼\"\n",
    "            ],\n",
    "            examples=[\n",
    "                {\n",
    "                    \"input\": \"ì œí’ˆì— ë¬¸ì œê°€ ìˆì–´ìš”\",\n",
    "                    \"output\": \"ë¶ˆí¸ì„ ë¼ì³ë“œë ¤ ì£„ì†¡í•©ë‹ˆë‹¤. ë¹ ë¥¸ í•´ê²°ì„ ìœ„í•´ êµ¬ì²´ì ì¸ ìƒí™©ì„ ì•Œë ¤ì£¼ì‹œê² ì–´ìš”? ìµœì„ ì„ ë‹¤í•´ ë„ì›€ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\"\n",
    "                }\n",
    "            ],\n",
    "            brand_guidelines={\n",
    "                \"tone\": \"professional_friendly\",\n",
    "                \"values\": [\"ê³ ê°ì¤‘ì‹¬\", \"í˜ì‹ \", \"ì‹ ë¢°\", \"í’ˆì§ˆ\"],\n",
    "                \"forbidden_words\": [\"ë¬¸ì œ\", \"ë¶ˆê°€ëŠ¥\", \"ì•ˆë¨\", \"ëª¨ë¦„\"],\n",
    "                \"preferred_words\": [\"í•´ê²°\", \"ê°€ëŠ¥\", \"ë„ì›€\", \"ì§€ì›\"]\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        self.personas[\"friendly_assistant\"] = friendly_assistant\n",
    "        self.personas[\"technical_expert\"] = technical_expert\n",
    "        self.personas[\"brand_ambassador\"] = brand_ambassador\n",
    "    \n",
    "    def add_persona(self, persona: PersonaConfig):\n",
    "        \"\"\"ìƒˆ í˜ë¥´ì†Œë‚˜ ì¶”ê°€\"\"\"\n",
    "        self.personas[persona.name] = persona\n",
    "        logger.info(f\"í˜ë¥´ì†Œë‚˜ ì¶”ê°€: {persona.name}\")\n",
    "    \n",
    "    def get_persona(self, name: str) -> Optional[PersonaConfig]:\n",
    "        \"\"\"í˜ë¥´ì†Œë‚˜ ì¡°íšŒ\"\"\"\n",
    "        return self.personas.get(name)\n",
    "    \n",
    "    def list_personas(self) -> List[PersonaConfig]:\n",
    "        \"\"\"í˜ë¥´ì†Œë‚˜ ëª©ë¡\"\"\"\n",
    "        return list(self.personas.values())\n",
    "\n",
    "# í˜ë¥´ì†Œë‚˜ ë§¤ë‹ˆì € ìƒì„± ë° í…ŒìŠ¤íŠ¸\n",
    "persona_manager = PersonaManager()\n",
    "\n",
    "print(f\"âœ… í˜ë¥´ì†Œë‚˜ ê´€ë¦¬ì ìƒì„± ì™„ë£Œ\")\n",
    "print(f\"ğŸ‘¥ ë¡œë“œëœ í˜ë¥´ì†Œë‚˜: {len(persona_manager.personas)}ê°œ\")\n",
    "\n",
    "for persona_name, persona in persona_manager.personas.items():\n",
    "    print(f\"  - {persona.name}: {persona.role} ({persona.tone})\")\n",
    "    print(f\"    ì „ë¬¸ë¶„ì•¼: {', '.join(persona.expertise[:3])}{'...' if len(persona.expertise) > 3 else ''}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5ï¸âƒ£ í”„ë¡¬í”„íŠ¸ ë Œë”ë§ í…ŒìŠ¤íŠ¸\n",
    "\n",
    "ì‹¤ì œë¡œ í…œí”Œë¦¿ê³¼ í˜ë¥´ì†Œë‚˜ë¥¼ ê²°í•©í•˜ì—¬ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•´ë´…ì‹œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì¼ë°˜ ì–´ì‹œìŠ¤í„´íŠ¸ í…œí”Œë¦¿ í…ŒìŠ¤íŠ¸\n",
    "print(\"ğŸ§ª ì¼ë°˜ ì–´ì‹œìŠ¤í„´íŠ¸ í…œí”Œë¦¿ í…ŒìŠ¤íŠ¸\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# ë³€ìˆ˜ ì„¤ì •\n",
    "persona = persona_manager.get_persona(\"friendly_assistant\")\n",
    "variables = {\n",
    "    \"persona\": persona,\n",
    "    \"user_question\": \"íŒŒì´ì¬ìœ¼ë¡œ ì›¹ í¬ë¡¤ë§ì„ ì–´ë–»ê²Œ ì‹œì‘í•˜ë©´ ì¢‹ì„ê¹Œìš”?\",\n",
    "    \"response_format\": \"ë‹¨ê³„ë³„ ê°€ì´ë“œ\",\n",
    "    \"length_limit\": 300\n",
    "}\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ ë Œë”ë§\n",
    "try:\n",
    "    rendered_prompt = template_engine.render_prompt(\"general_assistant\", variables)\n",
    "    print(\"ğŸ“ ìƒì„±ëœ í”„ë¡¬í”„íŠ¸:\")\n",
    "    print(\"-\" * 30)\n",
    "    print(rendered_prompt)\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"ğŸ“Š í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(rendered_prompt)} ë¬¸ì\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ ë Œë”ë§ ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì½”ë“œ ë¦¬ë·° í…œí”Œë¦¿ í…ŒìŠ¤íŠ¸\n",
    "print(\"ğŸ§ª ì½”ë“œ ë¦¬ë·° í…œí”Œë¦¿ í…ŒìŠ¤íŠ¸\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# ë³€ìˆ˜ ì„¤ì •\n",
    "code_variables = {\n",
    "    \"years_experience\": 10,\n",
    "    \"programming_language\": \"Python\",\n",
    "    \"code_snippet\": \"\"\"def fibonacci(n):\n",
    "    if n <= 1:\n",
    "        return n\n",
    "    return fibonacci(n-1) + fibonacci(n-2)\n",
    "\n",
    "result = fibonacci(35)\n",
    "print(result)\"\"\",\n",
    "    \"review_aspects\": [\"ì„±ëŠ¥\", \"ê°€ë…ì„±\", \"ë©”ëª¨ë¦¬ ì‚¬ìš©\", \"ì•Œê³ ë¦¬ì¦˜ íš¨ìœ¨ì„±\"]\n",
    "}\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ ë Œë”ë§\n",
    "try:\n",
    "    code_prompt = template_engine.render_prompt(\"code_reviewer\", code_variables)\n",
    "    print(\"ğŸ“ ìƒì„±ëœ ì½”ë“œ ë¦¬ë·° í”„ë¡¬í”„íŠ¸:\")\n",
    "    print(\"-\" * 30)\n",
    "    print(code_prompt)\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"ğŸ“Š í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(code_prompt)} ë¬¸ì\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ ë Œë”ë§ ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6ï¸âƒ£ AI ì‘ë‹µ ìƒì„± ë° ë¹„êµ\n",
    "\n",
    "ìƒì„±ëœ í”„ë¡¬í”„íŠ¸ë¡œ ì‹¤ì œ AI ì‘ë‹µì„ ìƒì„±í•˜ê³  í’ˆì§ˆì„ ë¹„êµí•´ë´…ì‹œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”\n",
    "if config.llm.openai_api_key:\n",
    "    client = OpenAI(api_key=config.llm.openai_api_key)\n",
    "    print(\"âœ… OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ\")\n",
    "else:\n",
    "    print(\"âŒ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "    client = None\n",
    "\n",
    "def generate_ai_response(prompt: str, user_input: str, model: str = None) -> Dict[str, Any]:\n",
    "    \"\"\"AI ì‘ë‹µ ìƒì„± í—¬í¼ í•¨ìˆ˜\"\"\"\n",
    "    if not client:\n",
    "        return {\"error\": \"OpenAI í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\"}\n",
    "    \n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=model or config.llm.openai_model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": prompt},\n",
    "                {\"role\": \"user\", \"content\": user_input}\n",
    "            ],\n",
    "            max_tokens=500,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        \n",
    "        processing_time = time.time() - start_time\n",
    "        \n",
    "        return {\n",
    "            \"response\": response.choices[0].message.content,\n",
    "            \"tokens_used\": response.usage.total_tokens,\n",
    "            \"processing_time\": processing_time,\n",
    "            \"model\": model or config.llm.openai_model\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "# ì¼ë°˜ ì–´ì‹œìŠ¤í„´íŠ¸ í”„ë¡¬í”„íŠ¸ë¡œ ì‘ë‹µ ìƒì„±\n",
    "if client:\n",
    "    print(\"ğŸ¤– ì¼ë°˜ ì–´ì‹œìŠ¤í„´íŠ¸ í”„ë¡¬í”„íŠ¸ ì‘ë‹µ ìƒì„±\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    user_question = \"íŒŒì´ì¬ìœ¼ë¡œ ì›¹ í¬ë¡¤ë§ì„ ì–´ë–»ê²Œ ì‹œì‘í•˜ë©´ ì¢‹ì„ê¹Œìš”?\"\n",
    "    result = generate_ai_response(rendered_prompt, user_question)\n",
    "    \n",
    "    if \"error\" not in result:\n",
    "        print(f\"ğŸ‘¤ ì‚¬ìš©ì: {user_question}\")\n",
    "        print(f\"\\nğŸ¤– AI ì‘ë‹µ:\")\n",
    "        print(result[\"response\"])\n",
    "        print(f\"\\nğŸ“Š ë©”íƒ€ë°ì´í„°:\")\n",
    "        print(f\"  - í† í° ì‚¬ìš©: {result['tokens_used']}\")\n",
    "        print(f\"  - ì²˜ë¦¬ ì‹œê°„: {result['processing_time']:.2f}ì´ˆ\")\n",
    "        print(f\"  - ëª¨ë¸: {result['model']}\")\n",
    "    else:\n",
    "        print(f\"âŒ ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {result['error']}\")\n",
    "else:\n",
    "    print(\"âš ï¸ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ ì‘ë‹µ ìƒì„±ì„ ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7ï¸âƒ£ í”„ë¡¬í”„íŠ¸ ìµœì í™” ë° A/B í…ŒìŠ¤íŠ¸ ì‹œìŠ¤í…œ\n",
    "\n",
    "í”„ë¡¬í”„íŠ¸ì˜ í’ˆì§ˆì„ ì¸¡ì •í•˜ê³  A/B í…ŒìŠ¤íŠ¸ë¥¼ í†µí•´ ìµœì í™”í•˜ëŠ” ì‹œìŠ¤í…œì„ êµ¬í˜„í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PromptOptimizer:\n",
    "    \"\"\"í”„ë¡¬í”„íŠ¸ ìµœì í™” ë° A/B í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    \n",
    "    def __init__(self, openai_client: OpenAI):\n",
    "        self.client = openai_client\n",
    "        self.test_results: List[PromptTestResult] = []\n",
    "        logger.info(\"í”„ë¡¬í”„íŠ¸ ìµœì í™” ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ\")\n",
    "    \n",
    "    def calculate_quality_score(self, input_text: str, output_text: str, prompt: str) -> float:\n",
    "        \"\"\"í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° (íœ´ë¦¬ìŠ¤í‹±)\"\"\"\n",
    "        score = 50  # ê¸°ë³¸ ì ìˆ˜\n",
    "        \n",
    "        # 1. ê¸¸ì´ ì ì ˆì„± (ë„ˆë¬´ ì§§ê±°ë‚˜ ê¸¸ì§€ ì•ŠìŒ)\n",
    "        if 50 <= len(output_text) <= 500:\n",
    "            score += 20\n",
    "        elif len(output_text) < 20:\n",
    "            score -= 10\n",
    "        \n",
    "        # 2. ê´€ë ¨ì„± (ì…ë ¥ê³¼ ì¶œë ¥ì˜ í‚¤ì›Œë“œ ë§¤ì¹­)\n",
    "        input_words = set(input_text.lower().split())\n",
    "        output_words = set(output_text.lower().split())\n",
    "        if input_words:\n",
    "            relevance = len(input_words & output_words) / len(input_words)\n",
    "            score += relevance * 15\n",
    "        \n",
    "        # 3. êµ¬ì¡°í™” ì •ë„ (ë¬¸ì¥ êµ¬ì¡°, ë¦¬ìŠ¤íŠ¸ ë“±)\n",
    "        structure_indicators = ['. ', '\\n', ':', '-', '1.', '2.', 'â€¢']\n",
    "        structure_score = sum(1 for indicator in structure_indicators if indicator in output_text)\n",
    "        score += min(structure_score * 2, 10)\n",
    "        \n",
    "        # 4. ì „ë¬¸ì„± (ì „ë¬¸ ìš©ì–´ ì‚¬ìš©)\n",
    "        technical_terms = ['ì•Œê³ ë¦¬ì¦˜', 'í•¨ìˆ˜', 'í´ë˜ìŠ¤', 'ëª¨ë“ˆ', 'ë¼ì´ë¸ŒëŸ¬ë¦¬', 'API', 'ë°ì´í„°ë² ì´ìŠ¤']\n",
    "        tech_score = sum(1 for term in technical_terms if term in output_text)\n",
    "        score += min(tech_score * 1.5, 5)\n",
    "        \n",
    "        return min(100, max(0, score))\n",
    "    \n",
    "    def test_prompt_quality(self, prompt: str, test_inputs: List[str]) -> float:\n",
    "        \"\"\"í”„ë¡¬í”„íŠ¸ í’ˆì§ˆ í‰ê°€\"\"\"\n",
    "        if not self.client:\n",
    "            return 0\n",
    "        \n",
    "        scores = []\n",
    "        \n",
    "        for test_input in test_inputs:\n",
    "            try:\n",
    "                result = generate_ai_response(prompt, test_input)\n",
    "                if \"error\" not in result:\n",
    "                    score = self.calculate_quality_score(\n",
    "                        test_input, result[\"response\"], prompt\n",
    "                    )\n",
    "                    scores.append(score)\n",
    "            except Exception as e:\n",
    "                logger.error(f\"í’ˆì§ˆ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}\")\n",
    "                scores.append(0)\n",
    "        \n",
    "        avg_score = sum(scores) / len(scores) if scores else 0\n",
    "        logger.info(f\"í‰ê·  í’ˆì§ˆ ì ìˆ˜: {avg_score:.1f}\")\n",
    "        return avg_score\n",
    "    \n",
    "    def run_ab_test(self, prompt_a: str, prompt_b: str, \n",
    "                   test_inputs: List[str], test_name: str = \"A/B Test\") -> Dict[str, Any]:\n",
    "        \"\"\"A/B í…ŒìŠ¤íŠ¸ ì‹¤í–‰\"\"\"\n",
    "        if not self.client:\n",
    "            return {\"error\": \"OpenAI í´ë¼ì´ì–¸íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.\"}\n",
    "        \n",
    "        print(f\"ğŸ”¬ A/B í…ŒìŠ¤íŠ¸ ì‹œì‘: {test_name}\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        results_a = []\n",
    "        results_b = []\n",
    "        \n",
    "        for i, test_input in enumerate(test_inputs):\n",
    "            print(f\"  í…ŒìŠ¤íŠ¸ {i+1}/{len(test_inputs)} ì§„í–‰ì¤‘...\")\n",
    "            \n",
    "            # í”„ë¡¬í”„íŠ¸ A í…ŒìŠ¤íŠ¸\n",
    "            result_a = generate_ai_response(prompt_a, test_input)\n",
    "            if \"error\" not in result_a:\n",
    "                quality_a = self.calculate_quality_score(\n",
    "                    test_input, result_a[\"response\"], prompt_a\n",
    "                )\n",
    "                result_a[\"quality_score\"] = quality_a\n",
    "                results_a.append(result_a)\n",
    "            \n",
    "            # í”„ë¡¬í”„íŠ¸ B í…ŒìŠ¤íŠ¸\n",
    "            result_b = generate_ai_response(prompt_b, test_input)\n",
    "            if \"error\" not in result_b:\n",
    "                quality_b = self.calculate_quality_score(\n",
    "                    test_input, result_b[\"response\"], prompt_b\n",
    "                )\n",
    "                result_b[\"quality_score\"] = quality_b\n",
    "                results_b.append(result_b)\n",
    "        \n",
    "        # ê²°ê³¼ ë¶„ì„\n",
    "        if results_a and results_b:\n",
    "            avg_score_a = sum(r[\"quality_score\"] for r in results_a) / len(results_a)\n",
    "            avg_score_b = sum(r[\"quality_score\"] for r in results_b) / len(results_b)\n",
    "            avg_time_a = sum(r[\"processing_time\"] for r in results_a) / len(results_a)\n",
    "            avg_time_b = sum(r[\"processing_time\"] for r in results_b) / len(results_b)\n",
    "            avg_tokens_a = sum(r[\"tokens_used\"] for r in results_a) / len(results_a)\n",
    "            avg_tokens_b = sum(r[\"tokens_used\"] for r in results_b) / len(results_b)\n",
    "        else:\n",
    "            return {\"error\": \"í…ŒìŠ¤íŠ¸ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\"}\n",
    "        \n",
    "        total_time = time.time() - start_time\n",
    "        winner = \"A\" if avg_score_a > avg_score_b else \"B\"\n",
    "        score_diff = abs(avg_score_a - avg_score_b)\n",
    "        \n",
    "        result = {\n",
    "            \"test_name\": test_name,\n",
    "            \"winner\": winner,\n",
    "            \"score_difference\": score_diff,\n",
    "            \"results\": {\n",
    "                \"prompt_a\": {\n",
    "                    \"avg_quality_score\": avg_score_a,\n",
    "                    \"avg_processing_time\": avg_time_a,\n",
    "                    \"avg_tokens\": avg_tokens_a,\n",
    "                    \"results_count\": len(results_a)\n",
    "                },\n",
    "                \"prompt_b\": {\n",
    "                    \"avg_quality_score\": avg_score_b,\n",
    "                    \"avg_processing_time\": avg_time_b,\n",
    "                    \"avg_tokens\": avg_tokens_b,\n",
    "                    \"results_count\": len(results_b)\n",
    "                }\n",
    "            },\n",
    "            \"test_duration\": total_time,\n",
    "            \"total_tests\": len(test_inputs) * 2,\n",
    "            \"timestamp\": datetime.now()\n",
    "        }\n",
    "        \n",
    "        print(f\"âœ… A/B í…ŒìŠ¤íŠ¸ ì™„ë£Œ - ìŠ¹ì: {winner}, ì ìˆ˜ì°¨: {score_diff:.1f}\")\n",
    "        return result\n",
    "\n",
    "# ìµœì í™” ì—”ì§„ ìƒì„±\n",
    "if client:\n",
    "    optimizer = PromptOptimizer(client)\n",
    "    print(\"âœ… í”„ë¡¬í”„íŠ¸ ìµœì í™” ì—”ì§„ ìƒì„± ì™„ë£Œ\")\nelse:\n",
    "    optimizer = None\n",
    "    print(\"âš ï¸ API í‚¤ê°€ ì—†ì–´ ìµœì í™” ì—”ì§„ì„ ê±´ë„ˆëœë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8ï¸âƒ£ A/B í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "\n",
    "ë‘ ê°€ì§€ ë‹¤ë¥¸ í”„ë¡¬í”„íŠ¸ ìŠ¤íƒ€ì¼ì„ ë¹„êµí•˜ëŠ” A/B í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•´ë´…ì‹œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if optimizer:\n",
    "    print(\"âš–ï¸ A/B í…ŒìŠ¤íŠ¸ ì‹¤í–‰\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # í…ŒìŠ¤íŠ¸í•  ë‘ í”„ë¡¬í”„íŠ¸ ì •ì˜\n",
    "    prompt_a = \"\"\"ë‹¹ì‹ ì€ ì¹œê·¼í•œ íŒŒì´ì¬ íŠœí„°ì…ë‹ˆë‹¤. ì´ˆë³´ìë„ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì‰½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.\n",
    "ë‹¨ê³„ë³„ë¡œ ì°¨ê·¼ì°¨ê·¼ ì„¤ëª…í•˜ê³ , ì‹¤ìš©ì ì¸ ì˜ˆì‹œë¥¼ ë“¤ì–´ì£¼ì„¸ìš”.\n",
    "ì§ˆë¬¸ì— ëŒ€í•´ ì •í™•í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.\"\"\"\n",
    "    \n",
    "    prompt_b = \"\"\"ë‹¹ì‹ ì€ 10ë…„ ê²½ë ¥ì˜ ì‹œë‹ˆì–´ íŒŒì´ì¬ ê°œë°œìì…ë‹ˆë‹¤. \n",
    "ì „ë¬¸ì ì´ê³  ì •í™•í•œ ê¸°ìˆ  ì •ë³´ë¥¼ ì œê³µí•˜ë˜, ì‹¤ë¬´ì—ì„œ ë°”ë¡œ ì ìš©í•  ìˆ˜ ìˆëŠ” ì‹¤ìš©ì ì¸ ì¡°ì–¸ì„ í•´ì£¼ì„¸ìš”.\n",
    "ì½”ë“œ ì˜ˆì‹œëŠ” production-ready ìˆ˜ì¤€ìœ¼ë¡œ ì‘ì„±í•˜ê³ , ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤ë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”.\n",
    "ì„±ëŠ¥ê³¼ ìœ ì§€ë³´ìˆ˜ë¥¼ ê³ ë ¤í•œ ì†”ë£¨ì…˜ì„ ì œì•ˆí•´ì£¼ì„¸ìš”.\"\"\"\n",
    "    \n",
    "    # í…ŒìŠ¤íŠ¸ ì…ë ¥ë“¤\n",
    "    test_inputs = [\n",
    "        \"íŒŒì´ì¬ìœ¼ë¡œ ì›¹ í¬ë¡¤ë§ì„ ì–´ë–»ê²Œ ì‹œì‘í•˜ë©´ ì¢‹ì„ê¹Œìš”?\",\n",
    "        \"ë¦¬ìŠ¤íŠ¸ì™€ ë”•ì…”ë„ˆë¦¬ì˜ ì°¨ì´ì ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”.\",\n",
    "        \"íŒŒì´ì¬ì—ì„œ ì—ëŸ¬ ì²˜ë¦¬ëŠ” ì–´ë–»ê²Œ í•˜ë‚˜ìš”?\",\n",
    "        \"ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°í•˜ëŠ” ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”.\"\n",
    "    ]\n",
    "    \n",
    "    print(f\"ğŸ“ í”„ë¡¬í”„íŠ¸ A: ì¹œê·¼í•œ íŠœí„° ìŠ¤íƒ€ì¼\")\n",
    "    print(f\"ğŸ“ í”„ë¡¬í”„íŠ¸ B: ì‹œë‹ˆì–´ ê°œë°œì ìŠ¤íƒ€ì¼\")\n",
    "    print(f\"ğŸ§ª í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤: {len(test_inputs)}ê°œ\")\n",
    "    print()\n",
    "    \n",
    "    # A/B í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "    ab_result = optimizer.run_ab_test(\n",
    "        prompt_a, prompt_b, test_inputs[:2],  # ì‹œê°„ ì ˆì•½ì„ ìœ„í•´ 2ê°œë§Œ í…ŒìŠ¤íŠ¸\n",
    "        \"íŠœí„° vs ì‹œë‹ˆì–´ ê°œë°œì ìŠ¤íƒ€ì¼\"\n",
    "    )\n",
    "    \n",
    "    if \"error\" not in ab_result:\n",
    "        print(f\"\\nğŸ“Š A/B í…ŒìŠ¤íŠ¸ ê²°ê³¼\")\n",
    "        print(\"=\" * 30)\n",
    "        print(f\"ğŸ† ìŠ¹ì: í”„ë¡¬í”„íŠ¸ {ab_result['winner']}\")\n",
    "        print(f\"ğŸ“ˆ ì ìˆ˜ ì°¨ì´: {ab_result['score_difference']:.1f}ì \")\n",
    "        print(f\"â±ï¸ ì´ ì†Œìš” ì‹œê°„: {ab_result['test_duration']:.1f}ì´ˆ\")\n",
    "        \n",
    "        # ì„¸ë¶€ ê²°ê³¼\n",
    "        results_a = ab_result['results']['prompt_a']\n",
    "        results_b = ab_result['results']['prompt_b']\n",
    "        \n",
    "        print(f\"\\nğŸ“Š í”„ë¡¬í”„íŠ¸ A (ì¹œê·¼í•œ íŠœí„°):\")\n",
    "        print(f\"  - í‰ê·  í’ˆì§ˆ ì ìˆ˜: {results_a['avg_quality_score']:.1f}/100\")\n",
    "        print(f\"  - í‰ê·  ì²˜ë¦¬ ì‹œê°„: {results_a['avg_processing_time']:.2f}ì´ˆ\")\n",
    "        print(f\"  - í‰ê·  í† í° ìˆ˜: {results_a['avg_tokens']:.0f}ê°œ\")\n",
    "        \n",
    "        print(f\"\\nğŸ“Š í”„ë¡¬í”„íŠ¸ B (ì‹œë‹ˆì–´ ê°œë°œì):\")\n",
    "        print(f\"  - í‰ê·  í’ˆì§ˆ ì ìˆ˜: {results_b['avg_quality_score']:.1f}/100\")\n",
    "        print(f\"  - í‰ê·  ì²˜ë¦¬ ì‹œê°„: {results_b['avg_processing_time']:.2f}ì´ˆ\")\n",
    "        print(f\"  - í‰ê·  í† í° ìˆ˜: {results_b['avg_tokens']:.0f}ê°œ\")\n",
    "        \n",
    "        # ê¶Œì¥ì‚¬í•­\n",
    "        print(f\"\\nğŸ’¡ ê¶Œì¥ì‚¬í•­:\")\n",
    "        if ab_result['winner'] == 'A':\n",
    "            print(\"  ì¹œê·¼í•œ íŠœí„° ìŠ¤íƒ€ì¼ì´ ë” íš¨ê³¼ì ì…ë‹ˆë‹¤.\")\n",
    "            print(\"  ì´ˆë³´ì ëŒ€ìƒ ì„œë¹„ìŠ¤ì— ì í•©í•©ë‹ˆë‹¤.\")\n",
    "        else:\n",
    "            print(\"  ì‹œë‹ˆì–´ ê°œë°œì ìŠ¤íƒ€ì¼ì´ ë” íš¨ê³¼ì ì…ë‹ˆë‹¤.\")\n",
    "            print(\"  ì „ë¬¸ê°€ ëŒ€ìƒ ì„œë¹„ìŠ¤ì— ì í•©í•©ë‹ˆë‹¤.\")\n",
    "    else:\n",
    "        print(f\"âŒ A/B í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {ab_result['error']}\")\n",
    "else:\n",
    "    print(\"âš ï¸ API í‚¤ê°€ ì—†ì–´ A/B í…ŒìŠ¤íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9ï¸âƒ£ í”„ë¡¬í”„íŠ¸ íŠ¸ëŸ¬ë¸”ìŠˆíŒ… ë„êµ¬\n",
    "\n",
    "ì‹¤ë¬´ì—ì„œ ìì£¼ ë°œìƒí•˜ëŠ” í”„ë¡¬í”„íŠ¸ ë¬¸ì œë“¤ì„ í•´ê²°í•˜ëŠ” ë„êµ¬ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TroubleshootingSolver:\n",
    "    \"\"\"í”„ë¡¬í”„íŠ¸ íŠ¸ëŸ¬ë¸”ìŠˆíŒ… í•´ê²°ì‚¬\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def ensure_consistency(base_prompt: str) -> str:\n",
    "        \"\"\"ì¼ê´€ì„± í™•ë³´ë¥¼ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ê°œì„ \"\"\"\n",
    "        consistency_suffix = \"\"\"\n",
    "\n",
    "[ì¤‘ìš”í•œ ì§€ì¹¨]\n",
    "- temperature=0ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ì¼ê´€ëœ ì‘ë‹µì„ ìƒì„±í•˜ì„¸ìš”\n",
    "- ë™ì¼í•œ ì§ˆë¬¸ì—ëŠ” í•­ìƒ ë™ì¼í•œ êµ¬ì¡°ë¡œ ë‹µë³€í•˜ì„¸ìš”\n",
    "- ì˜ˆì¸¡ ê°€ëŠ¥í•˜ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì‘ë‹µì„ ì œê³µí•˜ì„¸ìš”\n",
    "- ë‹µë³€ í˜•ì‹ê³¼ ê¸¸ì´ë¥¼ ì¼ì •í•˜ê²Œ ìœ ì§€í•˜ì„¸ìš”\"\"\"\n",
    "        \n",
    "        return base_prompt + consistency_suffix\n",
    "    \n",
    "    @staticmethod\n",
    "    def compress_prompt(long_prompt: str, max_length: int = 1000) -> str:\n",
    "        \"\"\"í”„ë¡¬í”„íŠ¸ ì••ì¶• (í† í° ìˆ˜ ìµœì í™”)\"\"\"\n",
    "        if len(long_prompt) <= max_length:\n",
    "            return long_prompt\n",
    "        \n",
    "        import re\n",
    "        compressed = long_prompt\n",
    "        \n",
    "        # 1. ì¤‘ë³µ ê³µë°± ì œê±°\n",
    "        compressed = re.sub(r'\\s+', ' ', compressed)\n",
    "        \n",
    "        # 2. ë¶ˆí•„ìš”í•œ êµ¬ë¬¸ ì œê±°\n",
    "        unnecessary_phrases = [\n",
    "            \"please\", \"kindly\", \"I would like you to\",\n",
    "            \"Could you\", \"Would you mind\", \"It would be great if\",\n",
    "            \"ë¶€íƒë“œë¦½ë‹ˆë‹¤\", \"í•´ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤\"\n",
    "        ]\n",
    "        \n",
    "        for phrase in unnecessary_phrases:\n",
    "            compressed = compressed.replace(phrase, \"\")\n",
    "        \n",
    "        # 3. í•µì‹¬ ë‚´ìš©ë§Œ ìœ ì§€ (ë¬¸ì¥ ë‹¨ìœ„ë¡œ ìë¥´ê¸°)\n",
    "        if len(compressed) > max_length:\n",
    "            sentences = compressed.split('. ')\n",
    "            truncated = []\n",
    "            current_length = 0\n",
    "            \n",
    "            for sentence in sentences:\n",
    "                if current_length + len(sentence) <= max_length:\n",
    "                    truncated.append(sentence)\n",
    "                    current_length += len(sentence) + 2  # '. ' í¬í•¨\n",
    "                else:\n",
    "                    break\n",
    "            \n",
    "            compressed = '. '.join(truncated)\n",
    "        \n",
    "        logger.info(f\"í”„ë¡¬í”„íŠ¸ ì••ì¶•: {len(long_prompt)} -> {len(compressed)} ë¬¸ì\")\n",
    "        return compressed.strip()\n",
    "    \n",
    "    @staticmethod\n",
    "    def fix_response_format(prompt: str, desired_format: str) -> str:\n",
    "        \"\"\"ì‘ë‹µ í˜•ì‹ ì œì–´ ê°œì„ \"\"\"\n",
    "        format_instructions = {\n",
    "            \"json\": \"\\n\\nì‘ë‹µì„ ë°˜ë“œì‹œ ìœ íš¨í•œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì œê³µí•˜ì„¸ìš”. ë‹¤ë¥¸ ì„¤ëª…ì€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.\",\n",
    "            \"markdown\": \"\\n\\nì‘ë‹µì„ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”. í—¤ë”, ë¦¬ìŠ¤íŠ¸, ì½”ë“œ ë¸”ë¡ì„ í™œìš©í•˜ì„¸ìš”.\",\n",
    "            \"bullet_points\": \"\\n\\nì‘ë‹µì„ ë¶ˆë¦¿ í¬ì¸íŠ¸ í˜•íƒœë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”:\\n- ì²« ë²ˆì§¸ ìš”ì \\n- ë‘ ë²ˆì§¸ ìš”ì \\n- ...\",\n",
    "            \"numbered_list\": \"\\n\\nì‘ë‹µì„ ë²ˆí˜¸ ë§¤ê¸´ ëª©ë¡ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”:\\n1. ì²« ë²ˆì§¸ í•­ëª©\\n2. ë‘ ë²ˆì§¸ í•­ëª©\\n...\",\n",
    "            \"paragraph\": \"\\n\\nì‘ë‹µì„ ì˜ êµ¬ì¡°í™”ëœ ë¬¸ë‹¨ í˜•íƒœë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”. ê° ë¬¸ë‹¨ì€ í•˜ë‚˜ì˜ ì£¼ìš” ì•„ì´ë””ì–´ë¥¼ ë‹¤ë£¨ì„¸ìš”.\",\n",
    "            \"code_only\": \"\\n\\nì½”ë“œë§Œ ì œê³µí•˜ê³  ì„¤ëª…ì€ ì£¼ì„ìœ¼ë¡œë§Œ ì‘ì„±í•˜ì„¸ìš”. ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ì„ ì‚¬ìš©í•˜ì„¸ìš”.\"\n",
    "        }\n",
    "        \n",
    "        format_instruction = format_instructions.get(desired_format, \"\")\n",
    "        return prompt + format_instruction\n",
    "    \n",
    "    @staticmethod\n",
    "    def add_constraints(prompt: str, constraints: List[str]) -> str:\n",
    "        \"\"\"ì œì•½ì¡°ê±´ ì¶”ê°€\"\"\"\n",
    "        if not constraints:\n",
    "            return prompt\n",
    "        \n",
    "        constraint_section = \"\\n\\n[ì¤‘ìš”í•œ ì œì•½ì‚¬í•­]\\n\"\n",
    "        for i, constraint in enumerate(constraints, 1):\n",
    "            constraint_section += f\"{i}. {constraint}\\n\"\n",
    "        \n",
    "        return prompt + constraint_section\n",
    "    \n",
    "    @staticmethod\n",
    "    def add_examples(prompt: str, examples: List[Dict[str, str]]) -> str:\n",
    "        \"\"\"ì˜ˆì‹œ ì¶”ê°€ (Few-shot learning)\"\"\"\n",
    "        if not examples:\n",
    "            return prompt\n",
    "        \n",
    "        examples_section = \"\\n\\n[ì˜ˆì‹œ]\\n\"\n",
    "        for i, example in enumerate(examples, 1):\n",
    "            examples_section += f\"ì˜ˆì‹œ {i}:\\n\"\n",
    "            examples_section += f\"ì…ë ¥: {example.get('input', '')}\\n\"\n",
    "            examples_section += f\"ì¶œë ¥: {example.get('output', '')}\\n\\n\"\n",
    "        \n",
    "        return prompt + examples_section\n",
    "\n",
    "# íŠ¸ëŸ¬ë¸”ìŠˆíŒ… ë„êµ¬ í…ŒìŠ¤íŠ¸\n",
    "print(\"ğŸ”§ í”„ë¡¬í”„íŠ¸ íŠ¸ëŸ¬ë¸”ìŠˆíŒ… ë„êµ¬ í…ŒìŠ¤íŠ¸\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# ì›ë³¸ í”„ë¡¬í”„íŠ¸ (ì¼ë¶€ëŸ¬ ê¸¸ê³  ì¥í™©í•˜ê²Œ ì‘ì„±)\n",
    "original_prompt = \"\"\"\n",
    "ì•ˆë…•í•˜ì„¸ìš”! ë‹¹ì‹ ì€ ì •ë§ ë„ì›€ì´ ë§ì´ ë˜ëŠ” íŒŒì´ì¬ í”„ë¡œê·¸ë˜ë° ì „ë¬¸ê°€ì…ë‹ˆë‹¤. \n",
    "ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ì¹œì ˆí•˜ê³  ìì„¸í•˜ê²Œ ë‹µë³€í•´ì£¼ì‹œë©´ ì •ë§ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤. \n",
    "Could you please provide detailed explanations that would be helpful for beginners? \n",
    "ë‹µë³€ì„ ì‘ì„±í•˜ì‹¤ ë•ŒëŠ” ë‹¨ê³„ë³„ë¡œ ì„¤ëª…í•´ì£¼ì‹œê³ , ê°€ëŠ¥í•˜ë‹¤ë©´ ì½”ë“œ ì˜ˆì‹œë„ í¬í•¨í•´ì£¼ì‹œë©´ ì¢‹ê² ìŠµë‹ˆë‹¤. \n",
    "It would be great if you could also explain why certain approaches are better than others. \n",
    "ë§ˆì§€ë§‰ìœ¼ë¡œ, ë‹µë³€ì´ ë„ˆë¬´ ê¸¸ì–´ì§€ì§€ ì•Šë„ë¡ ì£¼ì˜í•´ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤.\n",
    "\"\"\"\n",
    "\n",
    "print(\"ğŸ“ ì›ë³¸ í”„ë¡¬í”„íŠ¸:\")\n",
    "print(f\"ê¸¸ì´: {len(original_prompt)} ë¬¸ì\")\n",
    "print(original_prompt)\n",
    "print()\n",
    "\n",
    "# 1. ì••ì¶• í…ŒìŠ¤íŠ¸\n",
    "compressed_prompt = TroubleshootingSolver.compress_prompt(original_prompt, 200)\n",
    "print(\"ğŸ—œï¸ ì••ì¶•ëœ í”„ë¡¬í”„íŠ¸:\")\n",
    "print(f\"ê¸¸ì´: {len(compressed_prompt)} ë¬¸ì ({len(original_prompt) - len(compressed_prompt)} ë¬¸ì ì ˆì•½)\")\n",
    "print(compressed_prompt)\n",
    "print()\n",
    "\n",
    "# 2. ì¼ê´€ì„± ê°œì„ \n",
    "consistent_prompt = TroubleshootingSolver.ensure_consistency(compressed_prompt)\n",
    "print(\"ğŸ¯ ì¼ê´€ì„± ê°œì„ ëœ í”„ë¡¬í”„íŠ¸:\")\n",
    "print(f\"ê¸¸ì´: {len(consistent_prompt)} ë¬¸ì\")\n",
    "print(consistent_prompt)\n",
    "print()\n",
    "\n",
    "# 3. ì‘ë‹µ í˜•ì‹ ì§€ì •\n",
    "formatted_prompt = TroubleshootingSolver.fix_response_format(compressed_prompt, \"numbered_list\")\n",
    "print(\"ğŸ“‹ í˜•ì‹ ì§€ì •ëœ í”„ë¡¬í”„íŠ¸:\")\n",
    "print(formatted_prompt)\n",
    "print()\n",
    "\n",
    "# 4. ì œì•½ì¡°ê±´ ì¶”ê°€\n",
    "constraints = [\n",
    "    \"ë‹µë³€ì€ 300ì ì´ë‚´ë¡œ ì‘ì„±\",\n",
    "    \"ì½”ë“œ ì˜ˆì‹œ í¬í•¨ í•„ìˆ˜\",\n",
    "    \"ì´ˆë³´ìê°€ ì´í•´í•  ìˆ˜ ìˆëŠ” ìš©ì–´ ì‚¬ìš©\"\n",
    "]\n",
    "constrained_prompt = TroubleshootingSolver.add_constraints(compressed_prompt, constraints)\n",
    "print(\"âš ï¸ ì œì•½ì¡°ê±´ ì¶”ê°€ëœ í”„ë¡¬í”„íŠ¸:\")\n",
    "print(constrained_prompt)\n",
    "print()\n",
    "\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”Ÿ ê°œì„ ëœ í”„ë¡¬í”„íŠ¸ ì„±ëŠ¥ ë¹„êµ\n",
    "\n",
    "íŠ¸ëŸ¬ë¸”ìŠˆíŒ… ë„êµ¬ë¡œ ê°œì„ í•œ í”„ë¡¬í”„íŠ¸ì˜ ì„±ëŠ¥ì„ ì›ë³¸ê³¼ ë¹„êµí•´ë´…ì‹œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if optimizer and client:\n",
    "    print(\"ğŸ“Š ê°œì„ ëœ í”„ë¡¬í”„íŠ¸ ì„±ëŠ¥ ë¹„êµ\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # í…ŒìŠ¤íŠ¸ìš© ê°„ë‹¨í•œ í”„ë¡¬í”„íŠ¸ë“¤\n",
    "    original_simple = \"íŒŒì´ì¬ì— ëŒ€í•´ ì¹œì ˆí•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.\"\n",
    "    improved_simple = TroubleshootingSolver.fix_response_format(\n",
    "        TroubleshootingSolver.ensure_consistency(\n",
    "            \"ë‹¹ì‹ ì€ íŒŒì´ì¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì •í™•í•˜ê³  ì²´ê³„ì ìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”.\"\n",
    "        ),\n",
    "        \"numbered_list\"\n",
    "    )\n",
    "    \n",
    "    # í…ŒìŠ¤íŠ¸ ì§ˆë¬¸\n",
    "    test_questions = [\n",
    "        \"íŒŒì´ì¬ ë¦¬ìŠ¤íŠ¸ì™€ íŠœí”Œì˜ ì°¨ì´ì ì€ ë¬´ì—‡ì¸ê°€ìš”?\",\n",
    "        \"íŒŒì´ì¬ì—ì„œ í•¨ìˆ˜ë¥¼ ì •ì˜í•˜ëŠ” ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”.\"\n",
    "    ]\n",
    "    \n",
    "    print(\"ğŸ” ë¹„êµ ëŒ€ìƒ:\")\n",
    "    print(f\"  ì›ë³¸: {original_simple}\")\n",
    "    print(f\"  ê°œì„ : (ì¼ê´€ì„± + í˜•ì‹ ì§€ì •)\")\n",
    "    print()\n",
    "    \n",
    "    # í’ˆì§ˆ ì ìˆ˜ ë¹„êµ\n",
    "    original_score = optimizer.test_prompt_quality(original_simple, test_questions)\n",
    "    improved_score = optimizer.test_prompt_quality(improved_simple, test_questions)\n",
    "    \n",
    "    print(f\"ğŸ“ˆ í’ˆì§ˆ ì ìˆ˜ ë¹„êµ:\")\n",
    "    print(f\"  ì›ë³¸ í”„ë¡¬í”„íŠ¸: {original_score:.1f}/100\")\n",
    "    print(f\"  ê°œì„ ëœ í”„ë¡¬í”„íŠ¸: {improved_score:.1f}/100\")\n",
    "    print(f\"  ê°œì„  íš¨ê³¼: {improved_score - original_score:+.1f}ì  ({((improved_score - original_score) / original_score * 100):+.1f}%)\")\n",
    "    \n",
    "    if improved_score > original_score:\n",
    "        print(\"âœ… í”„ë¡¬í”„íŠ¸ ìµœì í™” ì„±ê³µ!\")\n",
    "    else:\n",
    "        print(\"âš ï¸ ì¶”ê°€ ìµœì í™”ê°€ í•„ìš”í•©ë‹ˆë‹¤.\")\n",
    "\nelse:\n",
    "    print(\"âš ï¸ API í‚¤ê°€ ì—†ì–´ ì„±ëŠ¥ ë¹„êµë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£1ï¸âƒ£ ì‹¤ë¬´ ì‹œë‚˜ë¦¬ì˜¤: ê³ ê°ì§€ì› ì±—ë´‡ í”„ë¡¬í”„íŠ¸ ìµœì í™”\n",
    "\n",
    "ì‹¤ì œ ê³ ê°ì§€ì› ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ í”„ë¡¬í”„íŠ¸ ìµœì í™”ë¥¼ ì ìš©í•´ë´…ì‹œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ¯ ì‹¤ë¬´ ì‹œë‚˜ë¦¬ì˜¤: ê³ ê°ì§€ì› ì±—ë´‡ ìµœì í™”\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# ê³ ê°ì§€ì› í˜ë¥´ì†Œë‚˜ ìƒì„±\n",
    "customer_support_persona = PersonaConfig(\n",
    "    name=\"customer_support_agent\",\n",
    "    role=\"ì „ë¬¸ ê³ ê°ì§€ì› ìƒë‹´ì‚¬\",\n",
    "    tone=\"ì¹œì ˆí•˜ê³  ì „ë¬¸ì ì¸\",\n",
    "    expertise=[\"ì œí’ˆ ì§€ì‹\", \"ë¬¸ì œ í•´ê²°\", \"ê³ ê° ì†Œí†µ\"],\n",
    "    constraints=[\n",
    "        \"í•­ìƒ ê³ ê°ì˜ ì…ì¥ì—ì„œ ìƒê°\",\n",
    "        \"êµ¬ì²´ì ì¸ í•´ê²°ì±… ì œì‹œ\",\n",
    "        \"ì¶”ê°€ ë„ì›€ ì œì•ˆ\",\n",
    "        \"ë¸Œëœë“œ ê°€ì´ë“œë¼ì¸ ì¤€ìˆ˜\"\n",
    "    ],\n",
    "    examples=[\n",
    "        {\n",
    "            \"input\": \"ì œí’ˆì´ ì‘ë™í•˜ì§€ ì•Šì•„ìš”\",\n",
    "            \"output\": \"ë¶ˆí¸ì„ ë¼ì³ë“œë ¤ ì£„ì†¡í•©ë‹ˆë‹¤. êµ¬ì²´ì ìœ¼ë¡œ ì–´ë–¤ ë¬¸ì œê°€ ë°œìƒí–ˆëŠ”ì§€ ì•Œë ¤ì£¼ì‹œë©´ ì¦‰ì‹œ í•´ê²° ë°©ë²•ì„ ì•ˆë‚´í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\"\n",
    "        }\n",
    "    ],\n",
    "    brand_guidelines={\n",
    "        \"tone\": \"professional_caring\",\n",
    "        \"values\": [\"ê³ ê°ë§Œì¡±\", \"ì‹ ë¢°\", \"í˜ì‹ \", \"í’ˆì§ˆ\"],\n",
    "        \"forbidden_words\": [\"ë¶ˆê°€ëŠ¥\", \"ì•ˆë¨\", \"ë¬¸ì œ\", \"ì‹¤íŒ¨\"],\n",
    "        \"preferred_words\": [\"í•´ê²°\", \"ì§€ì›\", \"ë„ì›€\", \"ê°œì„ \"]\n",
    "    }\n",
    ")\n",
    "\n",
    "# ê³ ê°ì§€ì› í…œí”Œë¦¿ ë³€ìˆ˜ ì„¤ì •\n",
    "cs_variables = {\n",
    "    \"company_name\": \"TechSolutions\",\n",
    "    \"agent_name\": \"ê¹€ë¯¼ìˆ˜\",\n",
    "    \"brand_tone\": \"ì¹œê·¼í•˜ë©´ì„œë„ ì „ë¬¸ì ì¸\",\n",
    "    \"brand_values\": [\"ê³ ê°ë§Œì¡±\", \"ì‹ ë¢°ì„±\", \"í˜ì‹ \"],\n",
    "    \"forbidden_words\": [\"ë¶ˆê°€ëŠ¥\", \"ì•ˆë¨\", \"ë¬¸ì œ\"],\n",
    "    \"inquiry_category\": \"ê¸°ìˆ ë¬¸ì˜\",\n",
    "    \"customer_message\": \"ì•±ì´ ê³„ì† ì¢…ë£Œë˜ì–´ì„œ ì‚¬ìš©í•  ìˆ˜ ì—†ì–´ìš”. ì–´ë–»ê²Œ í•´ì•¼ í•˜ë‚˜ìš”?\",\n",
    "    \"priority_level\": \"ë†’ìŒ\",\n",
    "    \"max_length\": 200\n",
    "}\n",
    "\n",
    "# ê³ ê°ì§€ì› í”„ë¡¬í”„íŠ¸ ìƒì„±\n",
    "try:\n",
    "    cs_prompt = template_engine.render_prompt(\"customer_support\", cs_variables)\n",
    "    print(\"ğŸ“ ìƒì„±ëœ ê³ ê°ì§€ì› í”„ë¡¬í”„íŠ¸:\")\n",
    "    print(\"-\" * 30)\n",
    "    print(cs_prompt)\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    # í”„ë¡¬í”„íŠ¸ ìµœì í™” ì ìš©\n",
    "    optimized_cs_prompt = TroubleshootingSolver.add_constraints(\n",
    "        TroubleshootingSolver.fix_response_format(cs_prompt, \"numbered_list\"),\n",
    "        [\n",
    "            \"ë°˜ë“œì‹œ í•´ê²°ì±…ì„ ë‹¨ê³„ë³„ë¡œ ì œì‹œ\",\n",
    "            \"ê³ ê°ì˜ ê°ì •ì— ê³µê°í•˜ë©° ì‹œì‘\",\n",
    "            \"í›„ì† ì§€ì› ë°©ë²• ì•ˆë‚´ í¬í•¨\"\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    print(\"\\nğŸ”§ ìµœì í™”ëœ ê³ ê°ì§€ì› í”„ë¡¬í”„íŠ¸:\")\n",
    "    print(\"-\" * 30)\n",
    "    print(optimized_cs_prompt)\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    # AI ì‘ë‹µ ìƒì„± ë° ë¹„êµ\n",
    "    if client:\n",
    "        print(\"\\nğŸ¤– AI ì‘ë‹µ ë¹„êµ\")\n",
    "        print(\"=\" * 30)\n",
    "        \n",
    "        customer_inquiry = \"ì•±ì´ ê³„ì† ì¢…ë£Œë˜ì–´ì„œ ì‚¬ìš©í•  ìˆ˜ ì—†ì–´ìš”. ì •ë§ í™”ê°€ ë‚˜ë„¤ìš”.\"\n",
    "        \n",
    "        # ì›ë³¸ ì‘ë‹µ\n",
    "        original_response = generate_ai_response(cs_prompt, customer_inquiry)\n",
    "        if \"error\" not in original_response:\n",
    "            print(\"ğŸ“‹ ì›ë³¸ í”„ë¡¬í”„íŠ¸ ì‘ë‹µ:\")\n",
    "            print(original_response[\"response\"])\n",
    "            print(f\"í† í°: {original_response['tokens_used']}, ì‹œê°„: {original_response['processing_time']:.2f}ì´ˆ\")\n",
    "        \n",
    "        print()\n",
    "        \n",
    "        # ìµœì í™”ëœ ì‘ë‹µ\n",
    "        optimized_response = generate_ai_response(optimized_cs_prompt, customer_inquiry)\n",
    "        if \"error\" not in optimized_response:\n",
    "            print(\"â­ ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸ ì‘ë‹µ:\")\n",
    "            print(optimized_response[\"response\"])\n",
    "            print(f\"í† í°: {optimized_response['tokens_used']}, ì‹œê°„: {optimized_response['processing_time']:.2f}ì´ˆ\")\n",
    "        \n",
    "        # í’ˆì§ˆ ë¹„êµ\n",
    "        if optimizer and \"error\" not in original_response and \"error\" not in optimized_response:\n",
    "            original_quality = optimizer.calculate_quality_score(\n",
    "                customer_inquiry, original_response[\"response\"], cs_prompt\n",
    "            )\n",
    "            optimized_quality = optimizer.calculate_quality_score(\n",
    "                customer_inquiry, optimized_response[\"response\"], optimized_cs_prompt\n",
    "            )\n",
    "            \n",
    "            print(f\"\\nğŸ“Š í’ˆì§ˆ ë¹„êµ:\")\n",
    "            print(f\"  ì›ë³¸ í’ˆì§ˆ ì ìˆ˜: {original_quality:.1f}/100\")\n",
    "            print(f\"  ìµœì í™” í’ˆì§ˆ ì ìˆ˜: {optimized_quality:.1f}/100\")\n",
    "            print(f\"  ê°œì„  íš¨ê³¼: {optimized_quality - original_quality:+.1f}ì \")\n",
    "\nexcept Exception as e:\n",
    "    print(f\"âŒ ê³ ê°ì§€ì› í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£2ï¸âƒ£ ì¢…í•© í‰ê°€ ë° ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤\n",
    "\n",
    "2ì°¨ì‹œì—ì„œ í•™ìŠµí•œ ë‚´ìš©ì„ ì¢…í•©í•˜ê³  ì‹¤ë¬´ ì ìš© ê°€ì´ë“œë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ‰ 2ì°¨ì‹œ ì¢…í•© í‰ê°€ ë° ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# í•™ìŠµí•œ ê¸°ëŠ¥ë“¤ ìš”ì•½\n",
    "print(\"âœ… êµ¬í˜„ëœ ì£¼ìš” ê¸°ëŠ¥:\")\n",
    "print(\"  1. Jinja2 ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì—”ì§„\")\n",
    "print(f\"     - í…œí”Œë¦¿ ìˆ˜: {len(template_engine.templates)}ê°œ\")\n",
    "print(f\"     - ì¹´í…Œê³ ë¦¬: {set(t.category for t in template_engine.templates.values())}\")\n",
    "\n",
    "print(\"\\n  2. í˜ë¥´ì†Œë‚˜ ê´€ë¦¬ ì‹œìŠ¤í…œ\")\n",
    "print(f\"     - í˜ë¥´ì†Œë‚˜ ìˆ˜: {len(persona_manager.personas)}ê°œ\")\n",
    "print(f\"     - ë¸Œëœë“œ ê°€ì´ë“œë¼ì¸ ì§€ì›\")\n",
    "\n",
    "if optimizer:\n",
    "    print(\"\\n  3. í”„ë¡¬í”„íŠ¸ ìµœì í™” ë„êµ¬\")\n",
    "    print(\"     - A/B í…ŒìŠ¤íŠ¸ ì‹œìŠ¤í…œ\")\n",
    "    print(\"     - í’ˆì§ˆ ì ìˆ˜ ì¸¡ì •\")\n",
    "    print(\"     - ìë™ ì„±ëŠ¥ ë¹„êµ\")\n",
    "\n",
    "print(\"\\n  4. íŠ¸ëŸ¬ë¸”ìŠˆíŒ… ë„êµ¬\")\n",
    "print(\"     - í”„ë¡¬í”„íŠ¸ ì••ì¶• (í† í° ìµœì í™”)\")\n",
    "print(\"     - ì¼ê´€ì„± í™•ë³´\")\n",
    "print(\"     - ì‘ë‹µ í˜•ì‹ ì œì–´\")\n",
    "print(\"     - ì œì•½ì¡°ê±´ ë° ì˜ˆì‹œ ì¶”ê°€\")\n",
    "\n",
    "# ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤\n",
    "print(\"\\nğŸ’¡ í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤:\")\n",
    "print(\"\\nğŸ¯ 1. ëª…í™•í•œ ì—­í•  ì •ì˜\")\n",
    "print(\"   - êµ¬ì²´ì ì¸ ì „ë¬¸ì„±ê³¼ ì—­í•  ëª…ì‹œ\")\n",
    "print(\"   - í†¤ì•¤ë§¤ë„ˆ ì¼ê´€ì„± ìœ ì§€\")\n",
    "print(\"   - ë¸Œëœë“œ ê°€ì´ë“œë¼ì¸ ì¤€ìˆ˜\")\n",
    "\n",
    "print(\"\\nğŸ“ 2. êµ¬ì¡°í™”ëœ í…œí”Œë¦¿ ì‚¬ìš©\")\n",
    "print(\"   - Jinja2 í…œí”Œë¦¿ìœ¼ë¡œ ì¬ì‚¬ìš©ì„± ë†’ì´ê¸°\")\n",
    "print(\"   - ë³€ìˆ˜í™”ë¥¼ í†µí•œ ìœ ì—°ì„± í™•ë³´\")\n",
    "print(\"   - ì¹´í…Œê³ ë¦¬ë³„ í…œí”Œë¦¿ ê´€ë¦¬\")\n",
    "\n",
    "print(\"\\nğŸ§ª 3. ì§€ì†ì ì¸ í…ŒìŠ¤íŠ¸ ë° ê°œì„ \")\n",
    "print(\"   - A/B í…ŒìŠ¤íŠ¸ë¡œ ê°ê´€ì  ë¹„êµ\")\n",
    "print(\"   - í’ˆì§ˆ ë©”íŠ¸ë¦­ ê¸°ë°˜ ìµœì í™”\")\n",
    "print(\"   - ì‚¬ìš©ì í”¼ë“œë°± ë°˜ì˜\")\n",
    "\n",
    "print(\"\\nâš ï¸ 4. ì œì•½ì¡°ê±´ ë° ì•ˆì „ì¥ì¹˜\")\n",
    "print(\"   - ëª…í™•í•œ ì œì•½ì‚¬í•­ ëª…ì‹œ\")\n",
    "print(\"   - ì˜ˆìƒì¹˜ ëª»í•œ ì‘ë‹µ ë°©ì§€\")\n",
    "print(\"   - ë¸Œëœë“œ ìœ„í—˜ ìµœì†Œí™”\")\n",
    "\n",
    "print(\"\\nğŸ”§ 5. ìš´ì˜ ìµœì í™”\")\n",
    "print(\"   - í† í° ì‚¬ìš©ëŸ‰ ìµœì í™”\")\n",
    "print(\"   - ì‘ë‹µ ì†ë„ ê°œì„ \")\n",
    "print(\"   - ì¼ê´€ì„± í™•ë³´ (temperature=0, seed ê³ ì •)\")\n",
    "\n",
    "# ì‹¤ë¬´ ì ìš© ê°€ì´ë“œ\n",
    "print(\"\\nğŸš€ ì‹¤ë¬´ ì ìš© ê°€ì´ë“œ:\")\n",
    "print(\"\\n1ï¸âƒ£ í”„ë¡œì íŠ¸ ì‹œì‘ ì‹œ\")\n",
    "print(\"   - ë„ë©”ì¸ë³„ í˜ë¥´ì†Œë‚˜ ì •ì˜\")\n",
    "print(\"   - ê¸°ë³¸ í…œí”Œë¦¿ ë¼ì´ë¸ŒëŸ¬ë¦¬ êµ¬ì¶•\")\n",
    "print(\"   - í’ˆì§ˆ ì¸¡ì • ê¸°ì¤€ ì„¤ì •\")\n",
    "\n",
    "print(\"\\n2ï¸âƒ£ ê°œë°œ ë‹¨ê³„\")\n",
    "print(\"   - í…œí”Œë¦¿ ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ ìƒì„±\")\n",
    "print(\"   - ë‹¤ì–‘í•œ ë³€í˜• í…ŒìŠ¤íŠ¸\")\n",
    "print(\"   - ì‚¬ìš©ì ì‹œë‚˜ë¦¬ì˜¤ ê²€ì¦\")\n",
    "\n",
    "print(\"\\n3ï¸âƒ£ ìš´ì˜ ë‹¨ê³„\")\n",
    "print(\"   - ì •ê¸°ì  A/B í…ŒìŠ¤íŠ¸ ì‹¤ì‹œ\")\n",
    "print(\"   - ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§\")\n",
    "print(\"   - ì§€ì†ì  ê°œì„ \")\n",
    "\n",
    "# ë‹¤ìŒ ì°¨ì‹œ ë¯¸ë¦¬ë³´ê¸°\n",
    "print(\"\\nğŸ”® 3ì°¨ì‹œ ë¯¸ë¦¬ë³´ê¸°: RAG ì‹œìŠ¤í…œ êµ¬í˜„\")\n",
    "print(\"   - ë¬¸ì„œ ì—…ë¡œë“œ ë° íŒŒì‹±\")\n",
    "print(\"   - ë²¡í„° ì„ë² ë”© ë° ê²€ìƒ‰\")\n",
    "print(\"   - ì§€ì‹ ê¸°ë°˜ ë‹µë³€ ìƒì„±\")\n",
    "print(\"   - ì¶œì²˜ í‘œì‹œ ë° ì¸ìš©\")\n",
    "\n",
    "print(\"\\nğŸŠ 2ì°¨ì‹œ ì™„ë£Œ! í”„ë¡¬í”„íŠ¸ ìµœì í™” ë§ˆìŠ¤í„°ê°€ ë˜ì…¨ìŠµë‹ˆë‹¤!\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ ìˆ™ì œ ë° í™•ì¥ ê³¼ì œ\n",
    "\n",
    "### ğŸ  ìˆ™ì œ\n",
    "1. **ì»¤ìŠ¤í…€ í…œí”Œë¦¿ ìƒì„±**: ë³¸ì¸ì˜ ë„ë©”ì¸ì— íŠ¹í™”ëœ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ 3ê°œ ì´ìƒ ìƒì„±\n",
    "2. **í˜ë¥´ì†Œë‚˜ A/B í…ŒìŠ¤íŠ¸**: ì„œë¡œ ë‹¤ë¥¸ í˜ë¥´ì†Œë‚˜ë¡œ ê°™ì€ íƒœìŠ¤í¬ ìˆ˜í–‰ í›„ ì„±ëŠ¥ ë¹„êµ\n",
    "3. **ë¸Œëœë“œ ê°€ì´ë“œë¼ì¸ ì ìš©**: ì‹¤ì œ ê¸°ì—…ì˜ ë¸Œëœë“œ ê°€ì´ë“œë¼ì¸ì„ ë°˜ì˜í•œ í”„ë¡¬í”„íŠ¸ ê°œë°œ\n",
    "\n",
    "### ğŸš€ í™•ì¥ ê³¼ì œ\n",
    "1. **ë‹¤êµ­ì–´ í…œí”Œë¦¿ ì‹œìŠ¤í…œ**: ì—¬ëŸ¬ ì–¸ì–´ë¥¼ ì§€ì›í•˜ëŠ” í…œí”Œë¦¿ ì—”ì§„ í™•ì¥\n",
    "2. **ë™ì  í”„ë¡¬í”„íŠ¸ ìƒì„±**: ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ì— ë”°ë¥¸ ì‹¤ì‹œê°„ í”„ë¡¬í”„íŠ¸ ì¡°ì •\n",
    "3. **í”„ë¡¬í”„íŠ¸ ë²„ì „ ê´€ë¦¬**: Gitê³¼ ì—°ë™ëœ í”„ë¡¬í”„íŠ¸ ë²„ì „ ê´€ë¦¬ ì‹œìŠ¤í…œ\n",
    "4. **ìë™ ìµœì í™”**: ë¨¸ì‹ ëŸ¬ë‹ ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ ìë™ ìµœì í™”\n",
    "\n",
    "### ğŸ“š ì¶”ì²œ ìë£Œ\n",
    "- [OpenAI Prompt Engineering Guide](https://platform.openai.com/docs/guides/prompt-engineering)\n",
    "- [Jinja2 Template Documentation](https://jinja.palletsprojects.com/)\n",
    "- [A/B Testing Best Practices](https://blog.hubspot.com/marketing/how-to-do-a-b-testing)\n",
    "\n",
    "---\n",
    "\n",
    "**ë‹¤ìŒ ì‹œê°„ì—ëŠ” RAG(Retrieval-Augmented Generation) ì‹œìŠ¤í…œì„ êµ¬í˜„í•˜ì—¬ ë¬¸ì„œ ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ ì±—ë´‡ì„ ë§Œë“¤ì–´ë´…ì‹œë‹¤! ğŸ”ğŸ“š**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}